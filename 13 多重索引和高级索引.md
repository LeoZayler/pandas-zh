### 13 多重索引和高级索引
本章将介绍MultiIndex的索引方法以及一些高级的索引技巧。
你可以从[索引和选择数据](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing)章节查看基本的索引方法。
> 警告：设置操作返回一个副本还是一个引用取决于不同的环境。有时这叫做链式赋值，应该尽量避免，查看[返回视图或副本](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing-view-versus-copy)。

从[cookbook](http://pandas.pydata.org/pandas-docs/version/0.23/cookbook.html#cookbook-selection)查看高级策略。

#### 13.1 分层索引（MultiIndex)
分层/分级索引令人兴奋，因为它为复杂的数据分析和操作，尤其是操作高维数据打开了一扇门。本质上，它令你可以在低纬数据结构（一维的Series，二维的DataFrame）中存储和处理任意维度的数据。
本章，我们将展示什么是分层索引，以及如何将它与前面章节提到的索引方法相结合。稍后，当我们讨论[分组](http://pandas.pydata.org/pandas-docs/version/0.23/groupby.html#groupby)、[透视表和重塑数据](http://pandas.pydata.org/pandas-docs/version/0.23/reshaping.html#reshaping)时，我们将展示重要的应用来说明它如何帮助结构化数据分析。

从[cookbook](http://pandas.pydata.org/pandas-docs/version/0.23/cookbook.html#cookbook-selection)查看高级策略。

##### 13.1.1 创建MultiIndex(分层索引)对象

`MultiIndex`对象是通常将轴标签存储在Pandas对象中的标准`Index`对象的分层模拟。你可以把`MultiIndex`想象成一个元组数组，其中每个元组都是唯一的。`MultiIndex`可以用一组数组（使用`MultiIndex.from_arrays`）、一组元组（使用`MultiIndex.from_tuples`）或用一组相交的迭代器（使用`MultiIndex.from_product`）来生成。当传入一个元组数组时，`Index`构造器将尝试返回一个`MultiIndex`。下面的示例展示了初始化多重索引的的不同方法。

```Python
In [1]: arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],
   ...:           ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]
   ...: 

In [2]: tuples = list(zip(*arrays))

In [3]: tuples
Out[3]: 
[('bar', 'one'),
 ('bar', 'two'),
 ('baz', 'one'),
 ('baz', 'two'),
 ('foo', 'one'),
 ('foo', 'two'),
 ('qux', 'one'),
 ('qux', 'two')]

In [4]: index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])

In [5]: index
Out[5]: 
MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],
           labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],
           names=['first', 'second'])

In [6]: s = pd.Series(np.random.randn(8), index=index)

In [7]: s
Out[7]: 
first  second
bar    one       0.469112
       two      -0.282863
baz    one      -1.509059
       two      -1.135632
foo    one       1.212112
       two      -0.173215
qux    one       0.119209
       two      -1.044236
dtype: float64
```

当你希望使用两个迭代器中的每一对元素时，使用MultiIndex.from product函数会更容易。

```python
In [8]: iterables = [['bar', 'baz', 'foo', 'qux'], ['one', 'two']]

In [9]: pd.MultiIndex.from_product(iterables, names=['first', 'second'])
Out[9]: 
MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],
           labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],
           names=['first', 'second'])
```

作为一种便利手段，你可以向一个Series或DataFrame中传入一个数组列表来自动构造多重索引。

```Python
In [10]: arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']),
   ....:           np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])]
   ....: 

In [11]: s = pd.Series(np.random.randn(8), index=arrays)

In [12]: s
Out[12]: 
bar  one   -0.861849
     two   -2.104569
baz  one   -0.494929
     two    1.071804
foo  one    0.721555
     two   -0.706771
qux  one   -1.039575
     two    0.271860
dtype: float64

In [13]: df = pd.DataFrame(np.random.randn(8, 4), index=arrays)

In [14]: df
Out[14]: 
                0         1         2         3
bar one -0.424972  0.567020  0.276232 -1.087401
    two -0.673690  0.113648 -1.478427  0.524988
baz one  0.404705  0.577046 -1.715002 -1.039268
    two -0.370647 -1.157892 -1.344312  0.844885
foo one  1.075770 -0.109050  1.643563 -1.469388
    two  0.357021 -0.674600 -1.776904 -0.968914
qux one -1.294524  0.413738  0.276662 -0.472035
    two -0.013960 -0.362543 -0.006154 -0.923061
```

所有的`MultiIndex`构造器都接受一个`names`参数，用来保存索引中每一层的字符串名称。如果不传入`names`，将被赋值为None。

```Python
In [15]: df.index.names
Out[15]: FrozenList([None, None])
```

索引支持pandas对象的任何轴，索引的级别由你来定。

```Python
In [16]: df = pd.DataFrame(np.random.randn(3, 8), index=['A', 'B', 'C'], columns=index)

In [17]: df
Out[17]: 
first        bar                 baz                 foo                 qux          
second       one       two       one       two       one       two       one       two
A       0.895717  0.805244 -1.206412  2.565646  1.431256  1.340309 -1.170299 -0.226169
B       0.410835  0.813850  0.132003 -0.827317 -0.076467 -1.187678  1.130127 -1.436737
C      -1.413681  1.607920  1.024180  0.569605  0.875906 -2.211372  0.974466 -2.006747

In [18]: pd.DataFrame(np.random.randn(6, 6), index=index[:6], columns=index[:6])
Out[18]: 
first              bar                 baz                 foo          
second             one       two       one       two       one       two
first second                                                            
bar   one    -0.410001 -0.078638  0.545952 -1.219217 -1.226825  0.769804
      two    -1.281247 -0.727707 -0.121306 -0.097883  0.695775  0.341734
baz   one     0.959726 -1.110336 -0.619976  0.149748 -0.732339  0.687738
      two     0.176444  0.403310 -0.154951  0.301624 -2.179861 -1.369849
foo   one    -0.954208  1.462696 -1.743161 -0.826591 -0.345352  1.314232
      two     0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441
```

为了看起来舒服，我们把高级的索引进行了稀疏化。索引如何显示可以通过`pandas.set_options()`设置`multi_sparse`来控制：

```python
In [19]: with pd.option_context('display.multi_sparse', False):
   ....:     df
   ....: 
```

值得记住的是，没有什么能阻止使用元组作为某个轴上的原子标签：

```python
In [20]: pd.Series(np.random.randn(8), index=tuples)
Out[20]: 
(bar, one)   -1.236269
(bar, two)    0.896171
(baz, one)   -0.487602
(baz, two)   -0.082240
(foo, one)   -2.182937
(foo, two)    0.380396
(qux, one)    0.084844
(qux, two)    0.432390
dtype: float64
```

`MultiIndex`之所以重要，是因为它允许我们进行分组、选择和重塑操作（在本章的下面以及文档的后续部分会介绍）。在后面的部分能够看到，你可以使用多层索引而不必显式地创建它。不过，当从一个文件导入数据时，你可能希望生成自己的`MultiIndex`。

##### 13.1.2 重构标签级别

`get_level_values`返回特定级别的每个位置上标签向量。

```python
In [21]: index.get_level_values(0)
Out[21]: Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')

In [22]: index.get_level_values('second')
Out[22]: Index(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'], dtype='object', name='second')
```

##### 13.1.3 `MultiIndex`基本索引方法

 分层索引的一个重要特性是，你可以通过选择能够标识数据的子组的局部标签来选择数据。 局部选择 以完全类似于在常规DataFrame中选择一列的方式降低结果中的分层索引的级别。

```python
In [23]: df['bar']
Out[23]: 
second       one       two
A       0.895717  0.805244
B       0.410835  0.813850
C      -1.413681  1.607920

In [24]: df['bar', 'one']
Out[24]: 
A    0.895717
B    0.410835
C   -1.413681
Name: (bar, one), dtype: float64

In [25]: df['bar']['one']
Out[25]: 
A    0.895717
B    0.410835
C   -1.413681
Name: one, dtype: float64

In [26]: s['qux']
Out[26]: 
one   -1.039575
two    0.271860
dtype: float64
```

通过[分层索引界面](https://pandas.pydata.org/pandas-docs/version/0.23/advanced.html#advanced-xs)来查看如何在深层级别选择数据。

##### 13.1.4 定义（索引）级别

`MultiIndex`的数据类型解释展示了一个索引上所有被定义了的级别，即使它们没有被使用。当对索引切片时，你会注意到这些。例如：

```python
In [27]: df.columns  # original MultiIndex
Out[27]: 
MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],
           labels=[[0, 0, 1, 1, 2, 2, 3, 3], [0, 1, 0, 1, 0, 1, 0, 1]],
           names=['first', 'second'])

In [28]: df[['foo','qux']].columns  # sliced
Out[28]: 
MultiIndex(levels=[['bar', 'baz', 'foo', 'qux'], ['one', 'two']],
           labels=[[2, 2, 3, 3], [0, 1, 0, 1]],
           names=['first', 'second'])
```

这么做避免了对索引级别的重新计算，从而提高了切片的性能。如果你只想看到被使用的（索引）级别，可以使用[`MultiIndex.get_level_values()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.MultiIndex.get_level_values.html#pandas.MultiIndex.get_level_values)方法查看。

```python
In [29]: df[['foo','qux']].columns.values
Out[29]: array([('foo', 'one'), ('foo', 'two'), ('qux', 'one'), ('qux', 'two')], dtype=object)

# for a specific level
In [30]: df[['foo','qux']].columns.get_level_values(0)
Out[30]: Index(['foo', 'foo', 'qux', 'qux'], dtype='object', name='first')
```

如果想用被使用的索引级别重构`MultiIndex`，可以用`remove_unused_level`方法。

0.20.0版新增。

```pyhton
In [31]: df[['foo','qux']].columns.remove_unused_levels()
Out[31]: 
MultiIndex(levels=[['foo', 'qux'], ['one', 'two']],
           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
           names=['first', 'second'])
```

##### 13.1.5 数据对齐，使用`reindex`

轴上有多个索引的不同被索引对象之间的操作将像你期望的那样，数据对齐将像元组索引那样工作。

```python
In [32]: s + s[:-2]
Out[32]: 
bar  one   -1.723698
     two   -4.209138
baz  one   -0.989859
     two    2.143608
foo  one    1.443110
     two   -1.413542
qux  one         NaN
     two         NaN
dtype: float64

In [33]: s + s[::2]
Out[33]: 
bar  one   -1.723698
     two         NaN
baz  one   -0.989859
     two         NaN
foo  one    1.443110
     two         NaN
qux  one   -2.079150
     two         NaN
dtype: float64
```

`reindex`可以使用另一个`MultiIndex`来调用，或者甚至是使用一个列表、数组或元组：

```python
In [34]: s.reindex(index[:3])
Out[34]: 
first  second
bar    one      -0.861849
       two      -2.104569
baz    one      -0.494929
dtype: float64

In [35]: s.reindex([('foo', 'two'), ('bar', 'one'), ('qux', 'one'), ('baz', 'one')])
Out[35]: 
foo  two   -0.706771
bar  one   -0.861849
qux  one   -1.039575
baz  one   -0.494929
dtype: float64
```

#### 13.2 分层索引的高级用法

在高级索引上对`MultiIndex`进行`.loc`语法整合是一个挑战。不过，我们做了所有的努力。通常，MultiIndex键采用元组的方式。例如，下面的示例会像你所想象的那样工作：

```python
In [36]: df = df.T

In [37]: df
Out[37]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [38]: df.loc[('bar', 'two'),]
Out[38]: 
A    0.805244
B    0.813850
C    1.607920
Name: (bar, two), dtype: float64
```

注意，在上面的示例中，`df.loc['bar', 'two']`一样可以工作，但是这种简写容易引起歧义。

如果你想用`.loc`来索引一列，必须像下面这样使用：

```python
In [39]: df.loc[('bar', 'two'), 'A']
Out[39]: 0.80524402538637851
```

你不用通过只想传递元组的第一个元素来指定`MultiIndex`的所有级别。例如，你可以用`df.loc['bar']`来得到`bar`这一列第一个级别的元素。

这是`df.loc[('bar',),]`的一种简写（在这个示例中等价于`df.loc['bar',]`）

"局部"切片也可以优雅的工作：

```python
In [40]: df.loc['baz':'foo']
Out[40]: 
                     A         B         C
first second                              
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
```

你可以通过传入一个元组切片来对一个数据范围进行切片：

```python
In [41]: df.loc[('baz', 'two'):('qux', 'one')]
Out[41]: 
                     A         B         C
first second                              
baz   two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466

In [42]: df.loc[('baz', 'two'):'foo']
Out[42]: 
                     A         B         C
first second                              
baz   two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
```

传入标签列表或元组会像重建索引那样工作：

```python
In [43]: df.loc[[('bar', 'two'), ('qux', 'one')]]
Out[43]: 
                     A         B         C
first second                              
bar   two     0.805244  0.813850  1.607920
qux   one    -1.170299  1.130127  0.974466
```

> 注意：在设计索引时，元组和列表在Pandas中没有被同等对待。元组被解释为一个多级别键，而列表用于指定多个键。或者说，元组是水平的（遍历级别），列表是垂直的（扫描级别）。

重要的，元组的列表索引一些完整的`MultiIndex`键，因为元组的列表指代级别中的一些值：

```python
In [44]: s = pd.Series([1, 2, 3, 4, 5, 6],
   ....:               index=pd.MultiIndex.from_product([["A", "B"], ["c", "d", "e"]]))
   ....: 

In [45]: s.loc[[("A", "c"), ("B", "d")]]  # list of tuples
Out[45]: 
A  c    1
B  d    5
dtype: int64

In [46]: s.loc[(["A", "B"], ["c", "d"])]  # tuple of lists
Out[46]: 
A  c    1
   d    2
B  c    4
   d    5
dtype: int64
```

##### 13.2.1 使用切片器

你可以通过提供多个索引器来对`MultiIndex`切片。

你可以提供任何的选择器，就像根据标签进行索引一样，查看[根据标签选择数据](https://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing-label)，包括切片、标签列表、标签和布尔索引器。

你可以使用`slice(None)`来选择某个级别的所有内容，不必指定所有深层级别，它们将被暗示为`slice(None)`。

通常的，切片器的两边都包含在内，因为这是标签索引。

> 警告：你应该在`.loc`符号中指定所有轴，表示索引器的行和列。 在一些不明确的情况下，传递的索引器可能被错误地解释为对两个轴都进行索引，而不是对行进行多索引 。
>
> 你应该这么用：
>
> ```python
> df.loc[(slice('A1','A3'),.....), :]
> ```
>
> 而不是这样：
>
> ```python
> df.loc[(slice('A1','A3'),.....)]
> ```

```python
In [47]: def mklbl(prefix,n):
   ....:     return ["%s%s" % (prefix,i)  for i in range(n)]
   ....: 

In [48]: miindex = pd.MultiIndex.from_product([mklbl('A',4),
   ....:                                       mklbl('B',2),
   ....:                                       mklbl('C',4),
   ....:                                       mklbl('D',2)])
   ....: 

In [49]: micolumns = pd.MultiIndex.from_tuples([('a','foo'),('a','bar'),
   ....:                                        ('b','foo'),('b','bah')],
   ....:                                       names=['lvl0', 'lvl1'])
   ....: 

In [50]: dfmi = pd.DataFrame(np.arange(len(miindex)*len(micolumns)).reshape((len(miindex),len(micolumns))),
   ....:                     index=miindex,
   ....:                     columns=micolumns).sort_index().sort_index(axis=1)
   ....: 

In [51]: dfmi
Out[51]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0    9    8   11   10
         D1   13   12   15   14
      C2 D0   17   16   19   18
         D1   21   20   23   22
      C3 D0   25   24   27   26
...          ...  ...  ...  ...
A3 B1 C0 D1  229  228  231  230
      C1 D0  233  232  235  234
         D1  237  236  239  238
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  249  248  251  250
         D1  253  252  255  254

[64 rows x 4 columns]
```

基本的使用切片、列表和标签进行多索引切片：

```pyhton
In [52]: dfmi.loc[(slice('A1','A3'), slice(None), ['C1', 'C3']), :]
Out[52]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A1 B0 C1 D0   73   72   75   74
         D1   77   76   79   78
      C3 D0   89   88   91   90
         D1   93   92   95   94
   B1 C1 D0  105  104  107  106
         D1  109  108  111  110
      C3 D0  121  120  123  122
...          ...  ...  ...  ...
A3 B0 C1 D1  205  204  207  206
      C3 D0  217  216  219  218
         D1  221  220  223  222
   B1 C1 D0  233  232  235  234
         D1  237  236  239  238
      C3 D0  249  248  251  250
         D1  253  252  255  254

[24 rows x 4 columns]
```

你可以使用[pandas.IndexSlice](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.IndexSlice.html#pandas.IndexSlice)来使用`:`而不是`slice(None)`获得一种更自然便捷的语法：

```python
In [53]: idx = pd.IndexSlice

In [54]: dfmi.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]
Out[54]: 
lvl0           a    b
lvl1         foo  foo
A0 B0 C1 D0    8   10
         D1   12   14
      C3 D0   24   26
         D1   28   30
   B1 C1 D0   40   42
         D1   44   46
      C3 D0   56   58
...          ...  ...
A3 B0 C1 D1  204  206
      C3 D0  216  218
         D1  220  222
   B1 C1 D0  232  234
         D1  236  238
      C3 D0  248  250
         D1  252  254

[32 rows x 2 columns]
```

使用这个方法可以同时在多个轴上进行非常复杂的选择：

```python
In [55]: dfmi.loc['A1', (slice(None), 'foo')]
Out[55]: 
lvl0        a    b
lvl1      foo  foo
B0 C0 D0   64   66
      D1   68   70
   C1 D0   72   74
      D1   76   78
   C2 D0   80   82
      D1   84   86
   C3 D0   88   90
...       ...  ...
B1 C0 D1  100  102
   C1 D0  104  106
      D1  108  110
   C2 D0  112  114
      D1  116  118
   C3 D0  120  122
      D1  124  126

[16 rows x 2 columns]

In [56]: dfmi.loc[idx[:, :, ['C1', 'C3']], idx[:, 'foo']]
Out[56]: 
lvl0           a    b
lvl1         foo  foo
A0 B0 C1 D0    8   10
         D1   12   14
      C3 D0   24   26
         D1   28   30
   B1 C1 D0   40   42
         D1   44   46
      C3 D0   56   58
...          ...  ...
A3 B0 C1 D1  204  206
      C3 D0  216  218
         D1  220  222
   B1 C1 D0  232  234
         D1  236  238
      C3 D0  248  250
         D1  252  254

[32 rows x 2 columns]
```

使用布尔索引器，你可以提供与值相关的选择：

```python
In [57]: mask = dfmi[('a', 'foo')] > 200

In [58]: dfmi.loc[idx[mask, :, ['C1', 'C3']], idx[:, 'foo']]
Out[58]: 
lvl0           a    b
lvl1         foo  foo
A3 B0 C1 D1  204  206
      C3 D0  216  218
         D1  220  222
   B1 C1 D0  232  234
         D1  236  238
      C3 D0  248  250
         D1  252  254
```

 你还可以指定`.loc`的`axis`参数来解释单个轴上传递的切片器 :

```python
In [59]: dfmi.loc(axis=0)[:, :, ['C1', 'C3']]
Out[59]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C1 D0    9    8   11   10
         D1   13   12   15   14
      C3 D0   25   24   27   26
         D1   29   28   31   30
   B1 C1 D0   41   40   43   42
         D1   45   44   47   46
      C3 D0   57   56   59   58
...          ...  ...  ...  ...
A3 B0 C1 D1  205  204  207  206
      C3 D0  217  216  219  218
         D1  221  220  223  222
   B1 C1 D0  233  232  235  234
         D1  237  236  239  238
      C3 D0  249  248  251  250
         D1  253  252  255  254

[32 rows x 4 columns]
```

另外，你可以用下面的方法设置数值：

```python
In [60]: df2 = dfmi.copy()

In [61]: df2.loc(axis=0)[:, :, ['C1', 'C3']] = -10

In [62]: df2
Out[62]: 
lvl0           a         b     
lvl1         bar  foo  bah  foo
A0 B0 C0 D0    1    0    3    2
         D1    5    4    7    6
      C1 D0  -10  -10  -10  -10
         D1  -10  -10  -10  -10
      C2 D0   17   16   19   18
         D1   21   20   23   22
      C3 D0  -10  -10  -10  -10
...          ...  ...  ...  ...
A3 B1 C0 D1  229  228  231  230
      C1 D0  -10  -10  -10  -10
         D1  -10  -10  -10  -10
      C2 D0  241  240  243  242
         D1  245  244  247  246
      C3 D0  -10  -10  -10  -10
         D1  -10  -10  -10  -10

[64 rows x 4 columns]
```

你也可以使用一个对齐的对象的右侧（来设置数值）：

```python
In [63]: df2 = dfmi.copy()

In [64]: df2.loc[idx[:, :, ['C1', 'C3']], :] = df2 * 1000

In [65]: df2
Out[65]: 
lvl0              a               b        
lvl1            bar     foo     bah     foo
A0 B0 C0 D0       1       0       3       2
         D1       5       4       7       6
      C1 D0    9000    8000   11000   10000
         D1   13000   12000   15000   14000
      C2 D0      17      16      19      18
         D1      21      20      23      22
      C3 D0   25000   24000   27000   26000
...             ...     ...     ...     ...
A3 B1 C0 D1     229     228     231     230
      C1 D0  233000  232000  235000  234000
         D1  237000  236000  239000  238000
      C2 D0     241     240     243     242
         D1     245     244     247     246
      C3 D0  249000  248000  251000  250000
         D1  253000  252000  255000  254000

[64 rows x 4 columns]
```

##### 13.2.2 截面

`DataFrame`的`xs`方法带有一个`level`参数，以使得在`MultiIndex`的特定级别上选择数据更容易：

```python
In [66]: df
Out[66]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
      two     0.805244  0.813850  1.607920
baz   one    -1.206412  0.132003  1.024180
      two     2.565646 -0.827317  0.569605
foo   one     1.431256 -0.076467  0.875906
      two     1.340309 -1.187678 -2.211372
qux   one    -1.170299  1.130127  0.974466
      two    -0.226169 -1.436737 -2.006747

In [67]: df.xs('one', level='second')
Out[67]: 
              A         B         C
first                              
bar    0.895717  0.410835 -1.413681
baz   -1.206412  0.132003  1.024180
foo    1.431256 -0.076467  0.875906
qux   -1.170299  1.130127  0.974466
```

```python
# using the slicers
In [68]: df.loc[(slice(None),'one'),:]
Out[68]: 
                     A         B         C
first second                              
bar   one     0.895717  0.410835 -1.413681
baz   one    -1.206412  0.132003  1.024180
foo   one     1.431256 -0.076467  0.875906
qux   one    -1.170299  1.130127  0.974466
```

你有可以通过传入`axis`参数，用`xs()`来列上进行选择：

```python
In [69]: df = df.T

In [70]: df.xs('one', level='second', axis=1)
Out[70]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466
```

```python
# using the slicers
In [71]: df.loc[:,(slice(None),'one')]
Out[71]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466
```

`xs()`也允许用多个键进行选择：

```python
In [72]: df.xs(('one', 'bar'), level=('second', 'first'), axis=1)
Out[72]: 
first        bar
second       one
A       0.895717
B       0.410835
C      -1.413681
```

```python
# using the slicers
In [73]: df.loc[:,('bar','one')]
Out[73]: 
A    0.895717
B    0.410835
C   -1.413681
Name: (bar, one), dtype: float64
```

传入`drop_level=False`来保留被选择的级别：

```python
In [74]: df.xs('one', level='second', axis=1, drop_level=False)
Out[74]: 
first        bar       baz       foo       qux
second       one       one       one       one
A       0.895717 -1.206412  1.431256 -1.170299
B       0.410835  0.132003 -0.076467  1.130127
C      -1.413681  1.024180  0.875906  0.974466
```

对比`drop_level=True`的情况：

```python
In [75]: df.xs('one', level='second', axis=1, drop_level=True)
Out[75]: 
first       bar       baz       foo       qux
A      0.895717 -1.206412  1.431256 -1.170299
B      0.410835  0.132003 -0.076467  1.130127
C     -1.413681  1.024180  0.875906  0.974466
```

##### 13.2.3 重建索引和数据对齐的高级方法

`reindex`和`align`方法添加了`level`参数，这对于在一个级别上广播数据很有用。下面一个示例：

```python
In [76]: midx = pd.MultiIndex(levels=[['zero', 'one'], ['x','y']],
   ....:                      labels=[[1,1,0,0],[1,0,1,0]])
   ....: 

In [77]: df = pd.DataFrame(np.random.randn(4,2), index=midx)

In [78]: df
Out[78]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [79]: df2 = df.mean(level=0)

In [80]: df2
Out[80]: 
             0         1
one   1.060074 -0.109716
zero  1.271532  0.713416

In [81]: df2.reindex(df.index, level=0)
Out[81]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416

# aligning
In [82]: df_aligned, df2_aligned = df.align(df2, level=0)

In [83]: df_aligned
Out[83]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [84]: df2_aligned
Out[84]: 
               0         1
one  y  1.060074 -0.109716
     x  1.060074 -0.109716
zero y  1.271532  0.713416
     x  1.271532  0.713416
```

##### 13.2.4 使用[`swaplevel()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.MultiIndex.swaplevel.html#pandas.MultiIndex.swaplevel)交换索引级别

`swaplevel`函数可以切换两个级别的顺序：

```python
In [85]: df[:5]
Out[85]: 
               0         1
one  y  1.519970 -0.493662
     x  0.600178  0.274230
zero y  0.132885 -0.023688
     x  2.410179  1.450520

In [86]: df[:5].swaplevel(0, 1, axis=0)
Out[86]: 
               0         1
y one   1.519970 -0.493662
x one   0.600178  0.274230
y zero  0.132885 -0.023688
x zero  2.410179  1.450520
```

##### 13.2.4 使用[`reorder_levels()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.MultiIndex.reorder_levels.html#pandas.MultiIndex.reorder_levels)对索引级别重新排序

`reorder_levels`函数泛化了`swaplevel`函数，允许你一次性排列索引层级：

```python
In [87]: df[:5].reorder_levels([1,0], axis=0)
Out[87]: 
               0         1
y one   1.519970 -0.493662
x one   0.600178  0.274230
y zero  0.132885 -0.023688
x zero  2.410179  1.450520
```

#### 13.3 `MultiIndex`排序

为了让有`MultiIndex`的对象能够高效的索引和切片，`MultiIndex`需要排序。与任何索引一样，你可以使用`sort_index`：

```python
In [88]: import random; random.shuffle(tuples)

In [89]: s = pd.Series(np.random.randn(8), index=pd.MultiIndex.from_tuples(tuples))

In [90]: s
Out[90]: 
qux  two    0.206053
bar  one   -0.251905
foo  one   -2.213588
baz  one    1.063327
qux  one    1.266143
baz  two    0.299368
foo  two   -0.863838
bar  two    0.408204
dtype: float64

In [91]: s.sort_index()
Out[91]: 
bar  one   -0.251905
     two    0.408204
baz  one    1.063327
     two    0.299368
foo  one   -2.213588
     two   -0.863838
qux  one    1.266143
     two    0.206053
dtype: float64

In [92]: s.sort_index(level=0)
Out[92]: 
bar  one   -0.251905
     two    0.408204
baz  one    1.063327
     two    0.299368
foo  one   -2.213588
     two   -0.863838
qux  one    1.266143
     two    0.206053
dtype: float64

In [93]: s.sort_index(level=1)
Out[93]: 
bar  one   -0.251905
baz  one    1.063327
foo  one   -2.213588
qux  one    1.266143
bar  two    0.408204
baz  two    0.299368
foo  two   -0.863838
qux  two    0.206053
dtype: float64
```

如果`MultiIndex`级别被命名，可以传入到`sort_index`中：

```python
In [94]: s.index.set_names(['L1', 'L2'], inplace=True)

In [95]: s.sort_index(level='L1')
Out[95]: 
L1   L2 
bar  one   -0.251905
     two    0.408204
baz  one    1.063327
     two    0.299368
foo  one   -2.213588
     two   -0.863838
qux  one    1.266143
     two    0.206053
dtype: float64

In [96]: s.sort_index(level='L2')
Out[96]: 
L1   L2 
bar  one   -0.251905
baz  one    1.063327
foo  one   -2.213588
qux  one    1.266143
bar  two    0.408204
baz  two    0.299368
foo  two   -0.863838
qux  two    0.206053
dtype: float64
```

在高维对象中，如果轴有多重索引，你可以通过级别排序他们。

```python
In [97]: df.T.sort_index(level=1, axis=1)
Out[97]: 
        one      zero       one      zero
          x         x         y         y
0  0.600178  2.410179  1.519970  0.132885
1  0.274230  1.450520 -0.493662 -0.023688
```

即使数据没有排序，索引也能工作，不过效率不高（会抛出一个`PerformanceWarning`）。这种操作会返回数据的副本，而不是视图。

```python
In [98]: dfm = pd.DataFrame({'jim': [0, 0, 1, 1],
   ....:                     'joe': ['x', 'x', 'z', 'y'],
   ....:                     'jolie': np.random.rand(4)})
   ....: 

In [99]: dfm = dfm.set_index(['jim', 'joe'])

In [100]: dfm
Out[100]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   z    0.537020
    y    0.110968
```

```python
In [4]: dfm.loc[(1, 'z')]
PerformanceWarning: indexing past lexsort depth may impact performance.

Out[4]:
           jolie
jim joe
1   z    0.64094
```

另外，如果尝试索引没有按词法排序的内容，会引发如下的错误：

```python
In [5]: dfm.loc[(0,'y'):(1, 'z')]
UnsortedIndexError: 'Key length (2) was greater than MultiIndex lexsort depth (1)'
```

`Index`的`is_lexsorted`方法会返回该`Index`是否已经排序，`lexsort_depth`属性返回排序的深度：

```python
In [101]: dfm.index.is_lexsorted()
Out[101]: False

In [102]: dfm.index.lexsort_depth
Out[102]: 1
```

```python
In [103]: dfm = dfm.sort_index()

In [104]: dfm
Out[104]: 
            jolie
jim joe          
0   x    0.490671
    x    0.120248
1   y    0.110968
    z    0.537020

In [105]: dfm.index.is_lexsorted()
Out[105]: True

In [106]: dfm.index.lexsort_depth
Out[106]: 2
```

现在，选择操作按照预期执行：

```python
In [107]: dfm.loc[(0,'y'):(1, 'z')]
Out[107]: 
            jolie
jim joe          
1   y    0.110968
    z    0.537020
```

#### 13.4 `take`方法

与Numpy的ndarray类似，Pandas的Index、Series和DataFrame也提供了`take`方法，在给定的索引上演着给定的轴检索元素。给定的索引必须是一个由整数位置组成的列表或ndarray。`take`也接受负整数，表示从索引对象的结尾向前数的位置。

```python
In [108]: index = pd.Index(np.random.randint(0, 1000, 10))

In [109]: index
Out[109]: Int64Index([214, 502, 712, 567, 786, 175, 993, 133, 758, 329], dtype='int64')

In [110]: positions = [0, 9, 3]

In [111]: index[positions]
Out[111]: Int64Index([214, 329, 567], dtype='int64')

In [112]: index.take(positions)
Out[112]: Int64Index([214, 329, 567], dtype='int64')

In [113]: ser = pd.Series(np.random.randn(10))

In [114]: ser.iloc[positions]
Out[114]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64

In [115]: ser.take(positions)
Out[115]: 
0   -0.179666
9    1.824375
3    0.392149
dtype: float64
```

对于DataFrame，给定的索引应该是一个1维的列表或ndarray，指定行列位置：

```python
In [116]: frm = pd.DataFrame(np.random.randn(5, 3))

In [117]: frm.take([1, 4, 3])
Out[117]: 
          0         1         2
1 -1.237881  0.106854 -1.276829
4  0.629675 -1.425966  1.857704
3  0.979542 -1.633678  0.615855

In [118]: frm.take([0, 2], axis=1)
Out[118]: 
          0         2
0  0.595974  0.601544
1 -1.237881 -1.276829
2 -0.767101  1.499591
3  0.979542  0.615855
4  0.629675  1.857704
```

特别需要注意，pandas对象的`take`方法没有计划设计在布尔索引上工作，可能会返回意想不到的结果：

```python
In [119]: arr = np.random.randn(10)

In [120]: arr.take([False, False, True, True])
Out[120]: array([-1.1935, -1.1935,  0.6775,  0.6775])

In [121]: arr[[0, 1]]
Out[121]: array([-1.1935,  0.6775])

In [122]: ser = pd.Series(np.random.randn(10))

In [123]: ser.take([False, False, True, True])
Out[123]: 
0    0.233141
0    0.233141
1   -0.223540
1   -0.223540
dtype: float64

In [124]: ser.iloc[[0, 1]]
Out[124]: 
0    0.233141
1   -0.223540
dtype: float64
```

最后，关于性能的一个小提示是，因为`take`方法处理的输入范围很窄，所以它可以提供比花式索引更好的性能。

#### 13.5 索引类型

 我们在前面几节中已经非常广泛地讨论了`MultiIndex`。这里展示的是`DatetimeIndex`、` PeriodIndex`和`TimedeltaIndex`。

 下面的小节中，我们将重点介绍其他一些索引类型。

##### 13.5.1 类别索引

`CategoricalIndex`是一种支持索引重复值的有用的方法。这是一个`Categorical`的容器， 允许对包含大量重复元素的索引进行有效的索引和存储。

```python
In [125]: from pandas.api.types import CategoricalDtype

In [126]: df = pd.DataFrame({'A': np.arange(6),
   .....:                    'B': list('aabbca')})
   .....: 

In [127]: df['B'] = df['B'].astype(CategoricalDtype(list('cab')))

In [128]: df
Out[128]: 
   A  B
0  0  a
1  1  a
2  2  b
3  3  b
4  4  c
5  5  a

In [129]: df.dtypes
Out[129]: 
A       int64
B    category
dtype: object

In [130]: df.B.cat.categories
Out[130]: Index(['c', 'a', 'b'], dtype='object')
```

设置索引将会创建一个`CategoricalIndex`

```python
In [131]: df2 = df.set_index('B')

In [132]: df2.index
Out[132]: CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')
```

使用`__getitem__`、`.iloc`、`.loc`进行索引的工作方式与具有重复项的`Index`类似。 索引器必须在类别中，否则操作将引发`KeyError`。

```python
In [133]: df2.loc['a']
Out[133]: 
   A
B   
a  0
a  1
a  5
```

索引之后`CategoricalIndex`会被保留

```python
In [134]: df2.loc['a'].index
Out[134]: CategoricalIndex(['a', 'a', 'a'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')
```

对索引排序将按照类别的顺序进行（回想一下，我们用  `CategoricalDtype(list('cab'))` 创建索引，因此排序后为`cab`）

```python
In [135]: df2.sort_index()
Out[135]: 
   A
B   
c  4
a  0
a  1
a  5
b  2
b  3
```

 对索引的Groupby操作也将保留索引的性质.

```python
In [136]: df2.groupby(level=0).sum()
Out[136]: 
   A
B   
c  4
a  6
b  5

In [137]: df2.groupby(level=0).sum().index
Out[137]: CategoricalIndex(['c', 'a', 'b'], categories=['c', 'a', 'b'], ordered=False, name='B', dtype='category')
```

 重新索引操作将根据传递的索引器的类型返回结果索引 。传入一个列表将会返回一个普通的旧索引； 使用`Categorical`索引将返回一个`CategoricalIndex`，根据传入的`Categorical`的dtype进行索引 。这允许你使用不在类别中的值任意索引它们，类似于重新索引任何pandas索引。

```python
In [138]: df2.reindex(['a','e'])
Out[138]: 
     A
B     
a  0.0
a  1.0
a  5.0
e  NaN

In [139]: df2.reindex(['a','e']).index
Out[139]: Index(['a', 'a', 'a', 'e'], dtype='object', name='B')

In [140]: df2.reindex(pd.Categorical(['a','e'],categories=list('abcde')))
Out[140]: 
     A
B     
a  0.0
a  1.0
a  5.0
e  NaN

In [141]: df2.reindex(pd.Categorical(['a','e'],categories=list('abcde'))).index
Out[141]: CategoricalIndex(['a', 'a', 'a', 'e'], categories=['a', 'b', 'c', 'd', 'e'], ordered=False, name='B', dtype='category')
```

> 警告： 对`CategoricalIndex`的变形和比较操作必须具有相同的类别，否则将引发`TypeError`。
>
> ```python
> In [9]: df3 = pd.DataFrame({'A' : np.arange(6),
>                             'B' : pd.Series(list('aabbca')).astype('category')})
> 
> In [11]: df3 = df3.set_index('B')
> 
> In [11]: df3.index
> Out[11]: CategoricalIndex([u'a', u'a', u'b', u'b', u'c', u'a'], categories=[u'a', u'b', u'c'], ordered=False, name=u'B', dtype='category')
> 
> In [12]: pd.concat([df2, df3]
> TypeError: categories must match existing categories when appending
> ```

##### 13.5.2 `Int64Index`和`RangeIndex`

> 警告： 在0.18.0版中已经阐明了使用浮点数对基于整数的索引进行索引，有关该更改的摘要，请参照[此处](https://pandas.pydata.org/pandas-docs/version/0.23/whatsnew.html#whatsnew-0180-float-indexers)。 

`Int64Index`是pandas中的基础索引。这是一个实现了排序、可切片的集合的可变数组。在0.18.0版本之前，`Int64Index` 将为所有`NDFrame`对象提供默认索引。

`RangeIndex`是0.18.0版本添加的`Int64Index`的子类，现在为所有`NDFrame`对象提供默认索引。 `RangeIndex`是`Int64Index`的一个优化版本，它可以表示一个单调有序的集合。这类似于Python的[range类型] (https://docs.python.org/3/library/stdtypes.html#typesseq-range)。

##### 13.5.3 `FloatIndex`

 默认情况下，在创建索引时传递浮点值或混合整数-浮点值时将自动创建一个`Float64Index `，这使得纯粹的基于标签的切片范式在使用`[]`、`ix`和`loc`进行标量索引和切片时工作一样。

```python
In [142]: indexf = pd.Index([1.5, 2, 3, 4.5, 5])

In [143]: indexf
Out[143]: Float64Index([1.5, 2.0, 3.0, 4.5, 5.0], dtype='float64')

In [144]: sf = pd.Series(range(5), index=indexf)

In [145]: sf
Out[145]: 
1.5    0
2.0    1
3.0    2
4.5    3
5.0    4
dtype: int64
```

`[]`j和`.loc`的的标量选择将会一直基于标签。整型索引会匹配相等的浮点型索引（例如：`3`等价于`3.0`）。

```python
In [146]: sf[3]
Out[146]: 2

In [147]: sf[3.0]
Out[147]: 2

In [148]: sf.loc[3]
Out[148]: 2

In [149]: sf.loc[3.0]
Out[149]: 2
```

唯一的位置索引方式是通过`iloc`

```python
In [150]: sf.iloc[3]
Out[150]: 3
```

 当使用`[]`、`ix`、`loc`时，切片主要针对索引的值，而当使用`iloc`时，切片总是基于位置的。当切片是布尔值是会有例外，这种情况下切片总是基于位置的。

```python
In [151]: sf[2:4]
Out[151]: 
2.0    1
3.0    2
dtype: int64

In [152]: sf.loc[2:4]
Out[152]: 
2.0    1
3.0    2
dtype: int64

In [153]: sf.iloc[2:4]
Out[153]: 
3.0    2
4.5    3
dtype: int64
```

 在float索引中，允许使用float进行切片 

```python
In [154]: sf[2.1:4.6]
Out[154]: 
3.0    2
4.5    3
dtype: int64

In [155]: sf.loc[2.1:4.6]
Out[155]: 
3.0    2
4.5    3
dtype: int64
```

在非float索引中，使用float进行切片会触发`TypeError`

```python
In [1]: pd.Series(range(5))[3.5]
TypeError: the label [3.5] is not a proper indexer for this index type (Int64Index)

In [1]: pd.Series(range(5))[3.5:4.5]
TypeError: the slice start [3.5] is not a proper indexer for this index type (Int64Index)
```

> 警告： 在0.18.0版本中已经删除了使用`.iloc`的标量浮点值索引器，因此下面的代码将引发一个`TypeError` 
>
> ```python
> In [3]: pd.Series(range(5)).iloc[3.0]
> TypeError: cannot do positional indexing on <class 'pandas.indexes.range.RangeIndex'> with these indexers [3.0] of <type 'float'>
> ```

这里有一个使用这种类型的索引的典型示例。假设你有一个有点不规则的类似`timedelta`的索引格式，但是数据被记录为浮点值，比如被记录为毫秒偏移量。

```python
In [156]: dfir = pd.concat([pd.DataFrame(np.random.randn(5,2),
   .....:                                index=np.arange(5) * 250.0,
   .....:                                columns=list('AB')),
   .....:                   pd.DataFrame(np.random.randn(6,2),
   .....:                                index=np.arange(4,10) * 250.1,
   .....:                                columns=list('AB'))])
   .....: 

In [157]: dfir
Out[157]: 
               A         B
0.0     0.997289 -1.693316
250.0  -0.179129 -1.598062
500.0   0.936914  0.912560
750.0  -1.003401  1.632781
1000.0 -0.724626  0.178219
1000.4  0.310610 -0.108002
1250.5 -0.974226 -1.147708
1500.6 -2.281374  0.760010
1750.7 -0.742532  1.533318
2000.8  2.495362 -0.432771
2250.9 -0.068954  0.043520
```

所有选择操作，始终将基于值进行。

```python
In [158]: dfir[0:1000.4]
Out[158]: 
               A         B
0.0     0.997289 -1.693316
250.0  -0.179129 -1.598062
500.0   0.936914  0.912560
750.0  -1.003401  1.632781
1000.0 -0.724626  0.178219
1000.4  0.310610 -0.108002

In [159]: dfir.loc[0:1001,'A']
Out[159]: 
0.0       0.997289
250.0    -0.179129
500.0     0.936914
750.0    -1.003401
1000.0   -0.724626
1000.4    0.310610
Name: A, dtype: float64

In [160]: dfir.loc[1000.4]
Out[160]: 
A    0.310610
B   -0.108002
Name: 1000.4, dtype: float64
```

 您可以检索前1秒(1000 ms)的数据 

```python
In [161]: dfir[0:1000]
Out[161]: 
               A         B
0.0     0.997289 -1.693316
250.0  -0.179129 -1.598062
500.0   0.936914  0.912560
750.0  -1.003401  1.632781
1000.0 -0.724626  0.178219
```

如果你需要基于整型的选择操作，应该使用`iloc`

```python
In [162]: dfir.iloc[0:5]
Out[162]: 
               A         B
0.0     0.997289 -1.693316
250.0  -0.179129 -1.598062
500.0   0.936914  0.912560
750.0  -1.003401  1.632781
1000.0 -0.724626  0.178219
```

##### 13.5.4 `IntervalIndex`

0.20.0版本新增。

[`IntervalIndex`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.IntervalIndex.html#pandas.IntervalIndex)和它自己的dtype，`interval`以及[`Interval`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Interval.html#pandas.Interval)标量类型一起，允许在pandas中对区间表示法提供优秀的支持。

 `IntervalIndex`允许一些唯一索引，并且也被用来当做[`cut()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.cut.html#pandas.cut)和[`qcut()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.qcut.html#pandas.qcut)的返回类型。

> 警告： 这些索引行为是暂时的，可能在将来的pandas版本中发生变化。

`IntervalIndex`可以在Series和DataFrame中作为索引。

```python
In [163]: df = pd.DataFrame({'A': [1, 2, 3, 4]},
   .....:                    index=pd.IntervalIndex.from_breaks([0, 1, 2, 3, 4]))
   .....: 

In [164]: df
Out[164]: 
        A
(0, 1]  1
(1, 2]  2
(2, 3]  3
(3, 4]  4
```

使用`.loc`沿着一个间隔的边缘进行基于标签的索引会按照你预期的那样工作：选择那个特定的间隔。

```python
In [165]: df.loc[2]
Out[165]: 
A    2
Name: (1, 2], dtype: int64

In [166]: df.loc[[2, 3]]
Out[166]: 
        A
(1, 2]  2
(2, 3]  3
```

如果你选择了包含在某间隔内的标签，也会选择该间隔。

```python
In [167]: df.loc[2.5]
Out[167]: 
A    3
Name: (2, 3], dtype: int64

In [168]: df.loc[[2.5, 3.5]]
Out[168]: 
        A
(2, 3]  3
(3, 4]  4
```

`Interval`和`IntervalIndex`被用在`cut`和`qcut`中：

```python
In [169]: c = pd.cut(range(4), bins=2)

In [170]: c
Out[170]: 
[(-0.003, 1.5], (-0.003, 1.5], (1.5, 3.0], (1.5, 3.0]]
Categories (2, interval[float64]): [(-0.003, 1.5] < (1.5, 3.0]]

In [171]: c.categories
Out[171]: 
IntervalIndex([(-0.003, 1.5], (1.5, 3.0]]
              closed='right',
              dtype='interval[float64]')
```

另外，`IntervalIndex`允许将其他数据与这些相同的bin进行分割，用NaN表示与其他dtype相似的缺失值。

```python
In [172]: pd.cut([0, 3, 5, 1], bins=c.categories)
Out[172]: 
[(-0.003, 1.5], (1.5, 3.0], NaN, (-0.003, 1.5]]
Categories (2, interval[float64]): [(-0.003, 1.5] < (1.5, 3.0]]
```

##### 13.5.5 生成间隔范围

如果我们需要固定频率的间隔，可以使用[`interval_range()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.interval_range.html#pandas.interval_range)函数使用`start`，`end`和`periods`的各种组合来创建`IntervalIndex`。对于数字区间，默认的间隔频率为为1，对于类似于时间的区间，默认的间隔频率为1天。

```python
In [173]: pd.interval_range(start=0, end=5)
Out[173]: 
IntervalIndex([(0, 1], (1, 2], (2, 3], (3, 4], (4, 5]]
              closed='right',
              dtype='interval[int64]')

In [174]: pd.interval_range(start=pd.Timestamp('2017-01-01'), periods=4)
Out[174]: 
IntervalIndex([(2017-01-01, 2017-01-02], (2017-01-02, 2017-01-03], (2017-01-03, 2017-01-04], (2017-01-04, 2017-01-05]]
              closed='right',
              dtype='interval[datetime64[ns]]')

In [175]: pd.interval_range(end=pd.Timedelta('3 days'), periods=3)
Out[175]: 
IntervalIndex([(0 days 00:00:00, 1 days 00:00:00], (1 days 00:00:00, 2 days 00:00:00], (2 days 00:00:00, 3 days 00:00:00]]
              closed='right',
              dtype='interval[timedelta64[ns]]')
```

`freq`参数用来指定非默认的间隔频率， 并可以利用各种频率别名与日期时间类似的间隔:

```python
In [176]: pd.interval_range(start=0, periods=5, freq=1.5)
Out[176]: 
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0], (6.0, 7.5]]
              closed='right',
              dtype='interval[float64]')

In [177]: pd.interval_range(start=pd.Timestamp('2017-01-01'), periods=4, freq='W')
Out[177]: 
IntervalIndex([(2017-01-01, 2017-01-08], (2017-01-08, 2017-01-15], (2017-01-15, 2017-01-22], (2017-01-22, 2017-01-29]]
              closed='right',
              dtype='interval[datetime64[ns]]')

In [178]: pd.interval_range(start=pd.Timedelta('0 days'), periods=3, freq='9H')
Out[178]: 
IntervalIndex([(0 days 00:00:00, 0 days 09:00:00], (0 days 09:00:00, 0 days 18:00:00], (0 days 18:00:00, 1 days 03:00:00]]
              closed='right',
              dtype='interval[timedelta64[ns]]')
```

另外，`closed`参数用来指定间隔的那一边封闭，默认情况下，间隔的右边封闭：

```python
In [179]: pd.interval_range(start=0, end=4, closed='both')
Out[179]: 
IntervalIndex([[0, 1], [1, 2], [2, 3], [3, 4]]
              closed='both',
              dtype='interval[int64]')

In [180]: pd.interval_range(start=0, end=4, closed='neither')
Out[180]: 
IntervalIndex([(0, 1), (1, 2), (2, 3), (3, 4)]
              closed='neither',
              dtype='interval[int64]')
```

0.23.0版本新增特性。

指定`start`，`end`和`periods`将生成从`start`到`end`（包含`end`）的均匀间隔的范围，在所得的`IntervalIndex`中其周期为`periods`。

```python
In [181]: pd.interval_range(start=0, end=6, periods=4)
Out[181]: 
IntervalIndex([(0.0, 1.5], (1.5, 3.0], (3.0, 4.5], (4.5, 6.0]]
              closed='right',
              dtype='interval[float64]')

In [182]: pd.interval_range(pd.Timestamp('2018-01-01'), pd.Timestamp('2018-02-28'), periods=3)
Out[182]: 
IntervalIndex([(2018-01-01, 2018-01-20 08:00:00], (2018-01-20 08:00:00, 2018-02-08 16:00:00], (2018-02-08 16:00:00, 2018-02-28]]
              closed='right',
              dtype='interval[datetime64[ns]]')
```

#### 13.6 其他关于索引的FAQ

##### 13.6.1 整数索引

带有整数轴标签的基于标签的索引是一个棘手的问题。在邮件列表以及Python社区的大量成员中都进行了广泛的讨论。在Pandas中，我们的普遍观点是，标签比整数位置重要。因此，对于整数轴索引，使用`.loc`这样的标准工具只能进行基于标签的索引。下面的代码将会触发异常：

```python
s = pd.Series(range(5))
s[-1]
df = pd.DataFrame(np.random.randn(5, 4))
df
df.loc[-2:]
```

这样做是为了防止歧义和细微的bug（许多用户报告说，在进行API更改以停止“回退”基于位置的索引时发现了错误）。

##### 13.6.2 非单调索引需要完全匹配

如果`Series`或`DataFrame`的索引是单调递增或递减的，那么基于标签的切片边界可以在索引范围之外，很像是普通的Python列表的索引切片。索引是否单调，可以用`is_monotonic_increasing`和`is_monotonic_decreasing`属性来判断。

```python
In [183]: df = pd.DataFrame(index=[2,3,3,4,5], columns=['data'], data=list(range(5)))

In [184]: df.index.is_monotonic_increasing
Out[184]: True

# no rows 0 or 1, but still returns rows 2, 3 (both of them), and 4:
In [185]: df.loc[0:4, :]
Out[185]: 
   data
2     0
3     1
3     2
4     3

# slice is are outside the index, so empty DataFrame is returned
In [186]: df.loc[13:15, :]
Out[186]: 
Empty DataFrame
Columns: [data]
Index: []
```

另一方面，如果索引不是单调的，那么切片的两个边界必须是索引的唯一成员：

```python
In [187]: df = pd.DataFrame(index=[2,3,1,4,3,5], columns=['data'], data=list(range(6)))

In [188]: df.index.is_monotonic_increasing
Out[188]: False

# OK because 2 and 4 are in the index
In [189]: df.loc[2:4, :]
Out[189]: 
   data
2     0
3     1
1     2
4     3
```

```python
# 0 is not in the index
In [9]: df.loc[0:4, :]
KeyError: 0

# 3 is not a unique label
In [11]: df.loc[2:3, :]
KeyError: 'Cannot get right slice bound for non-unique label: 3'
```

 [`Index.is_monotonic_increasing()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Index.is_monotonic_increasing.html#pandas.Index.is_monotonic_increasing) 和[`Index.is_monotonic_decreasing()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Index.is_monotonic_decreasing.html#pandas.Index.is_monotonic_decreasing) 只是用来检查索引的弱单调性，如果想要检查严格单调性，可以结合 [`Index.is_unique()`](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Index.is_unique.html#pandas.Index.is_unique) 一起使用：

```python
In [190]: weakly_monotonic = pd.Index(['a', 'b', 'c', 'c'])

In [191]: weakly_monotonic
Out[191]: Index(['a', 'b', 'c', 'c'], dtype='object')

In [192]: weakly_monotonic.is_monotonic_increasing
Out[192]: True

In [193]: weakly_monotonic.is_monotonic_increasing & weakly_monotonic.is_unique
Out[193]: False
```

##### 13.6.3 包含结束端点

标准的Python序列切片，结束端点是不含在内的，而Pandas基于标签的切片，结束端点是`包含`在内的。这样做的主要原因是，通常无法轻易确定索引中特定标签之后的“后继”元素或下一个元素。 例如，考虑以下系列：

```python
In [194]: s = pd.Series(np.random.randn(6), index=list('abcdef'))

In [195]: s
Out[195]: 
a    0.112246
b    0.871721
c   -0.816064
d   -0.784880
e    1.030659
f    0.187483
dtype: float64假设我们想要从`c`到`e`的切片，使用整数切片可以这样实现：
```

```python
In [196]: s[2:5]
Out[196]: 
c   -0.816064
d   -0.784880
e    1.030659
dtype: float64
```

但是，如果你只有`c`和`e`，确定索引中的下一个元素可能有些复杂。比如，下面的代码将不能正常工作：

```python
s.loc['c':'e'+1]
```

一个非常常见的用例是将时间序列限定为在两个特定日期开始和结束。为了实现这一点，我们进行了设计，使基于标签的切片包括两个端点：

```python
In [197]: s.loc['c':'e']
Out[197]: 
c   -0.816064
d   -0.784880
e    1.030659
dtype: float64
```

这绝对是“实用性胜过纯粹性”的事情，但是如果你期望基于标签的切片以与标准Python整数切片一样的方式工作，则需要提防这一点。

##### 13.6.4 索引可能偷偷地修改Series dtype

不同的索引操作可能偷偷地修改Series的dtype

```python
In [198]: series1 = pd.Series([1, 2, 3])

In [199]: series1.dtype
Out[199]: dtype('int64')

In [200]: res = series1.reindex([0, 4])

In [201]: res.dtype
Out[201]: dtype('float64')

In [202]: res
Out[202]: 
0    1.0
4    NaN
dtype: float64
```

```python
In [203]: series2 = pd.Series([True])

In [204]: series2.dtype
Out[204]: dtype('bool')

In [205]: res = series2.reindex_like(series1)

In [206]: res.dtype
Out[206]: dtype('O')

In [207]: res
Out[207]: 
0    True
1     NaN
2     NaN
dtype: object
```

这是因为上面的重建索引操作会静默插入`NaN`，并且`dtype`会相应更改。这在使用`numpy ufuncs`时（比如`numpy.logical_and`）会引起一些问题。

到[the old issue](https://github.com/pydata/pandas/issues/2388)查看更多细节讨论。