### 第八章 数据结构介绍

我们将开始一个快速的，非综合性的对Pandas的基础数据结构的概览。数据类型、索引、轴标签/对齐的基本行为适用于所有的对象。一开始，我们在命名空间中引入NumPy和Pandas

```python
In [1]: import NumPy as np

In [2]: import pandas as pd
```

记住一个原则：数据对齐是内在的。除非你明确指定，否则标签和数据之间的联系不会被打破。

我们给出了数据结构的一个简介，然后在单独的小节考虑函数和方法的大的类别。

#### 8.1 Series

[`Series`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.html#pandas.Series)是一个一维的标签化数组，能够保存任何数据类型（整型、字符串、浮点型、Python对象等等）的数据。轴标签统称为索引。创建Series的基本方法：

```python
>>> s = pd.Series(data, index=index)
```

这里，`data`可以是许多不同的事物：

- 一个Python字典
- 一个ndarray（NumPy数组）
- 一个标量（比如5）

传入的`index`是轴标签的列表。所以，按data的不同，这将分为几种情况：

**从ndarray**

如果`data`是ndarray，**index**的长度必须和**data**的长度相同。如果没有传入index，会创建一个默认的值为[0, ..., len(data)-1]的index。

```python
In [3]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [4]: s
Out[4]: 
a    0.4691
b   -0.2829
c   -1.5091
d   -1.1356
e    1.2121
dtype: float64

In [5]: s.index
Out[5]: Index(['a', 'b', 'c', 'd', 'e'], dtype='object')

In [6]: pd.Series(np.random.randn(5))
Out[6]: 
0   -0.1732
1    0.1192
2   -1.0442
3   -0.8618
4   -2.1046
dtype: float64
```

> 注意：Pandas支持不唯一的索引值。如果尝试执行不支持重复索引的操作，会引发异常。懒处理的原因几乎都是基于性能考虑。许多参与计算的实例都不会使用索引，例如GroupBy的一部分。

**从字典**

Series可以从字典实例化

```python
In [7]: d = {'b' : 1, 'a' : 0, 'c' : 2}

In [8]: pd.Series(d)
Out[8]: 
b    1
a    0
c    2
dtype: int64
```

> 注意：当data是一个字典，并且没有传入index时，如果使用的Python版本高于3.6（含）或Pandas版本高于0.23（含），Series的索引会按照字典的插入顺序排序。
>
> 如果使用的Python版本低于3.6或Pandas的版本低于0.23，并且没有传入index，Series的索引会按照字典键的词法顺序排序。

在上面的示例中，如果你使用的Python版本低于3.6或Pandas版本低于0.23，Series会按照字典键的词法顺序排序（["a", "b", "c"]而不是["b", "a", "c"]）。

如果传入了index参数，与索引中的标签对应的数据中的值将被提取出来。

```python
In [9]: d = {'a' : 0., 'b' : 1., 'c' : 2.}

In [10]: pd.Series(d)
Out[10]: 
a    0.0
b    1.0
c    2.0
dtype: float64

In [11]: pd.Series(d, index=['b', 'c', 'd', 'a'])
Out[11]: 
b    1.0
c    2.0
d    NaN
a    0.0
dtype: float64
```

> 注意：NaN（not a number）是Pandas默认表示缺失数据的标记。

**从标量**

如果**data**是标量，必须提供**index**。数据会被复制，以匹配**index**的长度。

```python
In [12]: pd.Series(5., index=['a', 'b', 'c', 'd', 'e'])
Out[12]: 
a    5.0
b    5.0
c    5.0
d    5.0
e    5.0
dtype: float64
```

##### 8.1.1 Series类似于ndarray

Series按照类似于ndarray的方式工作，并且可以作为大多数NumPy函数的合法参数。不过，一些类似切片的操作也同时对索引切片。

```python
In [13]: s[0]
Out[13]: 0.46911229990718628

In [14]: s[:3]
Out[14]: 
a    0.4691
b   -0.2829
c   -1.5091
dtype: float64

In [15]: s[s > s.median()]
Out[15]: 
a    0.4691
e    1.2121
dtype: float64

In [16]: s[[4, 3, 1]]
Out[16]: 
e    1.2121
d   -1.1356
b   -0.2829
dtype: float64

In [17]: np.exp(s)
Out[17]: 
a    1.5986
b    0.7536
c    0.2211
d    0.3212
e    3.3606
dtype: float64
```

我们将在一个[单独的小节](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing)介绍基于数组的索引。

##### 8.1.2 Series类似于字典

Series类似于一个固定大小的字典，你可以通过索引标签获取和设置数据：

```python
In [18]: s['a']
Out[18]: 0.46911229990718628

In [19]: s['e'] = 12.

In [20]: s
Out[20]: 
a     0.4691
b    -0.2829
c    -1.5091
d    -1.1356
e    12.0000
dtype: float64

In [21]: 'e' in s
Out[21]: True

In [22]: 'f' in s
Out[22]: False
```

如果一个标签没有包含在Series之内，将会引发异常

```python
>>> s['f']
KeyError: 'f'
```

使用`get`方法，确实的标签将会返回`None`或指定的默认值

```python
In [23]: s.get('f')

In [24]: s.get('f', np.nan)
Out[24]: nan
```

查看[属性访问](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing-attribute-access)小节，获得更多信息。

##### 8.1.3 矢量化操作，标签对齐

操作原生NumPy数组时，循环操作数值通常是不必要的。操作Pandas的Series也是一样。Series也可以作为参数传入那些参数预期类型是ndarray的方法。

```python
In [25]: s + s
Out[25]: 
a     0.9382
b    -0.5657
c    -3.0181
d    -2.2713
e    24.0000
dtype: float64

In [26]: s * 2
Out[26]: 
a     0.9382
b    -0.5657
c    -3.0181
d    -2.2713
e    24.0000
dtype: float64

In [27]: np.exp(s)
Out[27]: 
a         1.5986
b         0.7536
c         0.2211
d         0.3212
e    162754.7914
dtype: float64
```

Series和ndarray的主要区别是，Series之间的操作会自动按照标签对齐数据。所以，你在编写计算指令时，不需要考虑待处理的Series是不是有相同的标签。

```python
In [28]: s[1:] + s[:-1]
Out[28]: 
a       NaN
b   -0.5657
c   -3.0181
d   -2.2713
e       NaN
dtype: float64
```

没有对齐的Series的操作的结果会合并涉及的索引。如果一个标签没有在所有Series中发现，结果会被标记成确实值NaN。在不做显式数据对齐的情况下编写代码，在交互式数据分析和研究中能够提高自由度和灵活性。Pandas数据结构的综合数据对齐功能，将Pandas与大部分相关的处理标签数据的相关工具区别开来。

> 注意：一般而言，我们在操作不同索引的对象时，将默认结果设为涉及到的索引的并集，以避免丢失数据。有标签，但是数据缺失，作为计算的一部分，也是一种典型的重要信息。你当然可以选择使用**drop**函数丢弃缺失数据的标签。

##### 8.1.4 `name`属性

Series还有一个`name`属性

```python
In [29]: s = pd.Series(np.random.randn(5), name='something')

In [30]: s
Out[30]: 
0   -0.4949
1    1.0718
2    0.7216
3   -0.7068
4   -1.0396
Name: something, dtype: float64

In [31]: s.name
Out[31]: 'something'
```

多数情况下，Series的`name`会被自动赋值，特别是在对DataFrame执行一维切片时，就像下面你将看到的一样。

这是0.18.0版本的新特性。

你可以使用`pandas.Series.rename()`重命名一个Series。

```python
In [32]: s2 = s.rename("different")

In [33]: s2.name
Out[33]: 'different'
```

注意，`s`和`s2`代表不同的对象。

#### 8.2 DataFrame

**DataFrame** 是一个二维标签化的数据结构，包含不同类型的列。你可以将其想象成一个电子表格或SQL表格，或一个有Series对象组成的字典。它是Pandas最常使用的对象。像Series一样，DataFrame接受很多不同种类的输入：

- 一维ndarray组成的字典、列表、字典或Series
- 二维NumPy.ndarray
- [结构化或记录](http://docs.scipy.org/doc/NumPy/user/basics.rec.html)ndarray
- 一个Series
- 另一个DataFrame

传入data的同时，你也可以（可选的）传入**index**（行标签）和**columns**（列标签）参数。如果你传入一个index和（或）columns，你正在为生成的DataFrame指定index和（或）columns。所以，Series字典加上一个特定的index将丢弃所有不匹配传入的index的数据。

如果没有传入轴标签，他们将会根据常识规则从输入的数据中构建。

> 注意：当data是字典，并且没有指定columns时，如果使用的Python版本高于3.6（含）或Pandas版本高于0.23（含），DataFrame的列将会按照字典的插入顺序排序。
>
> 如果使用的Python版本低于3.6或Pandas版本低于0.23，并且没有指定columns，DataFrame的列将会按照字典的键的词法顺序排序。

**从Series的字典或字典的字典**

结果的索引将会是各个Series的索引的并集。如果有嵌套字典，将首先转化为Series。如果没有传入columns，列将会是字典键的排序后的列表。

```python
In [34]: d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),
   ....:      'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}
   ....: 

In [35]: df = pd.DataFrame(d)

In [36]: df
Out[36]: 
   one  two
a  1.0  1.0
b  2.0  2.0
c  3.0  3.0
d  NaN  4.0

In [37]: pd.DataFrame(d, index=['d', 'b', 'a'])
Out[37]: 
   one  two
d  NaN  4.0
b  2.0  2.0
a  1.0  1.0

In [38]: pd.DataFrame(d, index=['d', 'b', 'a'], columns=['two', 'three'])
Out[38]: 
   two three
d  4.0   NaN
b  2.0   NaN
a  1.0   NaN
```

行和列可以分别通过**index**和**columns**属性访问：

> 注意：如果传入data的同时，传入特定的columns集合，传入的columns将会覆盖字典的键。

```python
In [39]: df.index
Out[39]: Index(['a', 'b', 'c', 'd'], dtype='object')

In [40]: df.columns
Out[40]: Index(['one', 'two'], dtype='object')
```

**从ndarray或lists的字典**

所有的ndarray必须有相同的长度。如果传入了index，也必须和ndarray有相同的长度。如果没有传入index，结果中index将会是range(n)，其中n是ndarray的长度。

```python
In [41]: d = {'one' : [1., 2., 3., 4.],
   ....:      'two' : [4., 3., 2., 1.]}
   ....: 

In [42]: pd.DataFrame(d)
Out[42]: 
   one  two
0  1.0  4.0
1  2.0  3.0
2  3.0  2.0
3  4.0  1.0

In [43]: pd.DataFrame(d, index=['a', 'b', 'c', 'd'])
Out[43]: 
   one  two
a  1.0  4.0
b  2.0  3.0
c  3.0  2.0
d  4.0  1.0
```

**从结构化或记录数组**

这种情况的处理方式和数组字典的方式是一样的

```python
In [44]: data = np.zeros((2,), dtype=[('A', 'i4'),('B', 'f4'),('C', 'a10')])

In [45]: data[:] = [(1,2.,'Hello'), (2,3.,"World")]

In [46]: pd.DataFrame(data)
Out[46]: 
   A    B         C
0  1  2.0  b'Hello'
1  2  3.0  b'World'

In [47]: pd.DataFrame(data, index=['first', 'second'])
Out[47]: 
        A    B         C
first   1  2.0  b'Hello'
second  2  3.0  b'World'

In [48]: pd.DataFrame(data, columns=['C', 'A', 'B'])
Out[48]: 
          C  A    B
0  b'Hello'  1  2.0
1  b'World'  2  3.0
```

> 注意：DataFrame并不是像二维NumPy数组那样工作。

**从字典组成的列表**

```python
In [49]: data2 = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]

In [50]: pd.DataFrame(data2)
Out[50]: 
   a   b     c
0  1   2   NaN
1  5  10  20.0

In [51]: pd.DataFrame(data2, index=['first', 'second'])
Out[51]: 
        a   b     c
first   1   2   NaN
second  5  10  20.0

In [52]: pd.DataFrame(data2, columns=['a', 'b'])
Out[52]: 
   a   b
0  1   2
1  5  10
```

**从元组组成的字典**

你可以通过传入元组组成的字典自动创建多级索引的数据框。

```python
In [53]: pd.DataFrame({('a', 'b'): {('A', 'B'): 1, ('A', 'C'): 2},
   ....:               ('a', 'a'): {('A', 'C'): 3, ('A', 'B'): 4},
   ....:               ('a', 'c'): {('A', 'B'): 5, ('A', 'C'): 6},
   ....:               ('b', 'a'): {('A', 'C'): 7, ('A', 'B'): 8},
   ....:               ('b', 'b'): {('A', 'D'): 9, ('A', 'B'): 10}})
   ....: 
Out[53]: 
       a              b      
       b    a    c    a     b
A B  1.0  4.0  5.0  8.0  10.0
  C  2.0  3.0  6.0  7.0   NaN
  D  NaN  NaN  NaN  NaN   9.0
```

**从Series**

结果将会是一个和输入的Series拥有同样的索引的DataFrame，只有一列，列名是原始的Series的名称（当没有提供其他的名字时）。

`缺失数据`

在[缺失数据](http://pandas.pydata.org/pandas-docs/version/0.23/missing_data.html#missing-data)章节将会更多的讨论这个主题。使用包含缺失值的数据构造DataFrame，我们使用`np.nan`来代表缺失值。另一个选择是，你可以为DataFrame构造函数传入一个`NumPy.MaskedArray`作为`data`参数，它的掩蔽条目将会被认为是缺失的。

#### 8.3 其他构造函数 

**DataFrame.from_dict** 

`DataFrame.from_dict`读取字典组成的字典或类似列表的对象组成的字典，返回一个DataFrame。除了将`orient`参数默认置为`columns之外`，它像DataFrame构造函数那样操作，不过也可以将`orient`置为`index`，以便将字典的键作为行标签。

```python
In [54]: pd.DataFrame.from_dict(dict([('A', [1, 2, 3]), ('B', [4, 5, 6])]))
Out[54]: 
   A  B
0  1  4
1  2  5
2  3  6
```

如果传入`orient='index'`，字典的键将会是行标签。这种情况下，你也可以传入期望的列名：

```python
In [55]: pd.DataFrame.from_dict(dict([('A', [1, 2, 3]), ('B', [4, 5, 6])]),
   ....:                        orient='index', columns=['one', 'two', 'three'])
   ....: 
Out[55]: 
   one  two  three
A    1    2      3
B    4    5      6
```

**DataFrame.from_records** 

`DataFrame.from_records `读取由元组组成的列表或有结构化类型的ndarray。除了结果DataFrame的索引可能是结构化类型的一个特定字段之外，它的工作方式和普通的DataFrame构造函数类似。示例：

```python
In [56]: data
Out[56]: 
array([(1,  2., b'Hello'), (2,  3., b'World')],
      dtype=[('A', '<i4'), ('B', '<f4'), ('C', 'S10')])

In [57]: pd.DataFrame.from_records(data, index='C')
Out[57]: 
          A    B
C               
b'Hello'  1  2.0
b'World'  2  3.0
```

#### 8.4 选择，增加，删除列

语义上，你可以把DataFrame看做是一个由类索引的Series对象组成的字典。获取、设置、删除列的语法和类似的字典操作是一样的。

```python
In [58]: df['one']
Out[58]: 
a    1.0
b    2.0
c    3.0
d    NaN
Name: one, dtype: float64

In [59]: df['three'] = df['one'] * df['two']

In [60]: df['flag'] = df['one'] > 2

In [61]: df
Out[61]: 
   one  two  three   flag
a  1.0  1.0    1.0  False
b  2.0  2.0    4.0  False
c  3.0  3.0    9.0   True
d  NaN  4.0    NaN  False
```

可以像操作字典那样删除或取出列

```python
In [62]: del df['two']

In [63]: three = df.pop('three')

In [64]: df
Out[64]: 
   one   flag
a  1.0  False
b  2.0  False
c  3.0   True
d  NaN  False
```

插入一个标量时，将会自然地填充满整列

```python
In [65]: df['foo'] = 'bar'

In [66]: df
Out[66]: 
   one   flag  foo
a  1.0  False  bar
b  2.0  False  bar
c  3.0   True  bar
d  NaN  False  bar
```

插入一个和DataFrame有不同的索引的Series时，将会被统一到DataFrame的索引：

```python
In [67]: df['one_trunc'] = df['one'][:2]

In [68]: df
Out[68]: 
   one   flag  foo  one_trunc
a  1.0  False  bar        1.0
b  2.0  False  bar        2.0
c  3.0   True  bar        NaN
d  NaN  False  bar        NaN
```

你可以插入原生ndarray，但是他们的长度必须匹配DataFrame的索引长度。

默认地，列被插入到尾部。`insert`函数可以指定在特定的位置插入列：

```python
In [69]: df.insert(1, 'bar', df['one'])

In [70]: df
Out[70]: 
   one  bar   flag  foo  one_trunc
a  1.0  1.0  False  bar        1.0
b  2.0  2.0  False  bar        2.0
c  3.0  3.0   True  bar        NaN
d  NaN  NaN  False  bar        NaN
```

#### 8.5 在方法链中赋值新的列

收[dplyr](http://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html#mutate)的`mutate`动词的启发，`DataFrame`有一个[assign()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.assign.html#pandas.DataFrame.assign)方法，它允许你很容易地从现有的列中派生出新的列。

```python
In [71]: iris = pd.read_csv('data/iris.data')

In [72]: iris.head()
Out[72]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name
0          5.1         3.5          1.4         0.2  Iris-setosa
1          4.9         3.0          1.4         0.2  Iris-setosa
2          4.7         3.2          1.3         0.2  Iris-setosa
3          4.6         3.1          1.5         0.2  Iris-setosa
4          5.0         3.6          1.4         0.2  Iris-setosa

In [73]: (iris.assign(sepal_ratio = iris['SepalWidth'] / iris['SepalLength'])
   ....:      .head())
   ....: 
Out[73]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio
0          5.1         3.5          1.4         0.2  Iris-setosa       0.6863
1          4.9         3.0          1.4         0.2  Iris-setosa       0.6122
2          4.7         3.2          1.3         0.2  Iris-setosa       0.6809
3          4.6         3.1          1.5         0.2  Iris-setosa       0.6739
4          5.0         3.6          1.4         0.2  Iris-setosa       0.7200
```

在上面的例子中，我们插入了一个预先计算的数值。我们也可以传入一个单参数的函数，这个函数会在正在赋值的DataFrame上进行计算。

```python
In [74]: iris.assign(sepal_ratio = lambda x: (x['SepalWidth'] /
   ....:                                      x['SepalLength'])).head()
   ....: 
Out[74]: 
   SepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio
0          5.1         3.5          1.4         0.2  Iris-setosa       0.6863
1          4.9         3.0          1.4         0.2  Iris-setosa       0.6122
2          4.7         3.2          1.3         0.2  Iris-setosa       0.6809
3          4.6         3.1          1.5         0.2  Iris-setosa       0.6739
4          5.0         3.6          1.4         0.2  Iris-setosa       0.7200
```

`assign`一直返回数据的拷贝，源数据会保留。

传入一个可调用对象，而不是实际的数值，在你没有DataFrame的引用时非常实用。这在链式操作中很常见。举例而言，我们可以先限制Sepal Length大于5的观察值，计算比率，然后绘图：

```python
In [75]: (iris.query('SepalLength > 5')
   ....:      .assign(SepalRatio = lambda x: x.SepalWidth / x.SepalLength,
   ....:              PetalRatio = lambda x: x.PetalWidth / x.PetalLength)
   ....:      .plot(kind='scatter', x='SepalRatio', y='PetalRatio'))
   ....: 
Out[75]: <matplotlib.axes._subplots.AxesSubplot at 0x1c29ff5b70>
```

![](http://pandas.pydata.org/pandas-docs/version/0.23/_images/basics_assign.png)

函数一旦作为参数传入，会在要赋值的DataFrame上计算。重要的是，这是那个被按Sepal Length大于5的行过滤的DataFrame。首先是过滤，然后计算比率。这里，我们没有过滤后的DataFrame变量的引用。

`assign`的函数签名是简单的`**kwargs`。键，是新的字段的列名；值，要么是一个要插入的值（比如一个Series或NumPy数组），要么是一个DataFrame调用的单参数函数。插入数据之后，返回源数据的一个拷贝。

以下是0.23.0版本之后的一个修改。

Python3.6版本开始，`**kwargs`的顺序被保留。这样可以实现依赖赋值，靠后的`**kwargs`中的表达式可以引用同一个[assign()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.assign.html#pandas.DataFrame.assign)在之前创建的列。

```python
In [76]: dfa = pd.DataFrame({"A": [1, 2, 3],
   ....:                     "B": [4, 5, 6]})
   ....: 

In [77]: dfa.assign(C=lambda x: x['A'] + x['B'],
   ....:            D=lambda x: x['A'] + x['C'])
   ....: 
Out[77]: 
   A  B  C   D
0  1  4  5   6
1  2  5  7   9
2  3  6  9  12
```

在第二个表达式中，`x['C']`将引用新创建的列，等于`dfa['A'] + dfa['B']`。

想要兼容所有版本的Python的话，将赋值操作一分为二：

```python
In [78]: dependent = pd.DataFrame({"A": [1, 1, 1]})

In [79]: (dependent.assign(A=lambda x: x['A'] + 1)
   ....:           .assign(B=lambda x: x['A'] + 2))
   ....: 
Out[79]: 
   A  B
0  2  4
1  2  4
2  2  4
```

> 注意：依赖赋值在Python3.6版本前后之间会有细微的差异。
>
> 如果想要同时支持Python3.6前后的版本，执行赋值操作时需要特别注意：
>
> - 更新现有的列
> - 在同一个assign操作中引用更新后的列
>
> 例如，我们将更新列A，然后在创建列B时引用它：
>
> ```python
> >>> dependent = pd.DataFrame({"A": [1, 1, 1]})
> >>> dependent.assign(A=lambda x: x["A"] + 1,
>                      B=lambda x: x["A"] + 2)
> ```
>
> 对于Python3.5和之前的版本，创建列B的表达式将引用A列的**旧**值，[1, 1, 1]，输出将会是：
>
> ```python
>   A  B
> 0  2  3
> 1  2  3
> 2  2  3
> ```
>
> 对于Python3.6和之后的版本，创建列B（译者注：此处原文有误）的表达式将引用A列的**新**值，[2, 2, 2]，输出将会是：
>
> ```python
>  A  B
> 0  2  4
> 1  2  4
> 2  2  4
> ```

#### 8.6 索引/选择

索引的基本语法如下表：

| 操作               | 语法          | 结果      |
| ------------------ | ------------- | --------- |
| 选择一列           | df[col]       | Series    |
| 按标签选择一行     | df.loc[label] | Series    |
| 按整数位置选择一行 | df.iloc[loc]  | Series    |
| 行切片             | df[5:10]      | DataFrame |
| 按布尔向量选择行   | df[bool_vec]  | DataFrame |

选取行，将会返回一个Series，这个Series的索引是DataFrame的列。

```python
In [80]: df.loc['b']
Out[80]: 
one              2
bar              2
flag         False
foo            bar
one_trunc        2
Name: b, dtype: object

In [81]: df.iloc[2]
Out[81]: 
one             3
bar             3
flag         True
foo           bar
one_trunc     NaN
Name: c, dtype: object
```

获得更详尽的处理基于复杂标签的索引和切片的信息，请查看[索引](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing)章节，我们将会在该章节介绍在新的标签集上重建索引或确保一致的基本原理。

##### 8.6.1 数据对齐和算术运算

DataFrame对象之间的数据对齐自动对齐在列和索引（行标签）上。再一次，结果对象将会包含列和行标签的并集。

```python
In [82]: df = pd.DataFrame(np.random.randn(10, 4), columns=['A', 'B', 'C', 'D'])

In [83]: df2 = pd.DataFrame(np.random.randn(7, 3), columns=['A', 'B', 'C'])

In [84]: df + df2
Out[84]: 
        A       B       C   D
0  0.0457 -0.0141  1.3809 NaN
1 -0.9554 -1.5010  0.0372 NaN
2 -0.6627  1.5348 -0.8597 NaN
3 -2.4529  1.2373 -0.1337 NaN
4  1.4145  1.9517 -2.3204 NaN
5 -0.4949 -1.6497 -1.0846 NaN
6 -1.0476 -0.7486 -0.8055 NaN
7     NaN     NaN     NaN NaN
8     NaN     NaN     NaN NaN
9     NaN     NaN     NaN NaN
```

当在DataFrame和Series之间操作时，默认的处理方式是，将Series的索引对齐到DataFrame的列上，因此将会进行行式[广播](http://docs.scipy.org/doc/NumPy/user/basics.broadcasting.html)。比如：

```python
In [85]: df - df.iloc[0]
Out[85]: 
        A       B       C       D
0  0.0000  0.0000  0.0000  0.0000
1 -1.3593 -0.2487 -0.4534 -1.7547
2  0.2531  0.8297  0.0100 -1.9912
3 -1.3111  0.0543 -1.7249 -1.6205
4  0.5730  1.5007 -0.6761  1.3673
5 -1.7412  0.7820 -1.2416 -2.0531
6 -1.2408 -0.8696 -0.1533  0.0004
7 -0.7439  0.4110 -0.9296 -0.2824
8 -1.1949  1.3207  0.2382 -1.4826
9  2.2938  1.8562  0.7733 -1.4465
```

特别地，当处理时间序列数据，并且DataFrame的索引也包含日期时，广播方式将会是列式的：

```python
In [86]: index = pd.date_range('1/1/2000', periods=8)

In [87]: df = pd.DataFrame(np.random.randn(8, 3), index=index, columns=list('ABC'))

In [88]: df
Out[88]: 
                 A       B       C
2000-01-01 -1.2268  0.7698 -1.2812
2000-01-02 -0.7277 -0.1213 -0.0979
2000-01-03  0.6958  0.3417  0.9597
2000-01-04 -1.1103 -0.6200  0.1497
2000-01-05 -0.7323  0.6877  0.1764
2000-01-06  0.4033 -0.1550  0.3016
2000-01-07 -2.1799 -1.3698 -0.9542
2000-01-08  1.4627 -1.7432 -0.8266

In [89]: type(df['A'])
Out[89]: pandas.core.series.Series

In [90]: df - df['A']
Out[90]: 
            2000-01-01 00:00:00  2000-01-02 00:00:00  2000-01-03 00:00:00  \
2000-01-01                  NaN                  NaN                  NaN   
2000-01-02                  NaN                  NaN                  NaN   
2000-01-03                  NaN                  NaN                  NaN   
2000-01-04                  NaN                  NaN                  NaN   
2000-01-05                  NaN                  NaN                  NaN   
2000-01-06                  NaN                  NaN                  NaN   
2000-01-07                  NaN                  NaN                  NaN   
2000-01-08                  NaN                  NaN                  NaN   

            2000-01-04 00:00:00 ...  2000-01-08 00:00:00   A   B   C  
2000-01-01                  NaN ...                  NaN NaN NaN NaN  
2000-01-02                  NaN ...                  NaN NaN NaN NaN  
2000-01-03                  NaN ...                  NaN NaN NaN NaN  
2000-01-04                  NaN ...                  NaN NaN NaN NaN  
2000-01-05                  NaN ...                  NaN NaN NaN NaN  
2000-01-06                  NaN ...                  NaN NaN NaN NaN  
2000-01-07                  NaN ...                  NaN NaN NaN NaN  
2000-01-08                  NaN ...                  NaN NaN NaN NaN  

[8 rows x 11 columns]
```

> 注意：
>
> ```python
> df - df['A']
> ```
>
> 现在被弃用了，未来也将会移除。这种操作的首选方法是：
>
> ```python
> df.sub(df['A'], axis=0)
> ```

获得显示地控制匹配和广播行为的知识，请查看灵活的[二元操作](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-binop)章节。

常量操作会和你预期的一样：

```python
In [91]: df * 5 + 2
Out[91]: 
                 A       B       C
2000-01-01 -4.1341  5.8490 -4.4062
2000-01-02 -1.6385  1.3935  1.5106
2000-01-03  5.4789  3.7087  6.7986
2000-01-04 -3.5517 -1.0999  2.7487
2000-01-05 -1.6617  5.4387  2.8822
2000-01-06  4.0165  1.2252  3.5081
2000-01-07 -8.8993 -4.8492 -2.7710
2000-01-08  9.3135 -6.7158 -2.1330

In [92]: 1 / df
Out[92]: 
                 A       B        C
2000-01-01 -0.8151  1.2990  -0.7805
2000-01-02 -1.3742 -8.2436 -10.2163
2000-01-03  1.4372  2.9262   1.0420
2000-01-04 -0.9006 -1.6130   6.6779
2000-01-05 -1.3655  1.4540   5.6675
2000-01-06  2.4795 -6.4537   3.3154
2000-01-07 -0.4587 -0.7300  -1.0480
2000-01-08  0.6837 -0.5737  -1.2098

In [93]: df ** 4
Out[93]: 
                  A       B           C
2000-01-01   2.2653  0.3512  2.6948e+00
2000-01-02   0.2804  0.0002  9.1796e-05
2000-01-03   0.2344  0.0136  8.4838e-01
2000-01-04   1.5199  0.1477  5.0286e-04
2000-01-05   0.2876  0.2237  9.6924e-04
2000-01-06   0.0265  0.0006  8.2769e-03
2000-01-07  22.5795  3.5212  8.2903e-01
2000-01-08   4.5774  9.2332  4.6683e-01
```

布尔操作也是一样：

```python
In [94]: df1 = pd.DataFrame({'a' : [1, 0, 1], 'b' : [0, 1, 1] }, dtype=bool)

In [95]: df2 = pd.DataFrame({'a' : [0, 1, 1], 'b' : [1, 1, 0] }, dtype=bool)

In [96]: df1 & df2
Out[96]: 
       a      b
0  False  False
1  False   True
2   True  False

In [97]: df1 | df2
Out[97]: 
      a     b
0  True  True
1  True  True
2  True  True

In [98]: df1 ^ df2
Out[98]: 
       a      b
0   True   True
1   True  False
2  False   True

In [99]: -df1
Out[99]: 
       a      b
0  False   True
1   True  False
2  False  False
```

##### 8.6.2 转置

使用T属性转置（同时也是`tranpose`函数），类似于`ndarray`:

```python
# only show the first 5 rows
In [100]: df[:5].T
Out[100]: 
   2000-01-01  2000-01-02  2000-01-03  2000-01-04  2000-01-05
A     -1.2268     -0.7277      0.6958     -1.1103     -0.7323
B      0.7698     -0.1213      0.3417     -0.6200      0.6877
C     -1.2812     -0.0979      0.9597      0.1497      0.1764
```

##### 8.6.3 DataFrame和NumPy函数的互操作性 

当操作的数据是数值型时，NumPy的全局的元素操作函数（log，exp，sqrt等）和许多其他的NumPy函数都可以在DataFrame中使用。

```python
In [101]: np.exp(df)
Out[101]: 
                 A       B       C
2000-01-01  0.2932  2.1593  0.2777
2000-01-02  0.4830  0.8858  0.9068
2000-01-03  2.0053  1.4074  2.6110
2000-01-04  0.3294  0.5380  1.1615
2000-01-05  0.4808  1.9892  1.1930
2000-01-06  1.4968  0.8565  1.3521
2000-01-07  0.1131  0.2541  0.3851
2000-01-08  4.3176  0.1750  0.4375

In [102]: np.asarray(df)
Out[102]: 
array([[-1.2268,  0.7698, -1.2812],
       [-0.7277, -0.1213, -0.0979],
       [ 0.6958,  0.3417,  0.9597],
       [-1.1103, -0.62  ,  0.1497],
       [-0.7323,  0.6877,  0.1764],
       [ 0.4033, -0.155 ,  0.3016],
       [-2.1799, -1.3698, -0.9542],
       [ 1.4627, -1.7432, -0.8266]])
```

DataFrame的`dot`方法实现了矩阵乘法：

```python
In [103]: df.T.dot(df)
Out[103]: 
         A       B       C
A  11.3419 -0.0598  3.0080
B  -0.0598  6.5206  2.0833
C   3.0080  2.0833  4.3105
```

类似地，Series的`dot`方法实现了点积：

```python
In [104]: s1 = pd.Series(np.arange(5,10))

In [105]: s1.dot(s1)
Out[105]: 255
```

DataFrame并不打算取代ndarray，因为它的索引方法从语义上来说与矩阵是完全不同的。

##### 8.6.4 控制台显示

太大的DataFrame将会被截断以便在控制台显示。你也可以通过[info()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.info.html#pandas.DataFrame.info)得到数据概要。（这里，我从**plyr** R包中读取了一个CSV版本的**棒球**数据）

```python
In [106]: baseball = pd.read_csv('data/baseball.csv')

In [107]: print(baseball)
       id     player  year  stint  ...   hbp   sh   sf  gidp
0   88641  womacto01  2006      2  ...   0.0  3.0  0.0   0.0
1   88643  schilcu01  2006      1  ...   0.0  0.0  0.0   0.0
..    ...        ...   ...    ...  ...   ...  ...  ...   ...
98  89533   aloumo01  2007      1  ...   2.0  0.0  3.0  13.0
99  89534  alomasa02  2007      1  ...   0.0  0.0  0.0   0.0

[100 rows x 23 columns]

In [108]: baseball.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 100 entries, 0 to 99
Data columns (total 23 columns):
id        100 non-null int64
player    100 non-null object
year      100 non-null int64
stint     100 non-null int64
team      100 non-null object
lg        100 non-null object
g         100 non-null int64
ab        100 non-null int64
r         100 non-null int64
h         100 non-null int64
X2b       100 non-null int64
X3b       100 non-null int64
hr        100 non-null int64
rbi       100 non-null float64
sb        100 non-null float64
cs        100 non-null float64
bb        100 non-null int64
so        100 non-null float64
ibb       100 non-null float64
hbp       100 non-null float64
sh        100 non-null float64
sf        100 non-null float64
gidp      100 non-null float64
dtypes: float64(9), int64(11), object(3)
memory usage: 18.0+ KB
```

不过，使用`to_string`将会以表格形式返回DataFrame的字符串表示，但不是总能匹配控制台宽度。

```python
In [109]: print(baseball.iloc[-20:, :12].to_string())
       id     player  year  stint team  lg    g   ab   r    h  X2b  X3b
80  89474  finlest01  2007      1  COL  NL   43   94   9   17    3    0
81  89480  embreal01  2007      1  OAK  AL    4    0   0    0    0    0
82  89481  edmonji01  2007      1  SLN  NL  117  365  39   92   15    2
83  89482  easleda01  2007      1  NYN  NL   76  193  24   54    6    0
84  89489  delgaca01  2007      1  NYN  NL  139  538  71  139   30    0
85  89493  cormirh01  2007      1  CIN  NL    6    0   0    0    0    0
86  89494  coninje01  2007      2  NYN  NL   21   41   2    8    2    0
87  89495  coninje01  2007      1  CIN  NL   80  215  23   57   11    1
88  89497  clemero02  2007      1  NYA  AL    2    2   0    1    0    0
89  89498  claytro01  2007      2  BOS  AL    8    6   1    0    0    0
90  89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0
91  89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0
92  89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2
93  89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0
94  89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3
95  89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0
96  89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0
97  89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3
98  89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1
99  89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0
```

默认地，宽的DataFrame将会跨多行显示：

```python
In [110]: pd.DataFrame(np.random.randn(3, 12))
Out[110]: 
         0         1         2         3         4         5         6         7         8         9         10        11
0 -0.345352  1.314232  0.690579  0.995761  2.396780  0.014871  3.357427 -0.317441 -1.236269  0.896171 -0.487602 -0.082240
1 -2.182937  0.380396  0.084844  0.432390  1.519970 -0.493662  0.600178  0.274230  0.132885 -0.023688  2.410179  1.450520
2  0.206053 -0.251905 -2.213588  1.063327  1.266143  0.299368 -0.863838  0.408204 -1.048089 -0.025747 -0.988387  0.094055
```

你可以通过设置`display.width `来改变一行显示多少：

```python
In [111]: pd.set_option('display.width', 40) # default is 80

In [112]: pd.DataFrame(np.random.randn(3, 12))
Out[112]: 
         0         1         2         3         4         5         6         7         8         9         10        11
0  1.262731  1.289997  0.082423 -0.055758  0.536580 -0.489682  0.369374 -0.034571 -2.484478 -0.281461  0.030711  0.109121
1  1.126203 -0.977349  1.474071 -0.064034 -1.282782  0.781836 -1.071357  0.441153  2.353925  0.583787  0.221471 -0.744471
2  0.758527  1.729689 -0.964980 -0.845696 -1.340896  1.846883 -1.328865  1.682706 -1.717693  0.888782  0.228440  0.901805
```

可以通过设置`display.max_colwidth `来调整一列的最大宽度：

```python
In [113]: datafile={'filename': ['filename_01','filename_02'],
   .....:           'path': ["media/user_name/storage/folder_01/filename_01",
   .....:                    "media/user_name/storage/folder_02/filename_02"]}
   .....: 

In [114]: pd.set_option('display.max_colwidth',30)

In [115]: pd.DataFrame(datafile)
Out[115]: 
      filename                           path
0  filename_01  media/user_name/storage/fo...
1  filename_02  media/user_name/storage/fo...

In [116]: pd.set_option('display.max_colwidth',100)

In [117]: pd.DataFrame(datafile)
Out[117]: 
      filename                                           path
0  filename_01  media/user_name/storage/folder_01/filename_01
1  filename_02  media/user_name/storage/folder_02/filename_02
```

也可以通过设置`expand_frame_repr` 来禁用这个特性，这将把表格打印在一个块中。

##### 8.6.5 DataFrame列属性访问和IPython自动完成

如果DataFrame的列标签是合法的Python变量名，列可以通过类似于属性的方式访问：

译者注：这里所说的`合法`主要是指不要使用Python关键字（比如`sum`等）作为列名，否则无法使用`.`操作。

```python
In [118]: df = pd.DataFrame({'foo1' : np.random.randn(5),
   .....:                    'foo2' : np.random.randn(5)})
   .....: 

In [119]: df
Out[119]: 
       foo1      foo2
0  1.171216 -0.858447
1  0.520260  0.306996
2 -1.197071 -0.028665
3 -1.066969  0.384316
4 -0.303421  1.574159

In [120]: df.foo1
Out[120]: 
0    1.171216
1    0.520260
2   -1.197071
3   -1.066969
4   -0.303421
Name: foo1, dtype: float64
```

列与IPython的完成机制相连接，所以可以通过`tab`自动完成：

```python
In [5]: df.fo<TAB>
df.foo1  df.foo2
```

#### 8.7 Panel

> 注意：在0.20版本中，Panel被弃用了，将来也会被移除。查看[弃用Panel](http://pandas.pydata.org/pandas-docs/version/0.23/dsintro.html#dsintro-deprecate-panel)部分。

从略。