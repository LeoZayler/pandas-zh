### 第九章 基本功能

本章我们将讨论很多Pandas数据结构的基本功能。下面是如何创建前面几章示例中用到的对象：

```python
In [1]: index = pd.date_range('1/1/2000', periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index,
   ...:                   columns=['A', 'B', 'C'])
   ...: 

In [4]: wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
   ...:               major_axis=pd.date_range('1/1/2000', periods=5),
   ...:               minor_axis=['A', 'B', 'C', 'D'])
   ...: 
```

#### 9.1 Head 和Tail

可以通过head()和tail()方法查看Series或DataFrame的一个小样本。默认显示的元素个数是5，可以传入自定义的数值：

```python
In [5]: long_series = pd.Series(np.random.randn(1000))

In [6]: long_series.head()
Out[6]: 
0    0.229453
1    0.304418
2    0.736135
3   -0.859631
4   -0.424100
dtype: float64

In [7]: long_series.tail(3)
Out[7]: 
997   -0.351587
998    1.136249
999   -0.448789
dtype: float64
```

#### 9.2 属性和原生ndarray

Pandas对象拥有许多属性，你可以通过这些属性访问元数据。

- shape：给出对象的维度，和ndarray是一致的。
- 轴标签
  - Series：索引（只有轴）
  - DataFrame：索引（行）和列
  - Panel：项目，最大轴和最小轴

注意，这些属性可以安全的赋值。

```python
In [8]: df[:2]
Out[8]: 
                   A         B        C
2000-01-01  0.048869 -1.360687 -0.47901
2000-01-02 -0.859661 -0.231595 -0.52775

In [9]: df.columns = [x.lower() for x in df.columns]

In [10]: df
Out[10]: 
                   a         b         c
2000-01-01  0.048869 -1.360687 -0.479010
2000-01-02 -0.859661 -0.231595 -0.527750
2000-01-03 -1.296337  0.150680  0.123836
2000-01-04  0.571764  1.555563 -0.823761
2000-01-05  0.535420 -1.032853  1.469725
2000-01-06  1.304124  1.449735  0.203109
2000-01-07 -1.032011  0.969818 -0.962723
2000-01-08  1.382083 -0.938794  0.669142
```

获得数据结构中的数，只需要通过**values**属性：

```python
In [11]: s.values
Out[11]: array([-1.9339,  0.3773,  0.7341,  2.1416, -0.0112])

In [12]: df.values
Out[12]: 
array([[ 0.0489, -1.3607, -0.479 ],
       [-0.8597, -0.2316, -0.5278],
       [-1.2963,  0.1507,  0.1238],
       [ 0.5718,  1.5556, -0.8238],
       [ 0.5354, -1.0329,  1.4697],
       [ 1.3041,  1.4497,  0.2031],
       [-1.032 ,  0.9698, -0.9627],
       [ 1.3821, -0.9388,  0.6691]])

In [13]: wp.values
Out[13]: 
array([[[-0.4336, -0.2736,  0.6804, -0.3084],
        [-0.2761, -1.8212, -1.9936, -1.9274],
        [-2.0279,  1.625 ,  0.5511,  3.0593],
        [ 0.4553, -0.0307,  0.9357,  1.0612],
        [-2.1079,  0.1999,  0.3236, -0.6416]],

       [[-0.5875,  0.0539,  0.1949, -0.382 ],
        [ 0.3186,  2.0891, -0.7283, -0.0903],
        [-0.7482,  1.3189, -2.0298,  0.7927],
        [ 0.461 , -0.5427, -0.3054, -0.4792],
        [ 0.095 , -0.2701, -0.7071, -0.7739]]])
```

如果一个DataFrame或Panel包含相同类型的数据，ndarray实际上可以就地修改，并且这些修改将会反映到数据结构中。对于不同类型的数据，例如DataFrame的一些列的数据类型不同，将不是这样。**values**属性本身不能被赋值，这与轴标签不同。

> 注意：当面对不同类型的数据时，结果的类型将会选择最大限度容纳所有数据的那个。例如，如果涉及到字符串，结果将会是object类型。如果只有浮点型数据和整型数据，结果将会是浮点型。

#### 9.3 加速操作

Pandas支持使用`numexpr`库和`bottleneck`库来加速某些类型的二进制数字和布尔操作。

这两个库在处理大型数据是格外有用，能够大幅提升速度。`numexpr`  使用智能分块、缓存和多核技术。`bottleneck`  是一系列专门的cython例程，这些例程在处理包含`nan`的数组时特别快。

这里有一个示例（使用100行100列的DataFrame）：

| 操作        | 0.11.0 版(ms) | 之前的版本 (ms) | 0.11版占之前版本的比例 |
| ----------- | ------------- | --------------- | ---------------------- |
| `df1 > df2` | 13.32         | 125.35          | 0.1063                 |
| `df1 * df2` | 21.71         | 36.63           | 0.5928                 |
| `df1 + df2` | 22.04         | 36.50           | 0.6039                 |

我们特别鼓励安装这两个库。查看[推荐依赖](http://pandas.pydata.org/pandas-docs/version/0.23/install.html#install-recommended-dependencies)，获得更多的安装信息。

这两个库默认使用，你可以通过设置选项控制是否使用：

```python
pd.set_option('compute.use_bottleneck', False)
pd.set_option('compute.use_numexpr', False)
```

#### 9.4 灵活的二进制操作

在Pandas数据结构中使用二进制操作时，有两点我们比较关心：

- 高维数据结构（DataFrame）和低维数据结构（Series）之间的广播方式。
- 缺失数据如何计算。

我们将展示如何独立地处理这两个问题，不过它们可以同时处理。

##### 9.4.1 匹配/广播行为

DataFrame有一些执行二进制运算的方法：[add()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.add.html#pandas.DataFrame.add)、[sub()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sub.html#pandas.DataFrame.sub)、[mul()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.mul.html#pandas.DataFrame.mul)、[div()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.div.html#pandas.DataFrame.div)和相关的[radd()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.radd.html#pandas.DataFrame.radd)、[rsub()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub)等。广播行为对Series的输入更感兴趣。使用这些函数，你可以通过**axis**关键字在索引和列上做匹配。

```python
In [14]: df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),
   ....:                    'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),
   ....:                    'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})
   ....: 

In [15]: df
Out[15]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [16]: row = df.iloc[1]

In [17]: column = df['two']

In [18]: df.sub(row, axis='columns')
Out[18]: 
        one       two     three
a -0.924269 -1.362632       NaN
b  0.000000  0.000000  0.000000
c  0.639504 -2.973170  2.565487
d       NaN -2.943392 -0.588625

In [19]: df.sub(row, axis=1)
Out[19]: 
        one       two     three
a -0.924269 -1.362632       NaN
b  0.000000  0.000000  0.000000
c  0.639504 -2.973170  2.565487
d       NaN -2.943392 -0.588625

In [20]: df.sub(column, axis='index')
Out[20]: 
        one  two     three
a -2.226031  0.0       NaN
b -2.664393  0.0 -3.121397
c  0.948280  0.0  2.417260
d       NaN  0.0 -0.766631

In [21]: df.sub(column, axis=0)
Out[21]: 
        one  two     three
a -2.226031  0.0       NaN
b -2.664393  0.0 -3.121397
c  0.948280  0.0  2.417260
d       NaN  0.0 -0.766631
```

更进一步，你也可以将一个多级索引的DataFrame的一个等级与一个Series对齐

```python
In [22]: dfmi = df.copy()

In [23]: dfmi.index = pd.MultiIndex.from_tuples([(1,'a'),(1,'b'),(1,'c'),(2,'a')],
   ....:                                        names=['first','second'])
   ....: 

In [24]: dfmi.sub(column, axis=0, level='second')
Out[24]: 
                   one      two     three
first second                             
1     a      -2.226031  0.00000       NaN
      b      -2.664393  0.00000 -3.121397
      c       0.948280  0.00000  2.417260
2     a            NaN -1.58076 -2.347391
```

对于Panel来说，描述广播行为有一点困难，所以算术方法让你来指定广播的轴（可能更加令人难以理解？）。例如，假设我们希望将一个特定的轴上的数据去均值化。这可以通过将这个轴上的数值的平均值在该轴上广播来实现：

```python
In [25]: major_mean = wp.mean(axis='major')

In [26]: major_mean
Out[26]: 
      Item1     Item2
A -0.878036 -0.092218
B -0.060128  0.529811
C  0.099453 -0.715139
D  0.248599 -0.186535

In [27]: wp.sub(major_mean, axis='major')
Out[27]: 
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: Item1 to Item2
Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00
Minor_axis axis: A to D
```

`axis="items"` 和`axis="minor"` 类似。

> 注意：我可以确定，DataFrame中的**axis**参数能够匹配Panel中的广播行为。尽管这需要一个过渡期，以便用户可以修改他们的代码...

Series和Index也支持[divmod()](https://docs.python.org/3/library/functions.html#divmod)内置函数。这个函数同时接受向下取整除法和取模操作，返回一个与左边相同类型的双元组。例如：

```python
In [28]: s = pd.Series(np.arange(10))

In [29]: s
Out[29]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [30]: div, rem = divmod(s, 3)

In [31]: div
Out[31]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [32]: rem
Out[32]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [33]: idx = pd.Index(np.arange(10))

In [34]: idx
Out[34]: Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [35]: div, rem = divmod(idx, 3)

In [36]: div
Out[36]: Int64Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [37]: rem
Out[37]: Int64Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')
```

我们也可以按元素执行[divmod()](https://docs.python.org/3/library/functions.html#divmod)：

```python
In [38]: div, rem = divmod(s, [2, 2, 3, 3, 4, 4, 5, 5, 6, 6])

In [39]: div
Out[39]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    1
7    1
8    1
9    1
dtype: int64

In [40]: rem
Out[40]: 
0    0
1    1
2    2
3    0
4    0
5    1
6    1
7    2
8    2
9    3
dtype: int64
```

##### 9.4.2 缺失数据/操作填充值

在Series和DataFrame中，算术函数有一个输入`fill_value`的选项，也就是说，一个位置上只要有数据缺失就会被替换。例如，当把两个DataFrame相加时，你可能希望把NaN处理成0，当两个DataFrame都缺失了那个数据时才处理成NaN（如果你愿意，你可以在后面使用`fillna`把NaN替换为其他的数值）

```python
In [41]: df
Out[41]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [42]: df2
Out[42]: 
        one       two     three
a -1.101558  1.124472  1.000000
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [43]: df + df2
Out[43]: 
        one       two     three
a -2.203116  2.248945       NaN
b -0.354579  4.974208 -1.268586
c  0.924429 -0.972131  3.862388
d       NaN -0.912575 -2.445837

In [44]: df.add(df2, fill_value=0)
Out[44]: 
        one       two     three
a -2.203116  2.248945  1.000000
b -0.354579  4.974208 -1.268586
c  0.924429 -0.972131  3.862388
d       NaN -0.912575 -2.445837
```

##### 9.4.3 灵活的对比

Series和DataFrame有一些二进制对比方法`eq`， `ne`， `lt`，`gt`，`le`和`ge`，这些方法和上面二进制算术操作类似：

```python
In [45]: df.gt(df2)
Out[45]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [46]: df2.ne(df)
Out[46]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False
```

这些操作产生一个和bool类型左手边的输入有相同数据类型的Pandas对象，这些布尔对象可以在索引操作中使用，查看[布尔索引](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing-boolean)章节，获得更多信息。

##### 9.4.4 布尔规约操作

你可以调用这些规约操作：[empty](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.empty.html#pandas.DataFrame.empty)，[any()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.any.html#pandas.DataFrame.any)， [all()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.all.html#pandas.DataFrame.all)和[bool](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.bool.html#pandas.DataFrame.bool)来为总结一个布尔结果提供一种方式。

```python
In [47]: (df > 0).all()
Out[47]: 
one      False
two      False
three    False
dtype: bool

In [48]: (df > 0).any()
Out[48]: 
one      True
two      True
three    True
dtype: bool
```

你可以通过规约得到最终的布尔值

```python
In [49]: (df > 0).any().any()
Out[49]: True
```

通过empty属性测试一个Pandas对象是不是空的：

```python
In [50]: df.empty
Out[50]: False

In [51]: pd.DataFrame(columns=list('ABC')).empty
Out[51]: True
```

通过[bool()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.bool.html#pandas.DataFrame.bool)方法在一个布尔环境中评估一个单元素的Pandas对象：

```python
In [52]: pd.Series([True]).bool()
Out[52]: True

In [53]: pd.Series([False]).bool()
Out[53]: False

In [54]: pd.DataFrame([[True]]).bool()
Out[54]: True

In [55]: pd.DataFrame([[False]]).bool()
Out[55]: False
```

> 注意：你可以想要尝试下面的操作：
>
> ```python
> >>> if df:
>      ...
> ```
>
> 或
>
> ```python
> >>> df and df2
> ```
>
> 这都会触发错误，因为你在尝试比较多个值。
>
> ```python
> ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().
> ```

查看[陷阱](http://pandas.pydata.org/pandas-docs/version/0.23/gotchas.html#gotchas-truth)，获得更多的讨论信息。

##### 9.4.5 比较对象是否相等

你经常可以发现，计算同一个结果可能有不同的方法。一个简单的例子，考虑`df + df`和`df * 2`。为了测试这两种计算是否会得到相同的结果，参考上面给出的工具，你可能想要使用`(df + df == df * 2).all()`。但是，这个表达式实际上是有欺骗性的。

```python
In [56]: df+df == df*2
Out[56]: 
     one   two  three
a   True  True  False
b   True  True   True
c   True  True   True
d  False  True   True

In [57]: (df+df == df*2).all()
Out[57]: 
one      False
two       True
three    False
dtype: bool
```

注意，`df + df == df * 2`得到的布尔DataFrame包含了一些False值。这是因为NaN值是不相等的。

```python
In [58]: np.nan == np.nan
Out[58]: False
```

所以，NDFrames （比如Series，DataFrame和Panel）有一个[equals()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.equals.html#pandas.DataFrame.equals)方法来比较是否相等。[equals()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.equals.html#pandas.DataFrame.equals)方法会将相关位置上的NaN值按相等处理。

```python
In [59]: (df+df).equals(df*2)
Out[59]: True
```

注意，Series和DataFrame的索引必须是相同的顺序，才会得到True。

```python
In [60]: df1 = pd.DataFrame({'col':['foo', 0, np.nan]})

In [61]: df2 = pd.DataFrame({'col':[np.nan, 0, 'foo']}, index=[2,1,0])

In [62]: df1.equals(df2)
Out[62]: False

In [63]: df1.equals(df2.sort_index())
Out[63]: True
```

##### 9.4.6 比较类数组对象

你可以很方便的按元素比较一个Pandas数据结构和一个标量

```python
In [64]: pd.Series(['foo', 'bar', 'baz']) == 'foo'
Out[64]: 
0     True
1    False
2    False
dtype: bool

In [65]: pd.Index(['foo', 'bar', 'baz']) == 'foo'
Out[65]: array([ True, False, False], dtype=bool)
```

Pandas也可以在长度相同的类数组对象之间按元素比较：

```python
In [66]: pd.Series(['foo', 'bar', 'baz']) == pd.Index(['foo', 'bar', 'qux'])
Out[66]: 
0     True
1     True
2    False
dtype: bool

In [67]: pd.Series(['foo', 'bar', 'baz']) == np.array(['foo', 'bar', 'qux'])
Out[67]: 
0     True
1     True
2    False
dtype: bool
```

比较不同长度的Index或Series对象将会触发ValueError：

```python
In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare
```

注意，这与Numpy的处理方式不同，在Numpy中，一个表达式可以广播：

```python
In [68]: np.array([1, 2, 3]) == np.array([2])
Out[68]: array([False,  True, False], dtype=bool)
```

或者，在不能广播的情况下，返回False

```python
In [69]: np.array([1, 2, 3]) == np.array([1, 2])
Out[69]: False
```

##### 9.4.7 合并重叠的数据集

偶尔出现的一个问题是，合并两个相似的数据集时，其中一个数据集的数比另一个优先度高。比如，两个表现特定的经济指标的数据序列，其中一个被认为"质量更高"。但是，低质量的序列可能在历史上可以回溯的更远或覆盖范围更全。同样的，我们希望合并两个DataFrame，其中一个DataFrame的缺失值有条件地以另一个DataFrame的同标签值替换。实现这种操作的函数是[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)。举例来说：

```python
In [70]: df1 = pd.DataFrame({'A' : [1., np.nan, 3., 5., np.nan],
   ....:                     'B' : [np.nan, 2., 3., np.nan, 6.]})
   ....: 

In [71]: df2 = pd.DataFrame({'A' : [5., 2., 4., np.nan, 3., 7.],
   ....:                     'B' : [np.nan, np.nan, 3., 4., 6., 8.]})
   ....: 

In [72]: df1
Out[72]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [73]: df2
Out[73]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [74]: df1.combine_first(df2)
Out[74]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
```

##### 9.4.8 一般的DataFrame合并

上面的[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)函数调用了更一般的[DataFrame.combine()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine.html#pandas.DataFrame.combine) 。这个方法接受另一个DataFrame和合并函数，对齐输入的DataFrame，然后传入合并函数一对Series（即：这些列的名称是相同的）。

所以，例如，重新生成上面的[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)：

```python
In [75]: combiner = lambda x, y: np.where(pd.isna(x), y, x)

In [76]: df1.combine(df2, combiner)
Out[76]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
```

##### 9.5 描述统计

[Series](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-series-stats)，[DataFrame](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-dataframe-stats)和[Panel](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-panel-stats)有大量计算描述统计值的方法和相关操作。这些操作中大部分都是聚合操作（进而产生一个低纬度的结果），比如[sum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sum.html#pandas.DataFrame.sum)，[mean()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.mean.html#pandas.DataFrame.mean)和[quantile()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile)，但是其中的一部分操作，比如[cumsum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum)和[cumprod()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod)，会产生一个同样大小的对象。一般而言，这些操作会有一个**轴**参数，比如ndarray，{sum，std，……}，但是这个轴可以用名称或整数来指定：

- Series：不需要轴参数。
- DataFrame："index"（axis=0）或"columns"（axis=1）。
- Panel："items"（axis=1），"major"（axis=1，默认）,"minor"（axis=2）。

举例：

```python
In [77]: df
Out[77]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [78]: df.mean(0)
Out[78]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [79]: df.mean(1)
Out[79]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64
```

所有这些操作都有一个**skipna**选项来标记是否排除缺失值。默认为True（排除）。

```python
In [80]: df.sum(0, skipna=False)
Out[80]: 
one           NaN
two      2.669223
three         NaN
dtype: float64

In [81]: df.sum(axis=1, skipna=True)
Out[81]: 
a    0.022914
b    1.675522
c    1.907343
d   -1.679206
dtype: float64
```

合并广播和算术操作，可以描述各种统计程序，比如标准化（将数据转化为均值为0，标准差为1的数据），非常简洁：

```python
In [82]: ts_stand = (df - df.mean()) / df.std()

In [83]: ts_stand.std()
Out[83]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [84]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [85]: xs_stand.std(1)
Out[85]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64
```

注意，类似[cumsum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum)和[cumprod()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod)的方法保留了缺失值的位置。这与[expanding()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding)和[rolling()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling)略有不同。更多的细节，请查阅[这里](http://pandas.pydata.org/pandas-docs/version/0.23/computation.html#stats-moments-expanding-note)。

```python
In [86]: df.cumsum()
Out[86]: 
        one       two     three
a -1.101558  1.124472       NaN
b -1.278848  3.611576 -0.634293
c -0.816633  3.125511  1.296901
d       NaN  2.669223  0.073983
```

这里有一个常见函数的速查表。如果被操作的对象含有[多级索引](http://pandas.pydata.org/pandas-docs/version/0.23/advanced.html#advanced-hierarchical)，每个函数还有一个level参数。

| 函数       | 描述             |
| ---------- | ---------------- |
| `count`    | 非空观察值的个数 |
| `sum`      | 数值的和         |
| `mean`     | 数值的平均值     |
| `mad`      | 平均绝对偏差     |
| `median`   | 数值的算术平均值 |
| `min`      | 最小值           |
| `max`      | 最大值           |
| `mode`     | 众数             |
| `abs`      | 绝对值           |
| `prod`     | 数值的乘积       |
| `std`      | 标准差           |
| `var`      | 方差             |
| `sem`      | 平均值的标准误   |
| `skew`     | 样本偏度         |
| `kurt`     | 样本峰度         |
| `quantile` | 分位数           |
| `cumsum`   | 累加值           |
| `cumprod`  | 累乘值           |
| `cummax`   | 累计最大值       |
| `cummin`   | 累计最小值       |

 注意，意外地，一些Numpy方法，比如mean，std和sum，会默认排除输入的Series中的NA值：

```python
In [87]: np.mean(df['one'])
Out[87]: -0.27221094480450114

In [88]: np.mean(df['one'].values)
Out[88]: nan
```

[`Series.nunique()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.nunique.html#pandas.Series.nunique) 将返回Series中唯一的非空数据的个数：

```python
In [89]: series = pd.Series(np.random.randn(500))

In [90]: series[20:500] = np.nan

In [91]: series[10:20]  = 5

In [92]: series.nunique()
Out[92]: 11
```

##### 9.5.1 数据概览：描述

有一个非常方便的函数[`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe) 来计算一个Series或DataFrame的若干列的摘要统计（默认排除空值）：

```python
In [93]: series = pd.Series(np.random.randn(1000))

In [94]: series[::2] = np.nan

In [95]: series.describe()
Out[95]: 
count    500.000000
mean      -0.032127
std        1.067484
min       -3.463789
25%       -0.725523
50%       -0.053230
75%        0.679790
max        3.120271
dtype: float64

In [96]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=['a', 'b', 'c', 'd', 'e'])

In [97]: frame.iloc[::2] = np.nan

In [98]: frame.describe()
Out[98]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean    -0.045109   -0.052045    0.024520    0.006117    0.001141
std      1.029268    1.002320    1.042793    1.040134    1.005207
min     -2.915767   -3.294023   -3.610499   -2.907036   -3.010899
25%     -0.763783   -0.720389   -0.609600   -0.665896   -0.682900
50%     -0.086033   -0.048843    0.006093    0.043191   -0.001651
75%      0.663399    0.620980    0.728382    0.735973    0.656439
max      3.400646    2.925597    3.416896    3.331522    3.007143
```

你可以选择特定的分位数来输出：

```python
In [99]: series.describe(percentiles=[.05, .25, .75, .95])
Out[99]: 
count    500.000000
mean      -0.032127
std        1.067484
min       -3.463789
5%        -1.733545
25%       -0.725523
50%       -0.053230
75%        0.679790
95%        1.854383
max        3.120271
dtype: float64
```

默认地，结果中一直包含平均值。

对于非数值Series对象， [`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.describe.html#pandas.Series.describe)将给出唯一数据个数和最常出现的数值的简单摘要：

```python
In [100]: s = pd.Series(['a', 'a', 'b', 'b', 'a', 'a', np.nan, 'c', 'd', 'a'])

In [101]: s.describe()
Out[101]: 
count     9
unique    4
top       a
freq      5
dtype: object
```

注意，在混合类型的DataFrame对象上，[`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe) 将限制摘要只包含数值列，或（如果没有数值列），包含类别列：

```python
In [102]: frame = pd.DataFrame({'a': ['Yes', 'Yes', 'No', 'No'], 'b': range(4)})

In [103]: frame.describe()
Out[103]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000
```

这个操作行为可以通过给定一个类型列表作为 `include`或`exclude` 参数来控制。特别的值`all`也可以使用：

```python
In [104]: frame.describe(include=['object'])
Out[104]: 
          a
count     4
unique    2
top     Yes
freq      2

In [105]: frame.describe(include=['number'])
Out[105]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [106]: frame.describe(include='all')
Out[106]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000
```

这个特性依赖于 [select_dtypes](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-selectdtypes) 。可以到那里查看更多被接受的输入。

##### 9.5.2 最大值/最小值索引

[`idxmin()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin) 和 [`idxmax()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax) 函数计算一个Series和DataFrame的最小值和最大值的索引标签：

```python
In [107]: s1 = pd.Series(np.random.randn(5))

In [108]: s1
Out[108]: 
0   -1.649461
1    0.169660
2    1.246181
3    0.131682
4   -2.001988
dtype: float64

In [109]: s1.idxmin(), s1.idxmax()
Out[109]: (4, 2)

In [110]: df1 = pd.DataFrame(np.random.randn(5,3), columns=['A','B','C'])

In [111]: df1
Out[111]: 
          A         B         C
0 -1.273023  0.870502  0.214583
1  0.088452 -0.173364  1.207466
2  0.546121  0.409515 -0.310515
3  0.585014 -0.490528 -0.054639
4 -0.239226  0.701089  0.228656

In [112]: df1.idxmin(axis=0)
Out[112]: 
A    0
B    3
C    2
dtype: int64

In [113]: df1.idxmax(axis=1)
Out[113]: 
0    B
1    C
2    A
3    A
4    B
dtype: object
```

如果有多个行（或列）满足最大值和最小值，[`idxmin()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin) 和 [`idxmax()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax) 返回第一个符合的索引：

```python
In [114]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=['A'], index=list('edcba'))

In [115]: df3
Out[115]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [116]: df3['A'].idxmin()
Out[116]: 'd'
```

> 注意：在Numpy中，`idxmin`和`idxmax`称为`argmin`和`argmax`。

##### 9.5.3 计数（直方图）/ 众数

Series的[`value_counts()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.value_counts.html#pandas.Series.value_counts) 方法和顶级函数计算一个一维数组的每个值的个数。它也可以作为一个函数用在一个常规数组上：

```python
In [117]: data = np.random.randint(0, 7, size=50)

In [118]: data
Out[118]: 
array([3, 3, 0, 2, 1, 0, 5, 5, 3, 6, 1, 5, 6, 2, 0, 0, 6, 3, 3, 5, 0, 4, 3,
       3, 3, 0, 6, 1, 3, 5, 5, 0, 4, 0, 6, 3, 6, 5, 4, 3, 2, 1, 5, 0, 1, 1,
       6, 4, 1, 4])

In [119]: s = pd.Series(data)

In [120]: s.value_counts()
Out[120]: 
3    11
0     9
5     8
6     7
1     7
4     5
2     3
dtype: int64

In [121]: pd.value_counts(data)
Out[121]: 
3    11
0     9
5     8
6     7
1     7
4     5
2     3
dtype: int64
```

类似地，你可以得到一个Series或DataFrame的最常出现的数值（众数）:

```python
In [122]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [123]: s5.mode()
Out[123]: 
0    3
1    7
dtype: int64

In [124]: df5 = pd.DataFrame({"A": np.random.randint(0, 7, size=50),
   .....:                     "B": np.random.randint(-10, 15, size=50)})
   .....: 

In [125]: df5.mode()
Out[125]: 
   A  B
0  2 -5
```

##### 9.5.4 离散化和求分位数

可以使用[`cut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.cut.html#pandas.cut) （基于数值分段）和[`qcut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.qcut.html#pandas.qcut) （基于样本分位点分段）来离散化连续数值：

```python
In [126]: arr = np.random.randn(20)

In [127]: factor = pd.cut(arr, 4)

In [128]: factor
Out[128]: 
[(-2.611, -1.58], (0.473, 1.499], (-2.611, -1.58], (-1.58, -0.554], (-0.554, 0.473], ..., (0.473, 1.499], (0.473, 1.499], (-0.554, 0.473], (-0.554, 0.473], (-0.554, 0.473]]
Length: 20
Categories (4, interval[float64]): [(-2.611, -1.58] < (-1.58, -0.554] < (-0.554, 0.473] <
                                    (0.473, 1.499]]

In [129]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [130]: factor
Out[130]: 
[(-5, -1], (0, 1], (-5, -1], (-1, 0], (-1, 0], ..., (1, 5], (1, 5], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]
```

[`qcut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.qcut.html#pandas.qcut)计算样本分位点。例如，我们可以把一些普通分布数据切成相等大小的四份：

```python
In [131]: arr = np.random.randn(30)

In [132]: factor = pd.qcut(arr, [0, .25, .5, .75, 1])

In [133]: factor
Out[133]: 
[(0.544, 1.976], (0.544, 1.976], (-1.255, -0.375], (0.544, 1.976], (-0.103, 0.544], ..., (-0.103, 0.544], (0.544, 1.976], (-0.103, 0.544], (-1.255, -0.375], (-0.375, -0.103]]
Length: 30
Categories (4, interval[float64]): [(-1.255, -0.375] < (-0.375, -0.103] < (-0.103, 0.544] <
                                    (0.544, 1.976]]

In [134]: pd.value_counts(factor)
Out[134]: 
(0.544, 1.976]      8
(-1.255, -0.375]    8
(-0.103, 0.544]     7
(-0.375, -0.103]    7
dtype: int64
```

我们也可以传入无穷值来定义分组：

```python
In [135]: arr = np.random.randn(20)

In [136]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [137]: factor
Out[137]: 
[(0.0, inf], (0.0, inf], (0.0, inf], (0.0, inf], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (0.0, inf], (-inf, 0.0], (0.0, inf]]
Length: 20
Categories (2, interval[float64]): [(-inf, 0.0] < (0.0, inf]]
```

#### 9.6 调用函数

在Pandas对象上调用你自定义的或其他库中的函数，你应该了解下面的三个方法。至于使用哪个方法，取决于你的函数期望在整个DataFrame、Series、按行、按列还是按元素操作数据。

1. [按表调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#tablewise-function-application)：[`pipe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe) 
2. [按行或列调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#row-or-column-wise-function-application)：[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 
3. [聚合API](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#aggregation-api)：[`agg()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.agg.html#pandas.DataFrame.agg) 和[`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform) 
4. [按元素调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#applying-elementwise-functions)：[`applymap()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap) 

##### 9.6.1 按表调用函数

 `DataFrames` 和 `Series`  当然可以作为参数传入一个函数。不过，如果一个函数需要在一个方法链中调用，考虑使用 [`pipe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe) 方法。对比以下两个表达式：

```python
# f, g, and h are functions taking and returning ``DataFrames``
>>> f(g(h(df), arg1=1), arg2=2, arg3=3)
```

等价的：

```python
>>> (df.pipe(h)
       .pipe(g, arg1=1)
       .pipe(f, arg2=2, arg3=3)
    )
```

Pandas推荐使用第二种方式（方法链）。`pipe `使得在方法链中与Pandas方法一起使用自定义函数或其他库中的函数变得很容易。

在上面的例子中，函数f，g和h，每个都接受DataFrame作为第一位置参数。如果你要调用的函数将它的数据作为第二个参数怎么办？在这种情况下，Pandas提供了pipe方法，包含一个(callable, data_keyword)元组。pipe将DataFrame指向该元组的指定参数。

例如，我们可以使用statsmodels做回归拟合。他们的API接受一个公式（作为第一个参数），一个DataFrame作为第二个参数`data`。我们为pipe向这个函数传入关键词对(sm.ols,'data')：

```python
In [138]: import statsmodels.formula.api as sm

In [139]: bb = pd.read_csv('data/baseball.csv', index_col='id')

In [140]: (bb.query('h > 0')
   .....:    .assign(ln_h = lambda df: np.log(df.h))
   .....:    .pipe((sm.ols, 'data'), 'hr ~ ln_h + year + g + C(lg)')
   .....:    .fit()
   .....:    .summary()
   .....: )
   .....: 
Out[140]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                     hr   R-squared:                       0.685
Model:                            OLS   Adj. R-squared:                  0.665
Method:                 Least Squares   F-statistic:                     34.28
Date:                Tue, 12 Jun 2018   Prob (F-statistic):           3.48e-15
Time:                        12:53:14   Log-Likelihood:                -205.92
No. Observations:                  68   AIC:                             421.8
Df Residuals:                      63   BIC:                             432.9
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept   -8484.7720   4664.146     -1.819      0.074   -1.78e+04     835.780
C(lg)[T.NL]    -2.2736      1.325     -1.716      0.091      -4.922       0.375
ln_h           -1.3542      0.875     -1.547      0.127      -3.103       0.395
year            4.2277      2.324      1.819      0.074      -0.417       8.872
g               0.1841      0.029      6.258      0.000       0.125       0.243
==============================================================================
Omnibus:                       10.875   Durbin-Watson:                   1.999
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               17.298
Skew:                           0.537   Prob(JB):                     0.000175
Kurtosis:                       5.225   Cond. No.                     1.49e+07
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.49e+07. This might indicate that there are
strong multicollinearity or other numerical problems.
"""
```

pipe方法受到Unix管道和更近的为R引入流行的（%>%）（读管道）的[dplyr](https://github.com/hadley/dplyr) 和[magrittr](https://github.com/smbache/magrittr) 的启发。这里，pipe的实现非常干净，在Python中感觉很好。我们鼓励你去读一下[源码](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe)。

##### 9.6.2 按行、按列调用函数

可以使用[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 方法在DataFrame的一个轴上调用任意函数，比如，描述统计方法，就有一个axis参数：

```python
In [141]: df.apply(np.mean)
Out[141]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [142]: df.apply(np.mean, axis=1)
Out[142]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64

In [143]: df.apply(lambda x: x.max() - x.min())
Out[143]: 
one      1.563773
two      2.973170
three    3.154112
dtype: float64

In [144]: df.apply(np.cumsum)
Out[144]: 
        one       two     three
a -1.101558  1.124472       NaN
b -1.278848  3.611576 -0.634293
c -0.816633  3.125511  1.296901
d       NaN  2.669223  0.073983

In [145]: df.apply(np.exp)
Out[145]: 
        one        two    three
a  0.332353   3.078592      NaN
b  0.837537  12.026397  0.53031
c  1.587586   0.615041  6.89774
d       NaN   0.633631  0.29437
```

[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 方法也能够调用字符串方法名：

```python
In [146]: df.apply('mean')
Out[146]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [147]: df.apply('mean', axis=1)
Out[147]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64
```

传入[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)的函数返回值的类型会影响`DataFrame.apply`默认的最终的输出。

- 如果传入的函数返回Series，最终输出DataFrame。调用的函数返回匹配Series的索引的列。
- 如果传入的函数返回其他的类型，最终输出Series。

这种默认处理方式可以通过`result_type`来覆写，`result_type`接受三种选项：`reduce`，`broadcast`和`expand`。这将决定类列表返回值如何扩展（或不扩展）成DataFrame。

[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)合结合一些聪明的处理方式可以解决很多数据集的问题。例如，假设我们想要提取每列最大值对应的日期：

```python
In [148]: tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=1000))
   .....: 

In [149]: tsdf.apply(lambda x: x.idxmax())
Out[149]: 
A   2001-04-25
B   2002-05-31
C   2002-09-25
dtype: datetime64[ns]
```

你也可以为[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)方法传入额外的参数和关键字参数。比如，考虑接下来这个你想调用的函数：

```python
def subtract_and_divide(x, sub, divide=1):
    return (x - sub) / divide
```

你可以这么调用：

```python
df.apply(subtract_and_divide, args=(5,), divide=3)
```

另一个有用的特性是能够传入Series方法在每一列或行上执行Series操作：

```python
In [150]: tsdf
Out[150]: 
                   A         B         C
2000-01-01 -0.720299  0.546303 -0.082042
2000-01-02  0.200295 -0.577554 -0.908402
2000-01-03  0.102533  1.653614  0.303319
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.532566  0.341548  0.150493
2000-01-09  0.330418  1.761200  0.567133
2000-01-10 -0.251020  1.020099  1.893177

In [151]: tsdf.apply(pd.Series.interpolate)
Out[151]: 
                   A         B         C
2000-01-01 -0.720299  0.546303 -0.082042
2000-01-02  0.200295 -0.577554 -0.908402
2000-01-03  0.102533  1.653614  0.303319
2000-01-04  0.188539  1.391201  0.272754
2000-01-05  0.274546  1.128788  0.242189
2000-01-06  0.360553  0.866374  0.211624
2000-01-07  0.446559  0.603961  0.181059
2000-01-08  0.532566  0.341548  0.150493
2000-01-09  0.330418  1.761200  0.567133
2000-01-10 -0.251020  1.020099  1.893177
```

最后， [`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)  有一个`raw`参数，默认值为False，在调用函数之前将每一行或列转变为Series。当设为True时，传入的函数变为接收一个ndarray对象，在不需要操作索引时，能够提升性能。

##### 9.6.3 聚合API

0.20.0版本新特性。

聚合API允许使用者以一个简洁的方式表达可能的多种聚合操作。这个API类似于Pandas对象，查看[分组 API](http://pandas.pydata.org/pandas-docs/version/0.23/groupby.html#groupby-aggregate)，[窗口函数API](http://pandas.pydata.org/pandas-docs/version/0.23/computation.html#stats-aggregate)和[重采样API](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html#timeseries-aggregate)。聚合操作的入口是 [`DataFrame.aggregate()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate) 或其别名[`DataFrame.agg()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.agg.html#pandas.DataFrame.agg)。

我们将用一个类似上面的起始数据框（开始）：

```python
In [152]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [153]: tsdf.iloc[3:7] = np.nan

In [154]: tsdf
Out[154]: 
                   A         B         C
2000-01-01  0.170247 -0.916844  0.835024
2000-01-02  1.259919  0.801111  0.445614
2000-01-03  1.453046  2.430373  0.653093
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -1.874526  0.569822 -0.609644
2000-01-09  0.812462  0.565894 -1.461363
2000-01-10 -0.985475  1.388154 -0.078747
```

使用一个单独的函数等价于调用[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 。你也可以传入以字符串命名的方法。作为聚合操作的输出，这些将会返回一个Series：

```python
In [155]: tsdf.agg(np.sum)
Out[155]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64

In [156]: tsdf.agg('sum')
Out[156]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64

# these are equivalent to a ``.sum()`` because we are aggregating on a single function
In [157]: tsdf.sum()
Out[157]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64
```

在一个Series上执行单独的聚合操作将返回一个标量：

```pyhton
In [158]: tsdf.A.agg('sum')
Out[158]: 0.83567297915820504
```

###### 9.6.3.1 调用多个函数执行聚合操作

你可以传入多个聚合参数组成的列表。每一个传入的函数的返回结果将会是结果DataFrame中的一行。这些都是自然地有聚合函数命名的：

```python
In [159]: tsdf.agg(['sum'])
Out[159]: 
            A        B         C
sum  0.835673  4.83851 -0.216025
```

多个函数生成多个行：

```python
In [160]: tsdf.agg(['sum', 'mean'])
Out[160]: 
             A         B         C
sum   0.835673  4.838510 -0.216025
mean  0.139279  0.806418 -0.036004
```

在一个Series上执行多个聚合操作，返回一个Series，这个Series的索引由聚合函数命名：

```python
In [161]: tsdf.A.agg(['sum', 'mean'])
Out[161]: 
sum     0.835673
mean    0.139279
Name: A, dtype: float64
```

传入lambda匿名函数，将生成一个由`<lambda>`命名的行：

```python
In [162]: tsdf.A.agg(['sum', lambda x: x.mean()])
Out[162]: 
sum         0.835673
<lambda>    0.139279
Name: A, dtype: float64
```

传入一个命名函数，将生成一个命名为该函数名的行：

```python
In [163]: def mymean(x):
   .....:    return x.mean()
   .....: 

In [164]: tsdf.A.agg(['sum', mymean])
Out[164]: 
sum       0.835673
mymean    0.139279
Name: A, dtype: float64
```

###### 9.6.3.2 使用字典执行聚合操作

为`DataFrame.agg`传入一个列名作为键，一个标量或标量列表作为值的字典，允许你自定义哪个列调用哪个函数。注意，结果没有排序，你可以使用一个`OrderedDict`替代保证排序。

```python
In [165]: tsdf.agg({'A': 'mean', 'B': 'sum'})
Out[165]: 
A    0.139279
B    4.838510
dtype: float64
```

传入列表将生产一个DataFrame输出。你将得到一个含有所有聚合操作的类矩阵输出。这个输出由所有的独立函数组成。那些没有执行聚合操作的列会返回NaN：

```python 
In [166]: tsdf.agg({'A': ['mean', 'min'], 'B': 'sum'})
Out[166]: 
             A        B
mean  0.139279      NaN
min  -1.874526      NaN
sum        NaN  4.83851
```

###### 9.6.3.3 混合数据类型 

当提供的数据为不能执行聚合操作的混合数据类型时，`.agg`将只执行合法的聚合操作。这个分组中的`.agg`工作模式相似：

```python
In [167]: mdf = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [1., 2., 3.],
   .....:                     'C': ['foo', 'bar', 'baz'],
   .....:                     'D': pd.date_range('20130101', periods=3)})
   .....: 

In [168]: mdf.dtypes
Out[168]: 
A             int64
B           float64
C            object
D    datetime64[ns]
dtype: object
```

```python
In [169]: mdf.agg(['min', 'sum'])
Out[169]: 
     A    B          C          D
min  1  1.0        bar 2013-01-01
sum  6  6.0  foobarbaz        NaT
```

###### 9.6.3.4 自定义描述

使用`.agg`可以很方便地创建自定义描述函数，类似于内置的[描述函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-describe)：

```python
In [170]: from functools import partial

In [171]: q_25 = partial(pd.Series.quantile, q=0.25)

In [172]: q_25.__name__ = '25%'

In [173]: q_75 = partial(pd.Series.quantile, q=0.75)

In [174]: q_75.__name__ = '75%'

In [175]: tsdf.agg(['count', 'mean', 'std', 'min', q_25, 'median', q_75, 'max'])
Out[175]: 
               A         B         C
count   6.000000  6.000000  6.000000
mean    0.139279  0.806418 -0.036004
std     1.323362  1.100830  0.874990
min    -1.874526 -0.916844 -1.461363
25%    -0.696544  0.566876 -0.476920
median  0.491354  0.685467  0.183433
75%     1.148055  1.241393  0.601223
max     1.453046  2.430373  0.835024
```

##### 9.6.4 转换API

0.20.0版本新特性

 [`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform)  方法返回一个和原始索引相同（相同大小）的对象。这个API允许你同时提供多个操作，而不是一个接着一个。它的API和`.agg`的API很相似。

我们创建一个数据框，和上一节用到的类似。

```python
In [176]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [177]: tsdf.iloc[3:7] = np.nan

In [178]: tsdf
Out[178]: 
                   A         B         C
2000-01-01 -0.578465 -0.503335 -0.987140
2000-01-02 -0.767147 -0.266046  1.083797
2000-01-03  0.195348  0.722247 -0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.556397  0.542165 -0.308675
2000-01-09 -1.010924 -0.672504 -1.139222
2000-01-10  0.354653  0.563622 -0.365106
```

对整个数据框执行转换操作，`.tranform()`允许输入函数是：一个Numpy函数，一个字符串函数名或用户自定义函数。

```python
In [179]: tsdf.transform(np.abs)
Out[179]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106

In [180]: tsdf.transform('abs')
Out[180]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106

In [181]: tsdf.transform(lambda x: x.abs())
Out[181]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106
```

这里 [`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform)  接受了一个单独的函数，等价于调用Numpy的全局函数：

```python
In [182]: np.abs(tsdf)
Out[182]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106
```

在Series上为`.transform()`传入一个单独的函数，将返回一个Series：

```python
In [183]: tsdf.A.transform(np.abs)
Out[183]: 
2000-01-01    0.578465
2000-01-02    0.767147
2000-01-03    0.195348
2000-01-04         NaN
2000-01-05         NaN
2000-01-06         NaN
2000-01-07         NaN
2000-01-08    0.556397
2000-01-09    1.010924
2000-01-10    0.354653
Freq: D, Name: A, dtype: float64
```

###### 9.6.4.1 使用多个函数进行转换

传入多个函数，将会生成一个列多级索引的DataFrame。第一级将会是原始数据框的列名，第二级将会是变换函数的名称：

```python
In [184]: tsdf.transform([np.abs, lambda x: x+1])
Out[184]: 
                   A                   B                   C          
            absolute  <lambda>  absolute  <lambda>  absolute  <lambda>
2000-01-01  0.578465  0.421535  0.503335  0.496665  0.987140  0.012860
2000-01-02  0.767147  0.232853  0.266046  0.733954  1.083797  2.083797
2000-01-03  0.195348  1.195348  0.722247  1.722247  0.894537  0.105463
2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-08  0.556397  0.443603  0.542165  1.542165  0.308675  0.691325
2000-01-09  1.010924 -0.010924  0.672504  0.327496  1.139222 -0.139222
2000-01-10  0.354653  1.354653  0.563622  1.563622  0.365106  0.634894
```

为Series传入多个函数，将生成一个DataFrame，结果的列名将会是转换函数名：

```python
In [185]: tsdf.A.transform([np.abs, lambda x: x+1])
Out[185]: 
            absolute  <lambda>
2000-01-01  0.578465  0.421535
2000-01-02  0.767147  0.232853
2000-01-03  0.195348  1.195348
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  0.443603
2000-01-09  1.010924 -0.010924
2000-01-10  0.354653  1.354653
```

###### 9.6.4.2 使用字典进行转换

传入一个函数字典，将允许每列有选择的转换。

```python
In [186]: tsdf.transform({'A': np.abs, 'B': lambda x: x+1})
Out[186]: 
                   A         B
2000-01-01  0.578465  0.496665
2000-01-02  0.767147  0.733954
2000-01-03  0.195348  1.722247
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  1.542165
2000-01-09  1.010924  0.327496
2000-01-10  0.354653  1.563622
```

转入一个含有列表的字典，将返回一个多级索引的DataFrame：

```python
In [187]: tsdf.transform({'A': np.abs, 'B': [lambda x: x+1, 'sqrt']})
Out[187]: 
                   A         B          
            absolute  <lambda>      sqrt
2000-01-01  0.578465  0.496665       NaN
2000-01-02  0.767147  0.733954       NaN
2000-01-03  0.195348  1.722247  0.849851
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  1.542165  0.736318
2000-01-09  1.010924  0.327496       NaN
2000-01-10  0.354653  1.563622  0.750748
```
##### 9.7 调用按元素执行的函数
因为并不是所有的函数都能向量化（接受Numpy数组，返回另一个数组或值），Pandas提供了一个在applymap()方法，允许在DataFrame上执行，接受任意的单参数单返回值的Python函数。类似地，在Series上执行map()方法，也是一样。例如：
```python
In [188]: df4
Out[188]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [189]: f = lambda x: len(str(x))

In [190]: df4['one'].map(f)
Out[190]: 
a    19
b    20
c    18
d     3
Name: one, dtype: int64

In [191]: df4.applymap(f)
Out[191]: 
   one  two  three
a   19   18      3
b   20   18     19
c   18   20     18
d    3   19     19
```
Series.map()还有附加属性：它可以用来方便地"链接"或"映射"被第二个Series定义的值。这与[合并/连](http://pandas.pydata.org/pandas-docs/version/0.23/merging.html#merging)接功能密切相关：
```python
In [192]: s = pd.Series(['six', 'seven', 'six', 'seven', 'six'],
   .....:               index=['a', 'b', 'c', 'd', 'e'])
   .....: 

In [193]: t = pd.Series({'six' : 6., 'seven' : 7.})

In [194]: s
Out[194]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [195]: s.map(t)
Out[195]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64
```
##### 9.8 在Panel上调用函数
从略
##### 9.9 重建索引、改变标签



