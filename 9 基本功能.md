### 第九章 基本功能

本章我们将讨论很多Pandas数据结构的基本功能。下面是如何创建前面几章示例中用到的对象：

```python
In [1]: index = pd.date_range('1/1/2000', periods=8)

In [2]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [3]: df = pd.DataFrame(np.random.randn(8, 3), index=index,
   ...:                   columns=['A', 'B', 'C'])
   ...: 

In [4]: wp = pd.Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
   ...:               major_axis=pd.date_range('1/1/2000', periods=5),
   ...:               minor_axis=['A', 'B', 'C', 'D'])
   ...: 
```

#### 9.1 Head 和Tail

可以通过head()和tail()方法查看Series或DataFrame的一个小样本。默认显示的元素个数是5，可以传入自定义的数值：

```python
In [5]: long_series = pd.Series(np.random.randn(1000))

In [6]: long_series.head()
Out[6]: 
0    0.229453
1    0.304418
2    0.736135
3   -0.859631
4   -0.424100
dtype: float64

In [7]: long_series.tail(3)
Out[7]: 
997   -0.351587
998    1.136249
999   -0.448789
dtype: float64
```

#### 9.2 属性和原生ndarray

Pandas对象拥有许多属性，你可以通过这些属性访问元数据。

- shape：给出对象的维度，和ndarray是一致的。
- 轴标签
  - Series：索引（只有轴）
  - DataFrame：索引（行）和列
  - Panel：项目，最大轴和最小轴

注意，这些属性可以安全的赋值。

```python
In [8]: df[:2]
Out[8]: 
                   A         B        C
2000-01-01  0.048869 -1.360687 -0.47901
2000-01-02 -0.859661 -0.231595 -0.52775

In [9]: df.columns = [x.lower() for x in df.columns]

In [10]: df
Out[10]: 
                   a         b         c
2000-01-01  0.048869 -1.360687 -0.479010
2000-01-02 -0.859661 -0.231595 -0.527750
2000-01-03 -1.296337  0.150680  0.123836
2000-01-04  0.571764  1.555563 -0.823761
2000-01-05  0.535420 -1.032853  1.469725
2000-01-06  1.304124  1.449735  0.203109
2000-01-07 -1.032011  0.969818 -0.962723
2000-01-08  1.382083 -0.938794  0.669142
```

获得数据结构中的数，只需要通过**values**属性：

```python
In [11]: s.values
Out[11]: array([-1.9339,  0.3773,  0.7341,  2.1416, -0.0112])

In [12]: df.values
Out[12]: 
array([[ 0.0489, -1.3607, -0.479 ],
       [-0.8597, -0.2316, -0.5278],
       [-1.2963,  0.1507,  0.1238],
       [ 0.5718,  1.5556, -0.8238],
       [ 0.5354, -1.0329,  1.4697],
       [ 1.3041,  1.4497,  0.2031],
       [-1.032 ,  0.9698, -0.9627],
       [ 1.3821, -0.9388,  0.6691]])

In [13]: wp.values
Out[13]: 
array([[[-0.4336, -0.2736,  0.6804, -0.3084],
        [-0.2761, -1.8212, -1.9936, -1.9274],
        [-2.0279,  1.625 ,  0.5511,  3.0593],
        [ 0.4553, -0.0307,  0.9357,  1.0612],
        [-2.1079,  0.1999,  0.3236, -0.6416]],

       [[-0.5875,  0.0539,  0.1949, -0.382 ],
        [ 0.3186,  2.0891, -0.7283, -0.0903],
        [-0.7482,  1.3189, -2.0298,  0.7927],
        [ 0.461 , -0.5427, -0.3054, -0.4792],
        [ 0.095 , -0.2701, -0.7071, -0.7739]]])
```

如果一个DataFrame或Panel包含相同类型的数据，ndarray实际上可以就地修改，并且这些修改将会反映到数据结构中。对于不同类型的数据，例如DataFrame的一些列的数据类型不同，将不是这样。**values**属性本身不能被赋值，这与轴标签不同。

> 注意：当面对不同类型的数据时，结果的类型将会选择最大限度容纳所有数据的那个。例如，如果涉及到字符串，结果将会是object类型。如果只有浮点型数据和整型数据，结果将会是浮点型。

#### 9.3 加速操作

Pandas支持使用`numexpr`库和`bottleneck`库来加速某些类型的二进制数字和布尔操作。

这两个库在处理大型数据是格外有用，能够大幅提升速度。`numexpr`  使用智能分块、缓存和多核技术。`bottleneck`  是一系列专门的cython例程，这些例程在处理包含`nan`的数组时特别快。

这里有一个示例（使用100行100列的DataFrame）：

| 操作        | 0.11.0 版(ms) | 之前的版本 (ms) | 0.11版占之前版本的比例 |
| ----------- | ------------- | --------------- | ---------------------- |
| `df1 > df2` | 13.32         | 125.35          | 0.1063                 |
| `df1 * df2` | 21.71         | 36.63           | 0.5928                 |
| `df1 + df2` | 22.04         | 36.50           | 0.6039                 |

我们特别鼓励安装这两个库。查看[推荐依赖](http://pandas.pydata.org/pandas-docs/version/0.23/install.html#install-recommended-dependencies)，获得更多的安装信息。

这两个库默认使用，你可以通过设置选项控制是否使用：

```python
pd.set_option('compute.use_bottleneck', False)
pd.set_option('compute.use_numexpr', False)
```

#### 9.4 灵活的二进制操作

在Pandas数据结构中使用二进制操作时，有两点我们比较关心：

- 高维数据结构（DataFrame）和低维数据结构（Series）之间的广播方式。
- 缺失数据如何计算。

我们将展示如何独立地处理这两个问题，不过它们可以同时处理。

##### 9.4.1 匹配/广播行为

DataFrame有一些执行二进制运算的方法：[add()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.add.html#pandas.DataFrame.add)、[sub()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sub.html#pandas.DataFrame.sub)、[mul()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.mul.html#pandas.DataFrame.mul)、[div()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.div.html#pandas.DataFrame.div)和相关的[radd()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.radd.html#pandas.DataFrame.radd)、[rsub()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rsub.html#pandas.DataFrame.rsub)等。广播行为对Series的输入更感兴趣。使用这些函数，你可以通过**axis**关键字在索引和列上做匹配。

```python
In [14]: df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),
   ....:                    'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),
   ....:                    'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})
   ....: 

In [15]: df
Out[15]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [16]: row = df.iloc[1]

In [17]: column = df['two']

In [18]: df.sub(row, axis='columns')
Out[18]: 
        one       two     three
a -0.924269 -1.362632       NaN
b  0.000000  0.000000  0.000000
c  0.639504 -2.973170  2.565487
d       NaN -2.943392 -0.588625

In [19]: df.sub(row, axis=1)
Out[19]: 
        one       two     three
a -0.924269 -1.362632       NaN
b  0.000000  0.000000  0.000000
c  0.639504 -2.973170  2.565487
d       NaN -2.943392 -0.588625

In [20]: df.sub(column, axis='index')
Out[20]: 
        one  two     three
a -2.226031  0.0       NaN
b -2.664393  0.0 -3.121397
c  0.948280  0.0  2.417260
d       NaN  0.0 -0.766631

In [21]: df.sub(column, axis=0)
Out[21]: 
        one  two     three
a -2.226031  0.0       NaN
b -2.664393  0.0 -3.121397
c  0.948280  0.0  2.417260
d       NaN  0.0 -0.766631
```

更进一步，你也可以将一个多级索引的DataFrame的一个等级与一个Series对齐

```python
In [22]: dfmi = df.copy()

In [23]: dfmi.index = pd.MultiIndex.from_tuples([(1,'a'),(1,'b'),(1,'c'),(2,'a')],
   ....:                                        names=['first','second'])
   ....: 

In [24]: dfmi.sub(column, axis=0, level='second')
Out[24]: 
                   one      two     three
first second                             
1     a      -2.226031  0.00000       NaN
      b      -2.664393  0.00000 -3.121397
      c       0.948280  0.00000  2.417260
2     a            NaN -1.58076 -2.347391
```

对于Panel来说，描述广播行为有一点困难，所以算术方法让你来指定广播的轴（可能更加令人难以理解？）。例如，假设我们希望将一个特定的轴上的数据去均值化。这可以通过将这个轴上的数值的平均值在该轴上广播来实现：

```python
In [25]: major_mean = wp.mean(axis='major')

In [26]: major_mean
Out[26]: 
      Item1     Item2
A -0.878036 -0.092218
B -0.060128  0.529811
C  0.099453 -0.715139
D  0.248599 -0.186535

In [27]: wp.sub(major_mean, axis='major')
Out[27]: 
<class 'pandas.core.panel.Panel'>
Dimensions: 2 (items) x 5 (major_axis) x 4 (minor_axis)
Items axis: Item1 to Item2
Major_axis axis: 2000-01-01 00:00:00 to 2000-01-05 00:00:00
Minor_axis axis: A to D
```

`axis="items"` 和`axis="minor"` 类似。

> 注意：我可以确定，DataFrame中的**axis**参数能够匹配Panel中的广播行为。尽管这需要一个过渡期，以便用户可以修改他们的代码...

Series和Index也支持[divmod()](https://docs.python.org/3/library/functions.html#divmod)内置函数。这个函数同时接受向下取整除法和取模操作，返回一个与左边相同类型的双元组。例如：

```python
In [28]: s = pd.Series(np.arange(10))

In [29]: s
Out[29]: 
0    0
1    1
2    2
3    3
4    4
5    5
6    6
7    7
8    8
9    9
dtype: int64

In [30]: div, rem = divmod(s, 3)

In [31]: div
Out[31]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    2
7    2
8    2
9    3
dtype: int64

In [32]: rem
Out[32]: 
0    0
1    1
2    2
3    0
4    1
5    2
6    0
7    1
8    2
9    0
dtype: int64

In [33]: idx = pd.Index(np.arange(10))

In [34]: idx
Out[34]: Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')

In [35]: div, rem = divmod(idx, 3)

In [36]: div
Out[36]: Int64Index([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype='int64')

In [37]: rem
Out[37]: Int64Index([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype='int64')
```

我们也可以按元素执行[divmod()](https://docs.python.org/3/library/functions.html#divmod)：

```python
In [38]: div, rem = divmod(s, [2, 2, 3, 3, 4, 4, 5, 5, 6, 6])

In [39]: div
Out[39]: 
0    0
1    0
2    0
3    1
4    1
5    1
6    1
7    1
8    1
9    1
dtype: int64

In [40]: rem
Out[40]: 
0    0
1    1
2    2
3    0
4    0
5    1
6    1
7    2
8    2
9    3
dtype: int64
```

##### 9.4.2 缺失数据/操作填充值

在Series和DataFrame中，算术函数有一个输入`fill_value`的选项，也就是说，一个位置上只要有数据缺失就会被替换。例如，当把两个DataFrame相加时，你可能希望把NaN处理成0，当两个DataFrame都缺失了那个数据时才处理成NaN（如果你愿意，你可以在后面使用`fillna`把NaN替换为其他的数值）

```python
In [41]: df
Out[41]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [42]: df2
Out[42]: 
        one       two     three
a -1.101558  1.124472  1.000000
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [43]: df + df2
Out[43]: 
        one       two     three
a -2.203116  2.248945       NaN
b -0.354579  4.974208 -1.268586
c  0.924429 -0.972131  3.862388
d       NaN -0.912575 -2.445837

In [44]: df.add(df2, fill_value=0)
Out[44]: 
        one       two     three
a -2.203116  2.248945  1.000000
b -0.354579  4.974208 -1.268586
c  0.924429 -0.972131  3.862388
d       NaN -0.912575 -2.445837
```

##### 9.4.3 灵活的对比

Series和DataFrame有一些二进制对比方法`eq`， `ne`， `lt`，`gt`，`le`和`ge`，这些方法和上面二进制算术操作类似：

```python
In [45]: df.gt(df2)
Out[45]: 
     one    two  three
a  False  False  False
b  False  False  False
c  False  False  False
d  False  False  False

In [46]: df2.ne(df)
Out[46]: 
     one    two  three
a  False  False   True
b  False  False  False
c  False  False  False
d   True  False  False
```

这些操作产生一个和bool类型左手边的输入有相同数据类型的Pandas对象，这些布尔对象可以在索引操作中使用，查看[布尔索引](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing-boolean)章节，获得更多信息。

##### 9.4.4 布尔规约操作

你可以调用这些规约操作：[empty](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.empty.html#pandas.DataFrame.empty)，[any()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.any.html#pandas.DataFrame.any)， [all()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.all.html#pandas.DataFrame.all)和[bool](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.bool.html#pandas.DataFrame.bool)来为总结一个布尔结果提供一种方式。

```python
In [47]: (df > 0).all()
Out[47]: 
one      False
two      False
three    False
dtype: bool

In [48]: (df > 0).any()
Out[48]: 
one      True
two      True
three    True
dtype: bool
```

你可以通过规约得到最终的布尔值

```python
In [49]: (df > 0).any().any()
Out[49]: True
```

通过empty属性测试一个Pandas对象是不是空的：

```python
In [50]: df.empty
Out[50]: False

In [51]: pd.DataFrame(columns=list('ABC')).empty
Out[51]: True
```

通过[bool()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.bool.html#pandas.DataFrame.bool)方法在一个布尔环境中评估一个单元素的Pandas对象：

```python
In [52]: pd.Series([True]).bool()
Out[52]: True

In [53]: pd.Series([False]).bool()
Out[53]: False

In [54]: pd.DataFrame([[True]]).bool()
Out[54]: True

In [55]: pd.DataFrame([[False]]).bool()
Out[55]: False
```

> 注意：你可以想要尝试下面的操作：
>
> ```python
> >>> if df:
>      ...
> ```
>
> 或
>
> ```python
> >>> df and df2
> ```
>
> 这都会触发错误，因为你在尝试比较多个值。
>
> ```python
> ValueError: The truth value of an array is ambiguous. Use a.empty, a.any() or a.all().
> ```

查看[陷阱](http://pandas.pydata.org/pandas-docs/version/0.23/gotchas.html#gotchas-truth)，获得更多的讨论信息。

##### 9.4.5 比较对象是否相等

你经常可以发现，计算同一个结果可能有不同的方法。一个简单的例子，考虑`df + df`和`df * 2`。为了测试这两种计算是否会得到相同的结果，参考上面给出的工具，你可能想要使用`(df + df == df * 2).all()`。但是，这个表达式实际上是有欺骗性的。

```python
In [56]: df+df == df*2
Out[56]: 
     one   two  three
a   True  True  False
b   True  True   True
c   True  True   True
d  False  True   True

In [57]: (df+df == df*2).all()
Out[57]: 
one      False
two       True
three    False
dtype: bool
```

注意，`df + df == df * 2`得到的布尔DataFrame包含了一些False值。这是因为NaN值是不相等的。

```python
In [58]: np.nan == np.nan
Out[58]: False
```

所以，NDFrames （比如Series，DataFrame和Panel）有一个[equals()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.equals.html#pandas.DataFrame.equals)方法来比较是否相等。[equals()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.equals.html#pandas.DataFrame.equals)方法会将相关位置上的NaN值按相等处理。

```python
In [59]: (df+df).equals(df*2)
Out[59]: True
```

注意，Series和DataFrame的索引必须是相同的顺序，才会得到True。

```python
In [60]: df1 = pd.DataFrame({'col':['foo', 0, np.nan]})

In [61]: df2 = pd.DataFrame({'col':[np.nan, 0, 'foo']}, index=[2,1,0])

In [62]: df1.equals(df2)
Out[62]: False

In [63]: df1.equals(df2.sort_index())
Out[63]: True
```

##### 9.4.6 比较类数组对象

你可以很方便的按元素比较一个Pandas数据结构和一个标量

```python
In [64]: pd.Series(['foo', 'bar', 'baz']) == 'foo'
Out[64]: 
0     True
1    False
2    False
dtype: bool

In [65]: pd.Index(['foo', 'bar', 'baz']) == 'foo'
Out[65]: array([ True, False, False], dtype=bool)
```

Pandas也可以在长度相同的类数组对象之间按元素比较：

```python
In [66]: pd.Series(['foo', 'bar', 'baz']) == pd.Index(['foo', 'bar', 'qux'])
Out[66]: 
0     True
1     True
2    False
dtype: bool

In [67]: pd.Series(['foo', 'bar', 'baz']) == np.array(['foo', 'bar', 'qux'])
Out[67]: 
0     True
1     True
2    False
dtype: bool
```

比较不同长度的Index或Series对象将会触发ValueError：

```python
In [55]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo', 'bar'])
ValueError: Series lengths must match to compare

In [56]: pd.Series(['foo', 'bar', 'baz']) == pd.Series(['foo'])
ValueError: Series lengths must match to compare
```

注意，这与Numpy的处理方式不同，在Numpy中，一个表达式可以广播：

```python
In [68]: np.array([1, 2, 3]) == np.array([2])
Out[68]: array([False,  True, False], dtype=bool)
```

或者，在不能广播的情况下，返回False

```python
In [69]: np.array([1, 2, 3]) == np.array([1, 2])
Out[69]: False
```

##### 9.4.7 合并重叠的数据集

偶尔出现的一个问题是，合并两个相似的数据集时，其中一个数据集的数比另一个优先度高。比如，两个表现特定的经济指标的数据序列，其中一个被认为"质量更高"。但是，低质量的序列可能在历史上可以回溯的更远或覆盖范围更全。同样的，我们希望合并两个DataFrame，其中一个DataFrame的缺失值有条件地以另一个DataFrame的同标签值替换。实现这种操作的函数是[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)。举例来说：

```python
In [70]: df1 = pd.DataFrame({'A' : [1., np.nan, 3., 5., np.nan],
   ....:                     'B' : [np.nan, 2., 3., np.nan, 6.]})
   ....: 

In [71]: df2 = pd.DataFrame({'A' : [5., 2., 4., np.nan, 3., 7.],
   ....:                     'B' : [np.nan, np.nan, 3., 4., 6., 8.]})
   ....: 

In [72]: df1
Out[72]: 
     A    B
0  1.0  NaN
1  NaN  2.0
2  3.0  3.0
3  5.0  NaN
4  NaN  6.0

In [73]: df2
Out[73]: 
     A    B
0  5.0  NaN
1  2.0  NaN
2  4.0  3.0
3  NaN  4.0
4  3.0  6.0
5  7.0  8.0

In [74]: df1.combine_first(df2)
Out[74]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
```

##### 9.4.8 一般的DataFrame合并

上面的[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)函数调用了更一般的[DataFrame.combine()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine.html#pandas.DataFrame.combine) 。这个方法接受另一个DataFrame和合并函数，对齐输入的DataFrame，然后传入合并函数一对Series（即：这些列的名称是相同的）。

所以，例如，重新生成上面的[combine_first()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.combine_first.html#pandas.DataFrame.combine_first)：

```python
In [75]: combiner = lambda x, y: np.where(pd.isna(x), y, x)

In [76]: df1.combine(df2, combiner)
Out[76]: 
     A    B
0  1.0  NaN
1  2.0  2.0
2  3.0  3.0
3  5.0  4.0
4  3.0  6.0
5  7.0  8.0
```

#### 9.5 描述统计

[Series](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-series-stats)，[DataFrame](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-dataframe-stats)和[Panel](http://pandas.pydata.org/pandas-docs/version/0.23/api.html#api-panel-stats)有大量计算描述统计值的方法和相关操作。这些操作中大部分都是聚合操作（进而产生一个低纬度的结果），比如[sum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sum.html#pandas.DataFrame.sum)，[mean()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.mean.html#pandas.DataFrame.mean)和[quantile()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.quantile.html#pandas.DataFrame.quantile)，但是其中的一部分操作，比如[cumsum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum)和[cumprod()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod)，会产生一个同样大小的对象。一般而言，这些操作会有一个**轴**参数，比如ndarray，{sum，std，……}，但是这个轴可以用名称或整数来指定：

- Series：不需要轴参数。
- DataFrame："index"（axis=0）或"columns"（axis=1）。
- Panel："items"（axis=1），"major"（axis=1，默认）,"minor"（axis=2）。

举例：

```python
In [77]: df
Out[77]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [78]: df.mean(0)
Out[78]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [79]: df.mean(1)
Out[79]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64
```

所有这些操作都有一个**skipna**选项来标记是否排除缺失值。默认为True（排除）。

```python
In [80]: df.sum(0, skipna=False)
Out[80]: 
one           NaN
two      2.669223
three         NaN
dtype: float64

In [81]: df.sum(axis=1, skipna=True)
Out[81]: 
a    0.022914
b    1.675522
c    1.907343
d   -1.679206
dtype: float64
```

合并广播和算术操作，可以描述各种统计程序，比如标准化（将数据转化为均值为0，标准差为1的数据），非常简洁：

```python
In [82]: ts_stand = (df - df.mean()) / df.std()

In [83]: ts_stand.std()
Out[83]: 
one      1.0
two      1.0
three    1.0
dtype: float64

In [84]: xs_stand = df.sub(df.mean(1), axis=0).div(df.std(1), axis=0)

In [85]: xs_stand.std(1)
Out[85]: 
a    1.0
b    1.0
c    1.0
d    1.0
dtype: float64
```

注意，类似[cumsum()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumsum.html#pandas.DataFrame.cumsum)和[cumprod()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.cumprod.html#pandas.DataFrame.cumprod)的方法保留了缺失值的位置。这与[expanding()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.expanding.html#pandas.DataFrame.expanding)和[rolling()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rolling.html#pandas.DataFrame.rolling)略有不同。更多的细节，请查阅[这里](http://pandas.pydata.org/pandas-docs/version/0.23/computation.html#stats-moments-expanding-note)。

```python
In [86]: df.cumsum()
Out[86]: 
        one       two     three
a -1.101558  1.124472       NaN
b -1.278848  3.611576 -0.634293
c -0.816633  3.125511  1.296901
d       NaN  2.669223  0.073983
```

这里有一个常见函数的速查表。如果被操作的对象含有[多级索引](http://pandas.pydata.org/pandas-docs/version/0.23/advanced.html#advanced-hierarchical)，每个函数还有一个level参数。

| 函数       | 描述             |
| ---------- | ---------------- |
| `count`    | 非空观察值的个数 |
| `sum`      | 数值的和         |
| `mean`     | 数值的平均值     |
| `mad`      | 平均绝对偏差     |
| `median`   | 数值的算术平均值 |
| `min`      | 最小值           |
| `max`      | 最大值           |
| `mode`     | 众数             |
| `abs`      | 绝对值           |
| `prod`     | 数值的乘积       |
| `std`      | 标准差           |
| `var`      | 方差             |
| `sem`      | 平均值的标准误   |
| `skew`     | 样本偏度         |
| `kurt`     | 样本峰度         |
| `quantile` | 分位数           |
| `cumsum`   | 累加值           |
| `cumprod`  | 累乘值           |
| `cummax`   | 累计最大值       |
| `cummin`   | 累计最小值       |

 注意，意外地，一些Numpy方法，比如mean，std和sum，会默认排除输入的Series中的NA值：

```python
In [87]: np.mean(df['one'])
Out[87]: -0.27221094480450114

In [88]: np.mean(df['one'].values)
Out[88]: nan
```

[`Series.nunique()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.nunique.html#pandas.Series.nunique) 将返回Series中唯一的非空数据的个数：

```python
In [89]: series = pd.Series(np.random.randn(500))

In [90]: series[20:500] = np.nan

In [91]: series[10:20]  = 5

In [92]: series.nunique()
Out[92]: 11
```

##### 9.5.1 数据概览：描述

有一个非常方便的函数[`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe) 来计算一个Series或DataFrame的若干列的摘要统计（默认排除空值）：

```python
In [93]: series = pd.Series(np.random.randn(1000))

In [94]: series[::2] = np.nan

In [95]: series.describe()
Out[95]: 
count    500.000000
mean      -0.032127
std        1.067484
min       -3.463789
25%       -0.725523
50%       -0.053230
75%        0.679790
max        3.120271
dtype: float64

In [96]: frame = pd.DataFrame(np.random.randn(1000, 5), columns=['a', 'b', 'c', 'd', 'e'])

In [97]: frame.iloc[::2] = np.nan

In [98]: frame.describe()
Out[98]: 
                a           b           c           d           e
count  500.000000  500.000000  500.000000  500.000000  500.000000
mean    -0.045109   -0.052045    0.024520    0.006117    0.001141
std      1.029268    1.002320    1.042793    1.040134    1.005207
min     -2.915767   -3.294023   -3.610499   -2.907036   -3.010899
25%     -0.763783   -0.720389   -0.609600   -0.665896   -0.682900
50%     -0.086033   -0.048843    0.006093    0.043191   -0.001651
75%      0.663399    0.620980    0.728382    0.735973    0.656439
max      3.400646    2.925597    3.416896    3.331522    3.007143
```

你可以选择特定的分位数来输出：

```python
In [99]: series.describe(percentiles=[.05, .25, .75, .95])
Out[99]: 
count    500.000000
mean      -0.032127
std        1.067484
min       -3.463789
5%        -1.733545
25%       -0.725523
50%       -0.053230
75%        0.679790
95%        1.854383
max        3.120271
dtype: float64
```

默认地，结果中一直包含平均值。

对于非数值Series对象， [`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.describe.html#pandas.Series.describe)将给出唯一数据个数和最常出现的数值的简单摘要：

```python
In [100]: s = pd.Series(['a', 'a', 'b', 'b', 'a', 'a', np.nan, 'c', 'd', 'a'])

In [101]: s.describe()
Out[101]: 
count     9
unique    4
top       a
freq      5
dtype: object
```

注意，在混合类型的DataFrame对象上，[`describe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.describe.html#pandas.DataFrame.describe) 将限制摘要只包含数值列，或（如果没有数值列），包含类别列：

```python
In [102]: frame = pd.DataFrame({'a': ['Yes', 'Yes', 'No', 'No'], 'b': range(4)})

In [103]: frame.describe()
Out[103]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000
```

这个操作行为可以通过给定一个类型列表作为 `include`或`exclude` 参数来控制。特别的值`all`也可以使用：

```python
In [104]: frame.describe(include=['object'])
Out[104]: 
          a
count     4
unique    2
top     Yes
freq      2

In [105]: frame.describe(include=['number'])
Out[105]: 
              b
count  4.000000
mean   1.500000
std    1.290994
min    0.000000
25%    0.750000
50%    1.500000
75%    2.250000
max    3.000000

In [106]: frame.describe(include='all')
Out[106]: 
          a         b
count     4  4.000000
unique    2       NaN
top     Yes       NaN
freq      2       NaN
mean    NaN  1.500000
std     NaN  1.290994
min     NaN  0.000000
25%     NaN  0.750000
50%     NaN  1.500000
75%     NaN  2.250000
max     NaN  3.000000
```

这个特性依赖于 [select_dtypes](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-selectdtypes) 。可以到那里查看更多被接受的输入。

##### 9.5.2 最大值/最小值索引

[`idxmin()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin) 和 [`idxmax()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax) 函数计算一个Series和DataFrame的最小值和最大值的索引标签：

```python
In [107]: s1 = pd.Series(np.random.randn(5))

In [108]: s1
Out[108]: 
0   -1.649461
1    0.169660
2    1.246181
3    0.131682
4   -2.001988
dtype: float64

In [109]: s1.idxmin(), s1.idxmax()
Out[109]: (4, 2)

In [110]: df1 = pd.DataFrame(np.random.randn(5,3), columns=['A','B','C'])

In [111]: df1
Out[111]: 
          A         B         C
0 -1.273023  0.870502  0.214583
1  0.088452 -0.173364  1.207466
2  0.546121  0.409515 -0.310515
3  0.585014 -0.490528 -0.054639
4 -0.239226  0.701089  0.228656

In [112]: df1.idxmin(axis=0)
Out[112]: 
A    0
B    3
C    2
dtype: int64

In [113]: df1.idxmax(axis=1)
Out[113]: 
0    B
1    C
2    A
3    A
4    B
dtype: object
```

如果有多个行（或列）满足最大值和最小值，[`idxmin()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmin.html#pandas.DataFrame.idxmin) 和 [`idxmax()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.idxmax.html#pandas.DataFrame.idxmax) 返回第一个符合的索引：

```python
In [114]: df3 = pd.DataFrame([2, 1, 1, 3, np.nan], columns=['A'], index=list('edcba'))

In [115]: df3
Out[115]: 
     A
e  2.0
d  1.0
c  1.0
b  3.0
a  NaN

In [116]: df3['A'].idxmin()
Out[116]: 'd'
```

> 注意：在Numpy中，`idxmin`和`idxmax`称为`argmin`和`argmax`。

##### 9.5.3 计数（直方图）/ 众数

Series的[`value_counts()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.value_counts.html#pandas.Series.value_counts) 方法和顶级函数计算一个一维数组的每个值的个数。它也可以作为一个函数用在一个常规数组上：

```python
In [117]: data = np.random.randint(0, 7, size=50)

In [118]: data
Out[118]: 
array([3, 3, 0, 2, 1, 0, 5, 5, 3, 6, 1, 5, 6, 2, 0, 0, 6, 3, 3, 5, 0, 4, 3,
       3, 3, 0, 6, 1, 3, 5, 5, 0, 4, 0, 6, 3, 6, 5, 4, 3, 2, 1, 5, 0, 1, 1,
       6, 4, 1, 4])

In [119]: s = pd.Series(data)

In [120]: s.value_counts()
Out[120]: 
3    11
0     9
5     8
6     7
1     7
4     5
2     3
dtype: int64

In [121]: pd.value_counts(data)
Out[121]: 
3    11
0     9
5     8
6     7
1     7
4     5
2     3
dtype: int64
```

类似地，你可以得到一个Series或DataFrame的最常出现的数值（众数）:

```python
In [122]: s5 = pd.Series([1, 1, 3, 3, 3, 5, 5, 7, 7, 7])

In [123]: s5.mode()
Out[123]: 
0    3
1    7
dtype: int64

In [124]: df5 = pd.DataFrame({"A": np.random.randint(0, 7, size=50),
   .....:                     "B": np.random.randint(-10, 15, size=50)})
   .....: 

In [125]: df5.mode()
Out[125]: 
   A  B
0  2 -5
```

##### 9.5.4 离散化和求分位数

可以使用[`cut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.cut.html#pandas.cut) （基于数值分段）和[`qcut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.qcut.html#pandas.qcut) （基于样本分位点分段）来离散化连续数值：

```python
In [126]: arr = np.random.randn(20)

In [127]: factor = pd.cut(arr, 4)

In [128]: factor
Out[128]: 
[(-2.611, -1.58], (0.473, 1.499], (-2.611, -1.58], (-1.58, -0.554], (-0.554, 0.473], ..., (0.473, 1.499], (0.473, 1.499], (-0.554, 0.473], (-0.554, 0.473], (-0.554, 0.473]]
Length: 20
Categories (4, interval[float64]): [(-2.611, -1.58] < (-1.58, -0.554] < (-0.554, 0.473] <
                                    (0.473, 1.499]]

In [129]: factor = pd.cut(arr, [-5, -1, 0, 1, 5])

In [130]: factor
Out[130]: 
[(-5, -1], (0, 1], (-5, -1], (-1, 0], (-1, 0], ..., (1, 5], (1, 5], (-1, 0], (-1, 0], (-1, 0]]
Length: 20
Categories (4, interval[int64]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]
```

[`qcut()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.qcut.html#pandas.qcut)计算样本分位点。例如，我们可以把一些普通分布数据切成相等大小的四份：

```python
In [131]: arr = np.random.randn(30)

In [132]: factor = pd.qcut(arr, [0, .25, .5, .75, 1])

In [133]: factor
Out[133]: 
[(0.544, 1.976], (0.544, 1.976], (-1.255, -0.375], (0.544, 1.976], (-0.103, 0.544], ..., (-0.103, 0.544], (0.544, 1.976], (-0.103, 0.544], (-1.255, -0.375], (-0.375, -0.103]]
Length: 30
Categories (4, interval[float64]): [(-1.255, -0.375] < (-0.375, -0.103] < (-0.103, 0.544] <
                                    (0.544, 1.976]]

In [134]: pd.value_counts(factor)
Out[134]: 
(0.544, 1.976]      8
(-1.255, -0.375]    8
(-0.103, 0.544]     7
(-0.375, -0.103]    7
dtype: int64
```

我们也可以传入无穷值来定义分组：

```python
In [135]: arr = np.random.randn(20)

In [136]: factor = pd.cut(arr, [-np.inf, 0, np.inf])

In [137]: factor
Out[137]: 
[(0.0, inf], (0.0, inf], (0.0, inf], (0.0, inf], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (0.0, inf], (-inf, 0.0], (0.0, inf]]
Length: 20
Categories (2, interval[float64]): [(-inf, 0.0] < (0.0, inf]]
```

#### 9.6 调用函数

在Pandas对象上调用你自定义的或其他库中的函数，你应该了解下面的三个方法。至于使用哪个方法，取决于你的函数期望在整个DataFrame、Series、按行、按列还是按元素操作数据。

1. [按表调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#tablewise-function-application)：[`pipe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe) 
2. [按行或列调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#row-or-column-wise-function-application)：[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 
3. [聚合API](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#aggregation-api)：[`agg()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.agg.html#pandas.DataFrame.agg) 和[`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform) 
4. [按元素调用函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#applying-elementwise-functions)：[`applymap()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap) 

##### 9.6.1 按表调用函数

 `DataFrames` 和 `Series`  当然可以作为参数传入一个函数。不过，如果一个函数需要在一个方法链中调用，考虑使用 [`pipe()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe) 方法。对比以下两个表达式：

```python
# f, g, and h are functions taking and returning ``DataFrames``
>>> f(g(h(df), arg1=1), arg2=2, arg3=3)
```

等价的：

```python
>>> (df.pipe(h)
       .pipe(g, arg1=1)
       .pipe(f, arg2=2, arg3=3)
    )
```

Pandas推荐使用第二种方式（方法链）。`pipe `使得在方法链中与Pandas方法一起使用自定义函数或其他库中的函数变得很容易。

在上面的例子中，函数f，g和h，每个都接受DataFrame作为第一位置参数。如果你要调用的函数将它的数据作为第二个参数怎么办？在这种情况下，Pandas提供了pipe方法，包含一个(callable, data_keyword)元组。pipe将DataFrame指向该元组的指定参数。

例如，我们可以使用statsmodels做回归拟合。他们的API接受一个公式（作为第一个参数），一个DataFrame作为第二个参数`data`。我们为pipe向这个函数传入关键词对(sm.ols,'data')：

```python
In [138]: import statsmodels.formula.api as sm

In [139]: bb = pd.read_csv('data/baseball.csv', index_col='id')

In [140]: (bb.query('h > 0')
   .....:    .assign(ln_h = lambda df: np.log(df.h))
   .....:    .pipe((sm.ols, 'data'), 'hr ~ ln_h + year + g + C(lg)')
   .....:    .fit()
   .....:    .summary()
   .....: )
   .....: 
Out[140]: 
<class 'statsmodels.iolib.summary.Summary'>
"""
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                     hr   R-squared:                       0.685
Model:                            OLS   Adj. R-squared:                  0.665
Method:                 Least Squares   F-statistic:                     34.28
Date:                Tue, 12 Jun 2018   Prob (F-statistic):           3.48e-15
Time:                        12:53:14   Log-Likelihood:                -205.92
No. Observations:                  68   AIC:                             421.8
Df Residuals:                      63   BIC:                             432.9
Df Model:                           4                                         
Covariance Type:            nonrobust                                         
===============================================================================
                  coef    std err          t      P>|t|      [0.025      0.975]
-------------------------------------------------------------------------------
Intercept   -8484.7720   4664.146     -1.819      0.074   -1.78e+04     835.780
C(lg)[T.NL]    -2.2736      1.325     -1.716      0.091      -4.922       0.375
ln_h           -1.3542      0.875     -1.547      0.127      -3.103       0.395
year            4.2277      2.324      1.819      0.074      -0.417       8.872
g               0.1841      0.029      6.258      0.000       0.125       0.243
==============================================================================
Omnibus:                       10.875   Durbin-Watson:                   1.999
Prob(Omnibus):                  0.004   Jarque-Bera (JB):               17.298
Skew:                           0.537   Prob(JB):                     0.000175
Kurtosis:                       5.225   Cond. No.                     1.49e+07
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.49e+07. This might indicate that there are
strong multicollinearity or other numerical problems.
"""
```

pipe方法受到Unix管道和更近的为R引入流行的（%>%）（读管道）的[dplyr](https://github.com/hadley/dplyr) 和[magrittr](https://github.com/smbache/magrittr) 的启发。这里，pipe的实现非常干净，在Python中感觉很好。我们鼓励你去读一下[源码](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.pipe.html#pandas.DataFrame.pipe)。

##### 9.6.2 按行、按列调用函数

可以使用[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 方法在DataFrame的一个轴上调用任意函数，比如，描述统计方法，就有一个axis参数：

```python
In [141]: df.apply(np.mean)
Out[141]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [142]: df.apply(np.mean, axis=1)
Out[142]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64

In [143]: df.apply(lambda x: x.max() - x.min())
Out[143]: 
one      1.563773
two      2.973170
three    3.154112
dtype: float64

In [144]: df.apply(np.cumsum)
Out[144]: 
        one       two     three
a -1.101558  1.124472       NaN
b -1.278848  3.611576 -0.634293
c -0.816633  3.125511  1.296901
d       NaN  2.669223  0.073983

In [145]: df.apply(np.exp)
Out[145]: 
        one        two    three
a  0.332353   3.078592      NaN
b  0.837537  12.026397  0.53031
c  1.587586   0.615041  6.89774
d       NaN   0.633631  0.29437
```

[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 方法也能够调用字符串方法名：

```python
In [146]: df.apply('mean')
Out[146]: 
one     -0.272211
two      0.667306
three    0.024661
dtype: float64

In [147]: df.apply('mean', axis=1)
Out[147]: 
a    0.011457
b    0.558507
c    0.635781
d   -0.839603
dtype: float64
```

传入[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)的函数返回值的类型会影响`DataFrame.apply`默认的最终的输出。

- 如果传入的函数返回Series，最终输出DataFrame。调用的函数返回匹配Series的索引的列。
- 如果传入的函数返回其他的类型，最终输出Series。

这种默认处理方式可以通过`result_type`来覆写，`result_type`接受三种选项：`reduce`，`broadcast`和`expand`。这将决定类列表返回值如何扩展（或不扩展）成DataFrame。

[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)合结合一些聪明的处理方式可以解决很多数据集的问题。例如，假设我们想要提取每列最大值对应的日期：

```python
In [148]: tsdf = pd.DataFrame(np.random.randn(1000, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=1000))
   .....: 

In [149]: tsdf.apply(lambda x: x.idxmax())
Out[149]: 
A   2001-04-25
B   2002-05-31
C   2002-09-25
dtype: datetime64[ns]
```

你也可以为[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)方法传入额外的参数和关键字参数。比如，考虑接下来这个你想调用的函数：

```python
def subtract_and_divide(x, sub, divide=1):
    return (x - sub) / divide
```

你可以这么调用：

```python
df.apply(subtract_and_divide, args=(5,), divide=3)
```

另一个有用的特性是能够传入Series方法在每一列或行上执行Series操作：

```python
In [150]: tsdf
Out[150]: 
                   A         B         C
2000-01-01 -0.720299  0.546303 -0.082042
2000-01-02  0.200295 -0.577554 -0.908402
2000-01-03  0.102533  1.653614  0.303319
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.532566  0.341548  0.150493
2000-01-09  0.330418  1.761200  0.567133
2000-01-10 -0.251020  1.020099  1.893177

In [151]: tsdf.apply(pd.Series.interpolate)
Out[151]: 
                   A         B         C
2000-01-01 -0.720299  0.546303 -0.082042
2000-01-02  0.200295 -0.577554 -0.908402
2000-01-03  0.102533  1.653614  0.303319
2000-01-04  0.188539  1.391201  0.272754
2000-01-05  0.274546  1.128788  0.242189
2000-01-06  0.360553  0.866374  0.211624
2000-01-07  0.446559  0.603961  0.181059
2000-01-08  0.532566  0.341548  0.150493
2000-01-09  0.330418  1.761200  0.567133
2000-01-10 -0.251020  1.020099  1.893177
```

最后， [`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)  有一个`raw`参数，默认值为False，在调用函数之前将每一行或列转变为Series。当设为True时，传入的函数变为接收一个ndarray对象，在不需要操作索引时，能够提升性能。

##### 9.6.3 聚合API

0.20.0版本新特性。

聚合API允许使用者以一个简洁的方式表达可能的多种聚合操作。这个API类似于Pandas对象，查看[分组 API](http://pandas.pydata.org/pandas-docs/version/0.23/groupby.html#groupby-aggregate)，[窗口函数API](http://pandas.pydata.org/pandas-docs/version/0.23/computation.html#stats-aggregate)和[重采样API](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html#timeseries-aggregate)。聚合操作的入口是 [`DataFrame.aggregate()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.aggregate.html#pandas.DataFrame.aggregate) 或其别名[`DataFrame.agg()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.agg.html#pandas.DataFrame.agg)。

我们将用一个类似上面的起始数据框（开始）：

```python
In [152]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [153]: tsdf.iloc[3:7] = np.nan

In [154]: tsdf
Out[154]: 
                   A         B         C
2000-01-01  0.170247 -0.916844  0.835024
2000-01-02  1.259919  0.801111  0.445614
2000-01-03  1.453046  2.430373  0.653093
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -1.874526  0.569822 -0.609644
2000-01-09  0.812462  0.565894 -1.461363
2000-01-10 -0.985475  1.388154 -0.078747
```

使用一个单独的函数等价于调用[`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 。你也可以传入以字符串命名的方法。作为聚合操作的输出，这些将会返回一个Series：

```python
In [155]: tsdf.agg(np.sum)
Out[155]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64

In [156]: tsdf.agg('sum')
Out[156]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64

# these are equivalent to a ``.sum()`` because we are aggregating on a single function
In [157]: tsdf.sum()
Out[157]: 
A    0.835673
B    4.838510
C   -0.216025
dtype: float64
```

在一个Series上执行单独的聚合操作将返回一个标量：

```pyhton
In [158]: tsdf.A.agg('sum')
Out[158]: 0.83567297915820504
```

###### 9.6.3.1 调用多个函数执行聚合操作

你可以传入多个聚合参数组成的列表。每一个传入的函数的返回结果将会是结果DataFrame中的一行。这些都是自然地有聚合函数命名的：

```python
In [159]: tsdf.agg(['sum'])
Out[159]: 
            A        B         C
sum  0.835673  4.83851 -0.216025
```

多个函数生成多个行：

```python
In [160]: tsdf.agg(['sum', 'mean'])
Out[160]: 
             A         B         C
sum   0.835673  4.838510 -0.216025
mean  0.139279  0.806418 -0.036004
```

在一个Series上执行多个聚合操作，返回一个Series，这个Series的索引由聚合函数命名：

```python
In [161]: tsdf.A.agg(['sum', 'mean'])
Out[161]: 
sum     0.835673
mean    0.139279
Name: A, dtype: float64
```

传入lambda匿名函数，将生成一个由`<lambda>`命名的行：

```python
In [162]: tsdf.A.agg(['sum', lambda x: x.mean()])
Out[162]: 
sum         0.835673
<lambda>    0.139279
Name: A, dtype: float64
```

传入一个命名函数，将生成一个命名为该函数名的行：

```python
In [163]: def mymean(x):
   .....:    return x.mean()
   .....: 

In [164]: tsdf.A.agg(['sum', mymean])
Out[164]: 
sum       0.835673
mymean    0.139279
Name: A, dtype: float64
```

###### 9.6.3.2 使用字典执行聚合操作

为`DataFrame.agg`传入一个列名作为键，一个标量或标量列表作为值的字典，允许你自定义哪个列调用哪个函数。注意，结果没有排序，你可以使用一个`OrderedDict`替代保证排序。

```python
In [165]: tsdf.agg({'A': 'mean', 'B': 'sum'})
Out[165]: 
A    0.139279
B    4.838510
dtype: float64
```

传入列表将生产一个DataFrame输出。你将得到一个含有所有聚合操作的类矩阵输出。这个输出由所有的独立函数组成。那些没有执行聚合操作的列会返回NaN：

```python 
In [166]: tsdf.agg({'A': ['mean', 'min'], 'B': 'sum'})
Out[166]: 
             A        B
mean  0.139279      NaN
min  -1.874526      NaN
sum        NaN  4.83851
```

###### 9.6.3.3 混合数据类型 

当提供的数据为不能执行聚合操作的混合数据类型时，`.agg`将只执行合法的聚合操作。这个分组中的`.agg`工作模式相似：

```python
In [167]: mdf = pd.DataFrame({'A': [1, 2, 3],
   .....:                     'B': [1., 2., 3.],
   .....:                     'C': ['foo', 'bar', 'baz'],
   .....:                     'D': pd.date_range('20130101', periods=3)})
   .....: 

In [168]: mdf.dtypes
Out[168]: 
A             int64
B           float64
C            object
D    datetime64[ns]
dtype: object
```

```python
In [169]: mdf.agg(['min', 'sum'])
Out[169]: 
     A    B          C          D
min  1  1.0        bar 2013-01-01
sum  6  6.0  foobarbaz        NaT
```

###### 9.6.3.4 自定义描述

使用`.agg`可以很方便地创建自定义描述函数，类似于内置的[描述函数](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-describe)：

```python
In [170]: from functools import partial

In [171]: q_25 = partial(pd.Series.quantile, q=0.25)

In [172]: q_25.__name__ = '25%'

In [173]: q_75 = partial(pd.Series.quantile, q=0.75)

In [174]: q_75.__name__ = '75%'

In [175]: tsdf.agg(['count', 'mean', 'std', 'min', q_25, 'median', q_75, 'max'])
Out[175]: 
               A         B         C
count   6.000000  6.000000  6.000000
mean    0.139279  0.806418 -0.036004
std     1.323362  1.100830  0.874990
min    -1.874526 -0.916844 -1.461363
25%    -0.696544  0.566876 -0.476920
median  0.491354  0.685467  0.183433
75%     1.148055  1.241393  0.601223
max     1.453046  2.430373  0.835024
```

##### 9.6.4 转换API

0.20.0版本新特性

 [`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform)  方法返回一个和原始索引相同（相同大小）的对象。这个API允许你同时提供多个操作，而不是一个接着一个。它的API和`.agg`的API很相似。

我们创建一个数据框，和上一节用到的类似。

```python
In [176]: tsdf = pd.DataFrame(np.random.randn(10, 3), columns=['A', 'B', 'C'],
   .....:                     index=pd.date_range('1/1/2000', periods=10))
   .....: 

In [177]: tsdf.iloc[3:7] = np.nan

In [178]: tsdf
Out[178]: 
                   A         B         C
2000-01-01 -0.578465 -0.503335 -0.987140
2000-01-02 -0.767147 -0.266046  1.083797
2000-01-03  0.195348  0.722247 -0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08 -0.556397  0.542165 -0.308675
2000-01-09 -1.010924 -0.672504 -1.139222
2000-01-10  0.354653  0.563622 -0.365106
```

对整个数据框执行转换操作，`.tranform()`允许输入函数是：一个Numpy函数，一个字符串函数名或用户自定义函数。

```python
In [179]: tsdf.transform(np.abs)
Out[179]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106

In [180]: tsdf.transform('abs')
Out[180]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106

In [181]: tsdf.transform(lambda x: x.abs())
Out[181]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106
```

这里 [`transform()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.transform.html#pandas.DataFrame.transform)  接受了一个单独的函数，等价于调用Numpy的全局函数：

```python
In [182]: np.abs(tsdf)
Out[182]: 
                   A         B         C
2000-01-01  0.578465  0.503335  0.987140
2000-01-02  0.767147  0.266046  1.083797
2000-01-03  0.195348  0.722247  0.894537
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  0.542165  0.308675
2000-01-09  1.010924  0.672504  1.139222
2000-01-10  0.354653  0.563622  0.365106
```

在Series上为`.transform()`传入一个单独的函数，将返回一个Series：

```python
In [183]: tsdf.A.transform(np.abs)
Out[183]: 
2000-01-01    0.578465
2000-01-02    0.767147
2000-01-03    0.195348
2000-01-04         NaN
2000-01-05         NaN
2000-01-06         NaN
2000-01-07         NaN
2000-01-08    0.556397
2000-01-09    1.010924
2000-01-10    0.354653
Freq: D, Name: A, dtype: float64
```

###### 9.6.4.1 使用多个函数进行转换

传入多个函数，将会生成一个列多级索引的DataFrame。第一级将会是原始数据框的列名，第二级将会是变换函数的名称：

```python
In [184]: tsdf.transform([np.abs, lambda x: x+1])
Out[184]: 
                   A                   B                   C          
            absolute  <lambda>  absolute  <lambda>  absolute  <lambda>
2000-01-01  0.578465  0.421535  0.503335  0.496665  0.987140  0.012860
2000-01-02  0.767147  0.232853  0.266046  0.733954  1.083797  2.083797
2000-01-03  0.195348  1.195348  0.722247  1.722247  0.894537  0.105463
2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN
2000-01-08  0.556397  0.443603  0.542165  1.542165  0.308675  0.691325
2000-01-09  1.010924 -0.010924  0.672504  0.327496  1.139222 -0.139222
2000-01-10  0.354653  1.354653  0.563622  1.563622  0.365106  0.634894
```

为Series传入多个函数，将生成一个DataFrame，结果的列名将会是转换函数名：

```python
In [185]: tsdf.A.transform([np.abs, lambda x: x+1])
Out[185]: 
            absolute  <lambda>
2000-01-01  0.578465  0.421535
2000-01-02  0.767147  0.232853
2000-01-03  0.195348  1.195348
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  0.443603
2000-01-09  1.010924 -0.010924
2000-01-10  0.354653  1.354653
```

###### 9.6.4.2 使用字典进行转换

传入一个函数字典，将允许每列有选择的转换。

```python
In [186]: tsdf.transform({'A': np.abs, 'B': lambda x: x+1})
Out[186]: 
                   A         B
2000-01-01  0.578465  0.496665
2000-01-02  0.767147  0.733954
2000-01-03  0.195348  1.722247
2000-01-04       NaN       NaN
2000-01-05       NaN       NaN
2000-01-06       NaN       NaN
2000-01-07       NaN       NaN
2000-01-08  0.556397  1.542165
2000-01-09  1.010924  0.327496
2000-01-10  0.354653  1.563622
```

转入一个含有列表的字典，将返回一个多级索引的DataFrame：

```python
In [187]: tsdf.transform({'A': np.abs, 'B': [lambda x: x+1, 'sqrt']})
Out[187]: 
                   A         B          
            absolute  <lambda>      sqrt
2000-01-01  0.578465  0.496665       NaN
2000-01-02  0.767147  0.733954       NaN
2000-01-03  0.195348  1.722247  0.849851
2000-01-04       NaN       NaN       NaN
2000-01-05       NaN       NaN       NaN
2000-01-06       NaN       NaN       NaN
2000-01-07       NaN       NaN       NaN
2000-01-08  0.556397  1.542165  0.736318
2000-01-09  1.010924  0.327496       NaN
2000-01-10  0.354653  1.563622  0.750748
```
##### 9.6.5 调用按元素执行的函数
因为并不是所有的函数都能向量化（接受Numpy数组，返回另一个数组或值），Pandas提供了一个在applymap()方法，允许在DataFrame上执行，接受任意的单参数单返回值的Python函数。类似地，在Series上执行map()方法，也是一样。例如：
```python
In [188]: df4
Out[188]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [189]: f = lambda x: len(str(x))

In [190]: df4['one'].map(f)
Out[190]: 
a    19
b    20
c    18
d     3
Name: one, dtype: int64

In [191]: df4.applymap(f)
Out[191]: 
   one  two  three
a   19   18      3
b   20   18     19
c   18   20     18
d    3   19     19
```
Series.map()还有附加属性：它可以用来方便地"链接"或"映射"被第二个Series定义的值。这与[合并/连](http://pandas.pydata.org/pandas-docs/version/0.23/merging.html#merging)接功能密切相关：
```python
In [192]: s = pd.Series(['six', 'seven', 'six', 'seven', 'six'],
   .....:               index=['a', 'b', 'c', 'd', 'e'])
   .....: 

In [193]: t = pd.Series({'six' : 6., 'seven' : 7.})

In [194]: s
Out[194]: 
a      six
b    seven
c      six
d    seven
e      six
dtype: object

In [195]: s.map(t)
Out[195]: 
a    6.0
b    7.0
c    6.0
d    7.0
e    6.0
dtype: float64
```
##### 9.6.6 在Panel上调用函数
从略
#### 9.7 重建索引、改变标签

[`reindex()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.reindex.html#pandas.Series.reindex) 是Pandas数据规整的基本方法。它用来执行几乎所有的依赖标签对齐函数的其他特性。重建索引，意味着把数据与特定轴上的一组标签集匹配。这实现了几件事：

- 重新排序数据来匹配新的标签集。
- 在没有值匹配给定标签的位置插入缺失值标记（NA）。
- 如果指定，对缺失标签使用逻辑填充数据（与时间序列数据高度相关）。

下面是一个示例：

```python
In [216]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [217]: s
Out[217]: 
a   -0.454087
b   -0.360309
c   -0.951631
d   -0.535459
e    0.835231
dtype: float64

In [218]: s.reindex(['e', 'b', 'f', 'd'])
Out[218]: 
e    0.835231
b   -0.360309
f         NaN
d   -0.535459
dtype: float64
```

这里，`f`标签没有包含在Series中，因此在最终的结果中以NaN出现。

对于DataFrame，可以同时对行和列重建索引：

```python
In [219]: df
Out[219]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [220]: df.reindex(index=['c', 'f', 'b'], columns=['three', 'two', 'one'])
Out[220]: 
      three       two       one
c  1.931194 -0.486066  0.462215
f       NaN       NaN       NaN
b -0.634293  2.487104 -0.177289
```

也可以在使用reindex的时候传入axis关键字：

```python
In [221]: df.reindex(['c', 'f', 'b'], axis='index')
Out[221]: 
        one       two     three
c  0.462215 -0.486066  1.931194
f       NaN       NaN       NaN
b -0.177289  2.487104 -0.634293
```

注意，包含实际axis标签的Index对象可以在对象之间共享。因此，如果我们有一个Series和DataFrame，可以执行下面的操作：

```python
In [222]: rs = s.reindex(df.index)

In [223]: rs
Out[223]: 
a   -0.454087
b   -0.360309
c   -0.951631
d   -0.535459
dtype: float64

In [224]: rs.index is df.index
Out[224]: True
```

这意味着，重建索引之后的Series索引和DataFrame索引是同样的Python对象。

0.21.0新特性。

[`DataFrame.reindex()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.reindex.html#pandas.DataFrame.reindex) 还支持一个"axis_style"调用惯例：指定一个单独的lables参数和它所调用的axis：

```python
In [225]: df.reindex(['c', 'f', 'b'], axis='index')
Out[225]: 
        one       two     three
c  0.462215 -0.486066  1.931194
f       NaN       NaN       NaN
b -0.177289  2.487104 -0.634293

In [226]: df.reindex(['three', 'two', 'one'], axis='columns')
Out[226]: 
      three       two       one
a       NaN  1.124472 -1.101558
b -0.634293  2.487104 -0.177289
c  1.931194 -0.486066  0.462215
d -1.222918 -0.456288       NaN
```

查看： 

[MultiIndex / Advanced Indexing](http://pandas.pydata.org/pandas-docs/version/0.23/advanced.html#advanced) 是一种更简洁的重建索引方法。

> 当写性能敏感的代码时，有一个很好的理由来花些时间成为重建索引的忍者：许多操作在预先规整之后的数据上执行的更快。将两个DataFrame相加，在内部会默认触发重建索引的步骤。对探索性分析来说，你将很难注意到不同（因为reindex被很大程度的优化过），但是，当CPU周期比较重要时，一些小的显示的重建索引会有影响。

##### 9.7.1 重建索引，和另一个对象对齐

你可能想要对一个对象重建索引，使他的轴标签和另一个对象相同。这一语法很简单，但冗长，它是一个通用的操作，可以用[`reindex_like()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.reindex_like.html#pandas.DataFrame.reindex_like)来简化：

```python
In [227]: df2
Out[227]: 
        one       two
a -1.101558  1.124472
b -0.177289  2.487104
c  0.462215 -0.486066

In [228]: df3
Out[228]: 
        one       two
a -0.829347  0.082635
b  0.094922  1.445267
c  0.734426 -1.527903

In [229]: df.reindex_like(df2)
Out[229]: 
        one       two
a -1.101558  1.124472
b -0.177289  2.487104
c  0.462215 -0.486066
```

##### 9.7.2 使用align在对象之间互相对齐

[`align()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.align.html#pandas.Series.align)方法是同时对齐两个对象的最快方法。它支持一个`join`参数（和 [joining and merging](http://pandas.pydata.org/pandas-docs/version/0.23/merging.html#merging) 有关）：

- `join='outer'`：使用两个对象的索引的并集（默认）
- `join='left'`：使用调用该方法的对象的索引
- `join='right'`：使用作为参数传入该方法的对象的索引
- `join='inner'`：使用两个对象的索引的交集

它将返回一个包含两个重建之后的索引的元组：

```python
In [230]: s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])

In [231]: s1 = s[:4]

In [232]: s2 = s[1:]

In [233]: s1.align(s2)
Out[233]: 
(a    0.505453
 b    1.788110
 c   -0.405908
 d   -0.801912
 e         NaN
 dtype: float64, a         NaN
 b    1.788110
 c   -0.405908
 d   -0.801912
 e    0.768460
 dtype: float64)

In [234]: s1.align(s2, join='inner')
Out[234]: 
(b    1.788110
 c   -0.405908
 d   -0.801912
 dtype: float64, b    1.788110
 c   -0.405908
 d   -0.801912
 dtype: float64)

In [235]: s1.align(s2, join='left')
Out[235]: 
(a    0.505453
 b    1.788110
 c   -0.405908
 d   -0.801912
 dtype: float64, a         NaN
 b    1.788110
 c   -0.405908
 d   -0.801912
 dtype: float64)
```

对DataFrame，join方法会默认在行和列上都执行。

```python
In [236]: df.align(df2, join='inner')
Out[236]: 
(        one       two
 a -1.101558  1.124472
 b -0.177289  2.487104
 c  0.462215 -0.486066,         one       two
 a -1.101558  1.124472
 b -0.177289  2.487104
 c  0.462215 -0.486066)
```

也可以传入axis参数，来指定在特定的列上执行：

```python
In [237]: df.align(df2, join='inner', axis=0)
Out[237]: 
(        one       two     three
 a -1.101558  1.124472       NaN
 b -0.177289  2.487104 -0.634293
 c  0.462215 -0.486066  1.931194,         one       two
 a -1.101558  1.124472
 b -0.177289  2.487104
 c  0.462215 -0.486066)
```

如果为[`DataFrame.align()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.align.html#pandas.DataFrame.align) 传入以Series，可以通过axis参数指定在DataFrame的索引或列上执行：

```python
In [238]: df.align(df2.iloc[0], axis=1)
Out[238]: 
(        one     three       two
 a -1.101558       NaN  1.124472
 b -0.177289 -0.634293  2.487104
 c  0.462215  1.931194 -0.486066
 d       NaN -1.222918 -0.456288, one     -1.101558
 three         NaN
 two      1.124472
 Name: a, dtype: float64)
```

##### 9.7.3 重建索引时填充数据

[`reindex()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.reindex.html#pandas.Series.reindex)有一个参数选项method，它按照下表的方式来填充数据：

| Method           | Action                 |
| ---------------- | ---------------------- |
| pad / ffill      | 使用缺失值前面的值填充 |
| bfill / backfill | 使用缺失值后面的值填充 |
| nearest          | 使用最近的索引的值填充 |

 我们在一个简单的Series演示一下：

```python
In [239]: rng = pd.date_range('1/3/2000', periods=8)

In [240]: ts = pd.Series(np.random.randn(8), index=rng)

In [241]: ts2 = ts[[0, 3, 6]]

In [242]: ts
Out[242]: 
2000-01-03    0.466284
2000-01-04   -0.457411
2000-01-05   -0.364060
2000-01-06    0.785367
2000-01-07   -1.463093
2000-01-08    1.187315
2000-01-09   -0.493153
2000-01-10   -1.323445
Freq: D, dtype: float64

In [243]: ts2
Out[243]: 
2000-01-03    0.466284
2000-01-06    0.785367
2000-01-09   -0.493153
dtype: float64

In [244]: ts2.reindex(ts.index)
Out[244]: 
2000-01-03    0.466284
2000-01-04         NaN
2000-01-05         NaN
2000-01-06    0.785367
2000-01-07         NaN
2000-01-08         NaN
2000-01-09   -0.493153
2000-01-10         NaN
Freq: D, dtype: float64

In [245]: ts2.reindex(ts.index, method='ffill')
Out[245]: 
2000-01-03    0.466284
2000-01-04    0.466284
2000-01-05    0.466284
2000-01-06    0.785367
2000-01-07    0.785367
2000-01-08    0.785367
2000-01-09   -0.493153
2000-01-10   -0.493153
Freq: D, dtype: float64

In [246]: ts2.reindex(ts.index, method='bfill')
Out[246]: 
2000-01-03    0.466284
2000-01-04    0.785367
2000-01-05    0.785367
2000-01-06    0.785367
2000-01-07   -0.493153
2000-01-08   -0.493153
2000-01-09   -0.493153
2000-01-10         NaN
Freq: D, dtype: float64

In [247]: ts2.reindex(ts.index, method='nearest')
Out[247]: 
2000-01-03    0.466284
2000-01-04    0.466284
2000-01-05    0.785367
2000-01-06    0.785367
2000-01-07    0.785367
2000-01-08   -0.493153
2000-01-09   -0.493153
2000-01-10   -0.493153
Freq: D, dtype: float64
```

这些方法要求索引是排好序的。

注意，使用[fillna](http://pandas.pydata.org/pandas-docs/version/0.23/missing_data.html#missing-data-fillna) 或[interpolate](http://pandas.pydata.org/pandas-docs/version/0.23/missing_data.html#missing-data-interpolate) 也可以得到同样的结果（除了`method='nearest'`）：

```python
In [248]: ts2.reindex(ts.index).fillna(method='ffill')
Out[248]: 
2000-01-03    0.466284
2000-01-04    0.466284
2000-01-05    0.466284
2000-01-06    0.785367
2000-01-07    0.785367
2000-01-08    0.785367
2000-01-09   -0.493153
2000-01-10   -0.493153
Freq: D, dtype: float64
```

如果索引不是单调递增或递减，[`reindex()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.reindex.html#pandas.Series.reindex) 将会引发错误。 [`fillna()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.fillna.html#pandas.Series.fillna) 和 [`interpolate()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.interpolate.html#pandas.Series.interpolate) 不会对索引顺序做任何检查。

##### 9.7.4 创建索引时填充数据的限制操作

`limit`和`tolerance`参数为重建索引时填充数据提供了额外的控制选项。`limit`指定连续匹配的最大次数：

```python
In [249]: ts2.reindex(ts.index, method='ffill', limit=1)
Out[249]: 
2000-01-03    0.466284
2000-01-04    0.466284
2000-01-05         NaN
2000-01-06    0.785367
2000-01-07    0.785367
2000-01-08         NaN
2000-01-09   -0.493153
2000-01-10   -0.493153
Freq: D, dtype: float64
```

与之对比，`tolerance`指定索引和索引器的值之间的最大距离：

```pyhton
In [250]: ts2.reindex(ts.index, method='ffill', tolerance='1 day')
Out[250]: 
2000-01-03    0.466284
2000-01-04    0.466284
2000-01-05         NaN
2000-01-06    0.785367
2000-01-07    0.785367
2000-01-08         NaN
2000-01-09   -0.493153
2000-01-10   -0.493153
Freq: D, dtype: float64
```

注意：在DatatimeIndex、TimedeltaIndex或PeriodIndex上使用时，如果可能，`tolerance`将强制转换为Timedelta。这允许你用合适的字符串来制定tolerance。

##### 9.7.5 从一个轴丢弃数据

与reindex()关系密切的一个函数是[`drop()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop) 。它从一个轴移除一些标签集：

```python
In [251]: df
Out[251]: 
        one       two     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [252]: df.drop(['a', 'd'], axis=0)
Out[252]: 
        one       two     three
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194

In [253]: df.drop(['one'], axis=1)
Out[253]: 
        two     three
a  1.124472       NaN
b  2.487104 -0.634293
c -0.486066  1.931194
d -0.456288 -1.222918
```

 注意，下面的方法也可行，但显而易见会稍微慢一些：

```python
In [254]: df.reindex(df.index.difference(['a', 'd']))
Out[254]: 
        one       two     three
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
```
##### 9.7.6  重命名/映射标签
[`rename()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rename.html#pandas.DataFrame.rename)方法允许你使用映射（一个字典或Series）或任意函数来重命名标签。
```python
In [255]: s
Out[255]: 
a    0.505453
b    1.788110
c   -0.405908
d   -0.801912
e    0.768460
dtype: float64

In [256]: s.rename(str.upper)
Out[256]: 
A    0.505453
B    1.788110
C   -0.405908
D   -0.801912
E    0.768460
dtype: float64
```
如果传入一个函数，当在任意标签上调用这个函数时，它必须返回一个值（而且必须生成一组唯一值）。字典和Series也可以使用。
```python
In [257]: df.rename(columns={'one': 'foo', 'two': 'bar'},
   .....:           index={'a': 'apple', 'b': 'banana', 'd': 'durian'})
   .....: 
Out[257]: 
             foo       bar     three
apple  -1.101558  1.124472       NaN
banana -0.177289  2.487104 -0.634293
c       0.462215 -0.486066  1.931194
durian       NaN -0.456288 -1.222918
```
如果映射不包含行/列标签，将不会重命名。注意，映射中额外的标签名不会触发错误。
0.21.0版本的新特定。
[`DataFrame.rename()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rename.html#pandas.DataFrame.rename)也支持一种"axis-style"调用惯例，可以提供一个单独的映射并且指定在哪个抽上执行：
```python
In [258]: df.rename({'one': 'foo', 'two': 'bar'}, axis='columns')
Out[258]: 
        foo       bar     three
a -1.101558  1.124472       NaN
b -0.177289  2.487104 -0.634293
c  0.462215 -0.486066  1.931194
d       NaN -0.456288 -1.222918

In [259]: df.rename({'a': 'apple', 'b': 'banana', 'd': 'durian'}, axis='index')
Out[259]: 
             one       two     three
apple  -1.101558  1.124472       NaN
banana -0.177289  2.487104 -0.634293
c       0.462215 -0.486066  1.931194
durian       NaN -0.456288 -1.222918
```
[`rename()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rename.html#pandas.DataFrame.rename)方法提供了一个`inplace`命名参数（默认是False，代表复制一份数据），来控制是否在内部复制数据。可以将其置为True，替换现有的数据。

0.18.0新特性。

最后，[`rename()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.rename.html#pandas.DataFrame.rename)也接受一个标量或类列表的值来更改`Series.name`的属性。

```python
In [260]: s.rename("scalar-name")
Out[260]: 
a    0.505453
b    1.788110
c   -0.405908
d   -0.801912
e    0.768460
Name: scalar-name, dtype: float64
```

Panel类有一个相关的[`rename_axis()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Panel.rename_axis.html#pandas.Panel.rename_axis)类来修改它的三个轴的名称。

#### 9.8 迭代
在Pandas对象上执行基本迭代操作的处理方式取决于数据类型。迭代Series时，将会把它当做数组来处理，生成一组数据。其他数据结构（DataFrame和Panel）将会像迭代字典一样按照对象的`key`进行迭代。
简单来说，基本迭代操作（for i in object）将会生成：

- Series：生成数值
- DataFrame：生成列标签
- Panel：生成元素标签

所以，举例来说，在DataFrame上执行迭代，将会得到列名：
```python
In [261]: df = pd.DataFrame({'col1' : np.random.randn(3), 'col2' : np.random.randn(3)},
   .....:                   index=['a', 'b', 'c'])
   .....: 

In [262]: for col in df:
   .....:     print(col)
   .....: 
col1
col2
```

Pandas对象也有一个类似字典的[iteritems()](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iteritems.html#pandas.DataFrame.iteritems)方法来迭代(key, value)对。

可以使用下面的方法来迭代DataFrame的行：

- [`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) ：以(index, Series)对的形式迭代DataFrame的行，将行转换成可以更改数据类型并且能够获得一些性能提升的Series。
- [`itertuples()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples): 以命名元组的形式迭代DataFrame的行。这个方法比[`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) 快一些，也是多数情况下经常用到的。

> 警告：
>
> 迭代Pandas对象通常比较慢，很多情况下，不需要手动迭代，而且可以通过下面的方式代替迭代：
>
> - 使用向量化方案：许多操作可以通过使用内置方法、Numpy函数或布尔索引等来获得性能提升。
> - 如果你的函数不能作用在整个DataFrame或Series上，使用 [`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply) 比使用迭代强。查看[函数调用](http://pandas.pydata.org/pandas-docs/version/0.23/basics.html#basics-apply)获得更多信息。
> - 如果你非要迭代数据而且性能也重要，考虑用cython或numba来写内部的循环。查看[增强性能](http://pandas.pydata.org/pandas-docs/version/0.23/enhancingperf.html#enhancingperf)的部分来获得示例。

>警告：
>
>不要修改迭代对象。不一定在所有情况下都能正常工作。取决于数据类型，迭代器（有可能）返回一份拷贝，而不是视图。修改拷贝不会起作用。
>
>举例来说，下面的示例中设置数值没有效果：
>
>```python
>In [263]: df = pd.DataFrame({'a': [1, 2, 3], 'b': ['a', 'b', 'c']})
>
>In [264]: for index, row in df.iterrows():
>   .....:     row['a'] = 10
>   .....: 
>
>In [265]: df
>Out[265]: 
>   a  b
>0  1  a
>1  2  b
>2  3  c
>```

##### 9.8.1 iteritems

与字典的接口相似，[`iteritems()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iteritems.html#pandas.DataFrame.iteritems) 以key-value对的形式迭代数据：

- Series：(index, scale value)对
- DataFrame：(column, Series)对
- Panel：(item, DataFrame)对

例如：

```python
In [266]: for item, frame in wp.iteritems():
   .....:     print(item)
   .....:     print(frame)
   .....: 
Item1
                   A         B         C         D
2000-01-01 -0.433567 -0.273610  0.680433 -0.308450
2000-01-02 -0.276099 -1.821168 -1.993606 -1.927385
2000-01-03 -2.027924  1.624972  0.551135  3.059267
2000-01-04  0.455264 -0.030740  0.935716  1.061192
2000-01-05 -2.107852  0.199905  0.323586 -0.641630
Item2
                   A         B         C         D
2000-01-01 -0.587514  0.053897  0.194889 -0.381994
2000-01-02  0.318587  2.089075 -0.728293 -0.090255
2000-01-03 -0.748199  1.318931 -2.029766  0.792652
2000-01-04  0.461007 -0.542749 -0.305384 -0.479195
2000-01-05  0.095031 -0.270099 -0.707140 -0.773882
```

##### 9.8.2 iterrows

[`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) 允许把DataFrame的每一行当做Series对象来迭代，返回一个迭代器，每一个索引值对应DataFrame的一行。

```python
In [267]: for row_index, row in df.iterrows():
   .....:     print('%s\n%s' % (row_index, row))
   .....: 
0
a    1
b    a
Name: 0, dtype: object
1
a    2
b    b
Name: 1, dtype: object
2
a    3
b    c
Name: 2, dtype: object
```

> 注意：
>
> 因为[`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) 为每一行返回一个Series，它不会跨行保留数据类型（DataFrame跨列会保留数据类型）。例如：
>
> ```python
> In [268]: df_orig = pd.DataFrame([[1, 1.5]], columns=['int', 'float'])
> 
> In [269]: df_orig.dtypes
> Out[269]: 
> int        int64
> float    float64
> dtype: object
> 
> In [270]: row = next(df_orig.iterrows())[1]
> 
> In [271]: row
> Out[271]: 
> int      1.0
> float    1.5
> Name: 0, dtype: float64
> ```
>
> 以Series返回的`row`中的所有数值，现在向上转换为float类型，这也是X列中的原始整型数值。
>
> ```python
> In [272]: row['int'].dtype
> Out[272]: dtype('float64')
> 
> In [273]: df_orig['int'].dtype
> Out[273]: dtype('int64')
> ```
>
> 为了在迭代行时保留数据类型，最好使用[`itertuples()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) ，[`itertuples()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) 返回数值组成的命名元组，而且比 [`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) 快。

作为示例，一种人为的转置DataFrame的方式可能是：

```python
In [274]: df2 = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})

In [275]: print(df2)
   x  y
0  1  4
1  2  5
2  3  6

In [276]: print(df2.T)
   0  1  2
x  1  2  3
y  4  5  6

In [277]: df2_t = pd.DataFrame(dict((idx,values) for idx, values in df2.iterrows()))

In [278]: print(df2_t)
   0  1  2
x  1  2  3
y  4  5  6
```

##### itertuples

[`itertuples()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) 方法会返回一个迭代器，DataFrame的每一行被当做一个命名元组，命名元组的第一个元素是该行对应的索引值，剩下的元素是该行的值。

例如：

```python
In [279]: for row in df.itertuples():
   .....:     print(row)
   .....: 
Pandas(Index=0, a=1, b='a')
Pandas(Index=1, a=2, b='b')
Pandas(Index=2, a=3, b='c')
```

这个方法没有将行转换成Series对象，它只返回命名元组中的值。因此， [`itertuples()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.itertuples.html#pandas.DataFrame.itertuples) 保留了数值的数据类型，而且通常比[`iterrows()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.iterrows.html#pandas.DataFrame.iterrows) 快。

> 注意：
>
> 如果列名是无效的Python标识符、重复的或以下划线开头，列名将会被重命名为位置名称。对于大量的列（大于255），将返回普通元组。

#### 9.9 .dt访问器

如果一个Series是类型datetime或类period的，它会有一个可以方便地返回datetime的访问器，就像是Series的属性一样。这将会返回一个Series，像原来的Series一样索引。

```python
# datetime
In [280]: s = pd.Series(pd.date_range('20130101 09:10:12', periods=4))

In [281]: s
Out[281]: 
0   2013-01-01 09:10:12
1   2013-01-02 09:10:12
2   2013-01-03 09:10:12
3   2013-01-04 09:10:12
dtype: datetime64[ns]

In [282]: s.dt.hour
Out[282]: 
0    9
1    9
2    9
3    9
dtype: int64

In [283]: s.dt.second
Out[283]: 
0    12
1    12
2    12
3    12
dtype: int64

In [284]: s.dt.day
Out[284]: 
0    1
1    2
2    3
3    4
dtype: int64
```

这会得到下面这样的漂亮的表达式：

```python
In [285]: s[s.dt.day==2]
Out[285]: 
1   2013-01-02 09:10:12
dtype: datetime64[ns]
```

可以很容易生成时区转换

```python
In [286]: stz = s.dt.tz_localize('US/Eastern')

In [287]: stz
Out[287]: 
0   2013-01-01 09:10:12-05:00
1   2013-01-02 09:10:12-05:00
2   2013-01-03 09:10:12-05:00
3   2013-01-04 09:10:12-05:00
dtype: datetime64[ns, US/Eastern]

In [288]: stz.dt.tz
Out[288]: <DstTzInfo 'US/Eastern' LMT-1 day, 19:04:00 STD>
```

也可以把这些操作连起来

```python
In [289]: s.dt.tz_localize('UTC').dt.tz_convert('US/Eastern')
Out[289]: 
0   2013-01-01 04:10:12-05:00
1   2013-01-02 04:10:12-05:00
2   2013-01-03 04:10:12-05:00
3   2013-01-04 04:10:12-05:00
dtype: datetime64[ns, US/Eastern]
```

也可以通过[`Series.dt.strftime()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime) 来把datetime转换成字符串。[`Series.dt.strftime()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.dt.strftime.html#pandas.Series.dt.strftime) 支持标准[`strftime()`](https://docs.python.org/3/library/datetime.html#datetime.datetime.strftime) 的同样的格式。

```python
# DatetimeIndex
In [290]: s = pd.Series(pd.date_range('20130101', periods=4))

In [291]: s
Out[291]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: datetime64[ns]

In [292]: s.dt.strftime('%Y/%m/%d')
Out[292]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
```

```python
# PeriodIndex
In [293]: s = pd.Series(pd.period_range('20130101', periods=4))

In [294]: s
Out[294]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: object

In [295]: s.dt.strftime('%Y/%m/%d')
Out[295]: 
0    2013/01/01
1    2013/01/02
2    2013/01/03
3    2013/01/04
dtype: object
```

`.dt`访问器也可以作用在period和timedelta数据类型上

```python
# period
In [296]: s = pd.Series(pd.period_range('20130101', periods=4, freq='D'))

In [297]: s
Out[297]: 
0   2013-01-01
1   2013-01-02
2   2013-01-03
3   2013-01-04
dtype: object

In [298]: s.dt.year
Out[298]: 
0    2013
1    2013
2    2013
3    2013
dtype: int64

In [299]: s.dt.day
Out[299]: 
0    1
1    2
2    3
3    4
dtype: int64
```

```python
# timedelta
In [300]: s = pd.Series(pd.timedelta_range('1 day 00:00:05', periods=4, freq='s'))

In [301]: s
Out[301]: 
0   1 days 00:00:05
1   1 days 00:00:06
2   1 days 00:00:07
3   1 days 00:00:08
dtype: timedelta64[ns]

In [302]: s.dt.days
Out[302]: 
0    1
1    1
2    1
3    1
dtype: int64

In [303]: s.dt.seconds
Out[303]: 
0    5
1    6
2    7
3    8
dtype: int64

In [304]: s.dt.components
Out[304]: 
   days  hours  minutes  seconds  milliseconds  microseconds  nanoseconds
0     1      0        0        5             0             0            0
1     1      0        0        6             0             0            0
2     1      0        0        7             0             0            0
3     1      0        0        8             0             0            0
```

> 注意：
>
> 如果你访问了一个**非类datetime**的Series，`Series.dt`将会触发TypeError异常。

##### 9.10 向量化字符串方法

Series配备了一系列字符串处理方法，操作数组中的每个元素非常容易。也许是最重要的，这些方法自动排除缺失数据。这些方法是通过Series的`.str`属性来实现，一般来说，都有一个内置的等同的字符串方法与其同名。例如：

```python
In [305]: s = pd.Series(['A', 'B', 'C', 'Aaba', 'Baca', np.nan, 'CABA', 'dog', 'cat'])

In [306]: s.str.lower()
Out[306]: 
0       a
1       b
2       c
3    aaba
4    baca
5     NaN
6    caba
7     dog
8     cat
dtype: object
```

也有强大的模式匹配方法，但是，请注意，模式匹配一般默认使用[正则表达式（](https://docs.python.org/3/library/re.html)在某些情况下一直使用）。

查看[向量化字符串方法](http://pandas.pydata.org/pandas-docs/version/0.23/text.html#text-string-methods)获得更多信息。

#### 排序

Pandas支持三种排序：按索引标签、按列名、按索引标签和列名。

##### 按索引

 [`Series.sort_index()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.sort_index.html#pandas.Series.sort_index)和[`DataFrame.sort_index()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sort_index.html#pandas.DataFrame.sort_index)是按照索引标签索引Pandas对象的方法。

```python
In [307]: df = pd.DataFrame({'one' : pd.Series(np.random.randn(3), index=['a', 'b', 'c']),
   .....:                    'two' : pd.Series(np.random.randn(4), index=['a', 'b', 'c', 'd']),
   .....:                    'three' : pd.Series(np.random.randn(3), index=['b', 'c', 'd'])})
   .....: 

In [308]: unsorted_df = df.reindex(index=['a', 'd', 'c', 'b'],
   .....:                          columns=['three', 'two', 'one'])
   .....: 

In [309]: unsorted_df
Out[309]: 
      three       two       one
a       NaN  0.708543  0.036274
d -0.540166  0.586626       NaN
c  0.410238  1.121731  1.044630
b -0.282532 -2.038777 -0.490032

# DataFrame
In [310]: unsorted_df.sort_index()
Out[310]: 
      three       two       one
a       NaN  0.708543  0.036274
b -0.282532 -2.038777 -0.490032
c  0.410238  1.121731  1.044630
d -0.540166  0.586626       NaN

In [311]: unsorted_df.sort_index(ascending=False)
Out[311]: 
      three       two       one
d -0.540166  0.586626       NaN
c  0.410238  1.121731  1.044630
b -0.282532 -2.038777 -0.490032
a       NaN  0.708543  0.036274

In [312]: unsorted_df.sort_index(axis=1)
Out[312]: 
        one     three       two
a  0.036274       NaN  0.708543
d       NaN -0.540166  0.586626
c  1.044630  0.410238  1.121731
b -0.490032 -0.282532 -2.038777

# Series
In [313]: unsorted_df['three'].sort_index()
Out[313]: 
a         NaN
b   -0.282532
c    0.410238
d   -0.540166
Name: three, dtype: float64
```

##### 按数值

[`Series.sort_values()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.sort_values.html#pandas.Series.sort_values)方法是用来按数值排序Series的方法。[`DataFrame.sort_values()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)是按照列数值或行数值排序DataFrame的方法。[`DataFrame.sort_values()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)的可选参数`by`用来指定使用一个或多个列来确定排序的顺序。

```python
In [314]: df1 = pd.DataFrame({'one':[2,1,1,1],'two':[1,3,2,4],'three':[5,4,3,2]})

In [315]: df1.sort_values(by='two')
Out[315]: 
   one  two  three
0    2    1      5
2    1    2      3
1    1    3      4
3    1    4      2
```

`by`参数可以输入一个列名列表，例如：

```python
In [316]: df1[['one', 'two', 'three']].sort_values(by=['one','two'])
Out[316]: 
   one  two  three
2    1    2      3
1    1    3      4
3    1    4      2
0    2    1      5
```

`na_position`参数可以为这个方法指定如何处理NA值：

```python
In [317]: s[2] = np.nan

In [318]: s.sort_values()
Out[318]: 
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
2     NaN
5     NaN
dtype: object

In [319]: s.sort_values(na_position='first')
Out[319]: 
2     NaN
5     NaN
0       A
3    Aaba
1       B
4    Baca
6    CABA
8     cat
7     dog
dtype: object
```

##### 按索引标签和值

0.23.0新增特性

传入 [`DataFrame.sort_values()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)的`by`参数的字符串可能指向列或索引级别名：

```
# Build MultiIndex
In [320]: idx = pd.MultiIndex.from_tuples([('a', 1), ('a', 2), ('a', 2),
   .....:                                 ('b', 2), ('b', 1), ('b', 1)])
   .....: 

In [321]: idx.names = ['first', 'second']

# Build DataFrame
In [322]: df_multi = pd.DataFrame({'A': np.arange(6, 0, -1)},
   .....:                         index=idx)
   .....: 

In [323]: df_multi
Out[323]: 
              A
first second   
a     1       6
      2       5
      2       4
b     2       3
      1       2
      1       1
```

以`second`（索引）和`A`（列）排序：

```python
In [324]: df_multi.sort_values(by=['second', 'A'])
Out[324]: 
              A
first second   
b     1       1
      1       2
a     1       6
b     2       3
a     2       4
      2       5
```

> 注意：
>
> 如果一个字符换既能匹配列名也能匹配索引级别名，将会引起一个警告，并且列名优先。将来的版本将会触发`ambiguity`错误。

##### searchsorted

Series有一个[`searchsorted()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.searchsorted.html#pandas.Series.searchsorted)方法，和[`numpy.ndarray.searchsorted()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.searchsorted.html#numpy.ndarray.searchsorted)的工作方式类似。

```python
In [325]: ser = pd.Series([1, 2, 3])

In [326]: ser.searchsorted([0, 3])
Out[326]: array([0, 2])

In [327]: ser.searchsorted([0, 4])
Out[327]: array([0, 3])

In [328]: ser.searchsorted([1, 3], side='right')
Out[328]: array([1, 3])

In [329]: ser.searchsorted([1, 3], side='left')
Out[329]: array([0, 2])

In [330]: ser = pd.Series([3, 1, 2])

In [331]: ser.searchsorted([0, 3], sorter=np.argsort(ser))
Out[331]: array([0, 2])
```

##### 最小值、最大值

Series的 [`nsmallest()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.nsmallest.html#pandas.Series.nsmallest)和[`nlargest()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.nlargest.html#pandas.Series.nlargest)方法将会返回第n小或第n大的值。对于大数据量的Series，这两个方法将会比排序整个Series再执行head(n)快。

```python
In [332]: s = pd.Series(np.random.permutation(10))

In [333]: s
Out[333]: 
0    8
1    2
2    9
3    5
4    6
5    0
6    1
7    7
8    4
9    3
dtype: int64

In [334]: s.sort_values()
Out[334]: 
5    0
6    1
1    2
9    3
8    4
3    5
4    6
7    7
0    8
2    9
dtype: int64

In [335]: s.nsmallest(3)
Out[335]: 
5    0
6    1
1    2
dtype: int64

In [336]: s.nlargest(3)
Out[336]: 
2    9
0    8
7    7
dtype: int64
```

DataFrame也有这两个方法：

```python
In [337]: df = pd.DataFrame({'a': [-2, -1, 1, 10, 8, 11, -1],
   .....:                    'b': list('abdceff'),
   .....:                    'c': [1.0, 2.0, 4.0, 3.2, np.nan, 3.0, 4.0]})
   .....: 

In [338]: df.nlargest(3, 'a')
Out[338]: 
    a  b    c
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN

In [339]: df.nlargest(5, ['a', 'c'])
Out[339]: 
    a  b    c
6  -1  f  4.0
5  11  f  3.0
3  10  c  3.2
4   8  e  NaN
2   1  d  4.0

In [340]: df.nsmallest(3, 'a')
Out[340]: 
   a  b    c
0 -2  a  1.0
1 -1  b  2.0
6 -1  f  4.0

In [341]: df.nsmallest(5, ['a', 'c'])
Out[341]: 
   a  b    c
0 -2  a  1.0
2  1  d  4.0
4  8  e  NaN
1 -1  b  2.0
6 -1  f  4.0
```

##### 按多重索引排序

当按多重索引排序时，必须明确指定所有的索引等级：

```python
In [342]: df1.columns = pd.MultiIndex.from_tuples([('a','one'),('a','two'),('b','three')])

In [343]: df1.sort_values(by=('a','two'))
Out[343]: 
    a         b
  one two three
0   2   1     5
2   1   2     3
1   1   3     4
3   1   4     2
```

#### 复制

在Pandas对象上执行[`copy()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.copy.html#pandas.DataFrame.copy)方法，将会复制内部的数据（虽然不是轴索引，因为它们是不可变的）并且返回一个新的对象。注意，很小需要复制对象。比如：只有少数几种方法可以就地更改一个DataFrame：

- 插入、删除、修改列
- 为`index`和`columns`属性赋值
- 对同类型的数据，直接通过`values`属性修改数据或高级索引

更清楚地说，没有Pandas方法修改数据时有副作用；几乎所有的方法返回一个新的对象，源数据不会动。如果数据被修改，肯定是因为你明确指定了。

#### dtypes

Pandas对象的主要数据类型时float、int、bool、datetime64[ns]、datetime64[ns, tz]、timedelta[ns]、category和object。另外，这些数据类型都有项的大小，比如int64和int32。查看[Series with TZ](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html#timeseries-timezone-series)获取更多关于datetime64[ns, tz]数据类型的细节。

DataFrame的一个方便的[`dtypes`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes)属性返回一个包含每一列的数据类型的Series：

```python
In [344]: dft = pd.DataFrame(dict(A = np.random.rand(3),
   .....:                         B = 1,
   .....:                         C = 'foo',
   .....:                         D = pd.Timestamp('20010102'),
   .....:                         E = pd.Series([1.0]*3).astype('float32'),
   .....:                                     F = False,
   .....:                                     G = pd.Series([1]*3,dtype='int8')))
   .....: 

In [345]: dft
Out[345]: 
          A  B    C          D    E      F  G
0  0.809585  1  foo 2001-01-02  1.0  False  1
1  0.128238  1  foo 2001-01-02  1.0  False  1
2  0.775752  1  foo 2001-01-02  1.0  False  1

In [346]: dft.dtypes
Out[346]: 
A           float64
B             int64
C            object
D    datetime64[ns]
E           float32
F              bool
G              int8
dtype: object
```

在Series对象上使用 [`dtype`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.dtype.html#pandas.Series.dtype)属性

```python
In [347]: dft['A'].dtype
Out[347]: dtype('float64')
```

如果Pandas对象的一列上包含多种数据类型，列的数据类型将会选择能够包含所有数据的类型（一般是object）

```python
# these ints are coerced to floats
In [348]: pd.Series([1, 2, 3, 4, 5, 6.])
Out[348]: 
0    1.0
1    2.0
2    3.0
3    4.0
4    5.0
5    6.0
dtype: float64

# string data forces an ``object`` dtype
In [349]: pd.Series([1, 2, 3, 6., 'foo'])
Out[349]: 
0      1
1      2
2      3
3      6
4    foo
dtype: object
```

一个DataFrame的各列的数据类型数量可以通过调用[`get_dtype_counts()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.get_dtype_counts.html#pandas.DataFrame.get_dtype_counts)来获得

```python
In [350]: dft.get_dtype_counts()
Out[350]: 
float64           1
float32           1
int64             1
int8              1
datetime64[ns]    1
bool              1
object            1
dtype: int64
```

数值类型将传播，并且可以在DataFrame中共存。如果传入了一个数据类型（直接通过dtype关键字、传入的ndarray或传入的Series），那么它将在DataFrame操作中被保存。另外，不同的数值类型不会被合并。下面的示例将是一个尝试：

```python
In [351]: df1 = pd.DataFrame(np.random.randn(8, 1), columns=['A'], dtype='float32')

In [352]: df1
Out[352]: 
          A
0  0.890400
1  0.283331
2 -0.303613
3 -1.192210
4  0.065420
5  0.455918
6  2.008328
7  0.188942

In [353]: df1.dtypes
Out[353]: 
A    float32
dtype: object

In [354]: df2 = pd.DataFrame(dict( A = pd.Series(np.random.randn(8), dtype='float16'),
   .....:                         B = pd.Series(np.random.randn(8)),
   .....:                         C = pd.Series(np.array(np.random.randn(8), dtype='uint8')) ))
   .....: 

In [355]: df2
Out[355]: 
          A         B    C
0 -0.454346  0.200071  255
1 -0.916504 -0.557756  255
2  0.640625 -0.141988    0
3  2.675781 -0.174060    0
4 -0.007866  0.258626    0
5 -0.204224  0.941688    0
6 -0.100098 -1.849045    0
7 -0.402100 -0.949458    0

In [356]: df2.dtypes
Out[356]: 
A    float16
B    float64
C      uint8
dtype: object
```

##### 默认情况

默认地，不管平台是64位还是32位，整型数据类型是int64，浮点型是float64。下面的示例将都会返回int64数据类型：

```python
In [357]: pd.DataFrame([1, 2], columns=['a']).dtypes
Out[357]: 
a    int64
dtype: object

In [358]: pd.DataFrame({'a': [1, 2]}).dtypes
Out[358]: 
a    int64
dtype: object

In [359]: pd.DataFrame({'a': 1 }, index=list(range(2))).dtypes
Out[359]: 
a    int64
dtype: object
```

注意，Numpy创建数组时会根据平台类型选择数据类型。下面的示例在32位平台上将会返回int32类型。

```python
In [360]: frame = pd.DataFrame(np.array([1, 2]))
```

##### 向上转型

合并不同的数据类型时，有可能会向上转型，这表示，结果将会从现有的数据类型提升获得：

```python
In [361]: df3 = df1.reindex_like(df2).fillna(value=0.0) + df2

In [362]: df3
Out[362]: 
          A         B      C
0  0.436054  0.200071  255.0
1 -0.633173 -0.557756  255.0
2  0.337012 -0.141988    0.0
3  1.483571 -0.174060    0.0
4  0.057555  0.258626    0.0
5  0.251695  0.941688    0.0
6  1.908231 -1.849045    0.0
7 -0.213158 -0.949458    0.0

In [363]: df3.dtypes
Out[363]: 
A    float32
B    float64
C    float64
dtype: object
```

DataFrame的`values`属性会返回数据类型的最大公约数，就是说，在返回的Numpy同类型数组中的数据类型将能够容纳所有的数据类型。这会强制执行一些向上转型：

```python
In [364]: df3.values.dtype
Out[364]: dtype('float64')
```

##### astype

可以通过[`astype()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.astype.html#pandas.DataFrame.astype)方法来明确地将一个数据类型转为另一个。默认地，这将返回一个拷贝，即使数据类型没有改变（传入`copy=False`可以不执行拷贝）。另外，如果astype操作是非法的将会触发异常。

向上取整一直按照Numpy规则来执行。如果一个操作中涉及两个不同的数据类型，包含范围更大的那个将会在结果中使用。

```python
In [365]: df3
Out[365]: 
          A         B      C
0  0.436054  0.200071  255.0
1 -0.633173 -0.557756  255.0
2  0.337012 -0.141988    0.0
3  1.483571 -0.174060    0.0
4  0.057555  0.258626    0.0
5  0.251695  0.941688    0.0
6  1.908231 -1.849045    0.0
7 -0.213158 -0.949458    0.0

In [366]: df3.dtypes
Out[366]: 
A    float32
B    float64
C    float64
dtype: object

# conversion of dtypes
In [367]: df3.astype('float32').dtypes
Out[367]: 
A    float32
B    float32
C    float32
dtype: object
```

使用 [`astype()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.astype.html#pandas.DataFrame.astype)将列的子集转换为特定的数据类型：

```python
In [368]: dft = pd.DataFrame({'a': [1,2,3], 'b': [4,5,6], 'c': [7, 8, 9]})

In [369]: dft[['a','b']] = dft[['a','b']].astype(np.uint8)

In [370]: dft
Out[370]: 
   a  b  c
0  1  4  7
1  2  5  8
2  3  6  9

In [371]: dft.dtypes
Out[371]: 
a    uint8
b    uint8
c    int64
dtype: object
```

0.19.0版新增特性

为 [`astype()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.astype.html#pandas.DataFrame.astype)传入一个字典来把特定的列转成指定的数据类型

```python
In [372]: dft1 = pd.DataFrame({'a': [1,0,1], 'b': [4,5,6], 'c': [7, 8, 9]})

In [373]: dft1 = dft1.astype({'a': np.bool, 'c': np.float64})

In [374]: dft1
Out[374]: 
       a  b    c
0   True  4  7.0
1  False  5  8.0
2   True  6  9.0

In [375]: dft1.dtypes
Out[375]: 
a       bool
b      int64
c    float64
dtype: object
```

> 注意：
>
> 当使用[`astype()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.astype.html#pandas.DataFrame.astype) 和 [`loc()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc)尝试将列的子集转换为特定数据类型时，将会发生向上取整。
>
> [`loc()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.loc.html#pandas.DataFrame.loc) 试着匹配我们指定给当前类型的内容，同时`[]`将使用右边的数据类型覆写它们。所以，下面的代码片段产生了意想不到的结果：
>
> ```python
> In [376]: dft = pd.DataFrame({'a': [1,2,3], 'b': [4,5,6], 'c': [7, 8, 9]})
> 
> In [377]: dft.loc[:, ['a', 'b']].astype(np.uint8).dtypes
> Out[377]: 
> a    uint8
> b    uint8
> dtype: object
> 
> In [378]: dft.loc[:, ['a', 'b']] = dft.loc[:, ['a', 'b']].astype(np.uint8)
> 
> In [379]: dft.dtypes
> Out[379]: 
> a    int64
> b    int64
> c    int64
> dtype: object
> ```

##### object数据类型转换

Pandas提供了许多函数来强制把object数据类型转换成其他数据类型。为了处理数据使用了正确的数据类型，但被存为object类型的情况， [`DataFrame.infer_objects()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.infer_objects.html#pandas.DataFrame.infer_objects) 和[`Series.infer_objects()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.infer_objects.html#pandas.Series.infer_objects)方法可以用来将数据软转换为正确的类型：

```python
In [380]: import datetime

In [381]: df = pd.DataFrame([[1, 2],
   .....:                    ['a', 'b'],
   .....:                    [datetime.datetime(2016, 3, 2), datetime.datetime(2016, 3, 2)]])
   .....: 

In [382]: df = df.T

In [383]: df
Out[383]: 
   0  1                    2
0  1  a  2016-03-02 00:00:00
1  2  b  2016-03-02 00:00:00

In [384]: df.dtypes
Out[384]: 
0    object
1    object
2    object
dtype: object
```

因为数据被转置了，原型推断将所有的列存为了object类型，`infer_objects`将会展示实际的类型：

```python
In [385]: df.infer_objects().dtypes
Out[385]: 
0             int64
1            object
2    datetime64[ns]
dtype: object
```

下面的函数可以将一维object数组或标量硬转换为指定的类型：

- [`to_numeric()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.to_numeric.html#pandas.to_numeric)（转换为数值类型）

  ```python
  In [386]: m = ['1.1', 2, 3]
  
  In [387]: pd.to_numeric(m)
  Out[387]: array([ 1.1,  2. ,  3. ])
  ```

- [`to_datetime()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.to_datetime.html#pandas.to_datetime)（转换为datetime类型）

  ```python
  In [388]: import datetime
  
  In [389]: m = ['2016-07-09', datetime.datetime(2016, 3, 2)]
  
  In [390]: pd.to_datetime(m)
  Out[390]: DatetimeIndex(['2016-07-09', '2016-03-02'], dtype='datetime64[ns]', freq=None)
  ```

- [`to_timedelta()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.to_timedelta.html#pandas.to_timedelta)（转换为timedelta类型）

  ```python
  In [391]: m = ['5us', pd.Timedelta('1day')]
  
  In [392]: pd.to_timedelta(m)
  Out[392]: TimedeltaIndex(['0 days 00:00:00.000005', '1 days 00:00:00'], dtype='timedelta64[ns]', freq=None
  ```

强制转换时，我们可以转入一个`errors`参数，来指定那些不能正确转换为指定的数据类型或对象的数据应该如何处理。默认地，`erros='raise'`，意味着任何错误在转换时都会抛出。不过，如果`erros='coerce'`，这些错误将会被忽略并且Pandas将把有问题的元素转换为`pd.NaT`（datetime和timedelta）或`np.na`（数值型）。在读取大部分是期待的数据类型（比如数值型，时间型）但偶尔有一些不一致的混在一起的你想用缺失代替的数据时，这种处理方式也许有用。

```python
In [393]: import datetime

In [394]: m = ['apple', datetime.datetime(2016, 3, 2)]

In [395]: pd.to_datetime(m, errors='coerce')
Out[395]: DatetimeIndex(['NaT', '2016-03-02'], dtype='datetime64[ns]', freq=None)

In [396]: m = ['apple', 2, 3]

In [397]: pd.to_numeric(m, errors='coerce')
Out[397]: array([ nan,   2.,   3.])

In [398]: m = ['apple', pd.Timedelta('1day')]

In [399]: pd.to_timedelta(m, errors='coerce')
Out[399]: TimedeltaIndex([NaT, '1 days'], dtype='timedelta64[ns]', freq=None)
```

`errors`参数还有第三个选项`erros='ignore'`，这种情况下，在遇到不能正确转换为期待的数据类型时，将简单地返回传入的数据。

```python
In [400]: import datetime

In [401]: m = ['apple', datetime.datetime(2016, 3, 2)]

In [402]: pd.to_datetime(m, errors='ignore')
Out[402]: array(['apple', datetime.datetime(2016, 3, 2, 0, 0)], dtype=object)

In [403]: m = ['apple', 2, 3]

In [404]: pd.to_numeric(m, errors='ignore')
Out[404]: array(['apple', 2, 3], dtype=object)

In [405]: m = ['apple', pd.Timedelta('1day')]

In [406]: pd.to_timedelta(m, errors='ignore')
Out[406]: array(['apple', Timedelta('1 days 00:00:00')], dtype=object)
```

object转换之外，[`to_numeric()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.to_numeric.html#pandas.to_numeric)提供了另一参数`downcast`，给出了一个将新的（或已经存在的）数据转换为较小的数据类型的节省内存的选项。

```python
In [407]: m = ['1', 2, 3]

In [408]: pd.to_numeric(m, downcast='integer')   # smallest signed int dtype
Out[408]: array([1, 2, 3], dtype=int8)

In [409]: pd.to_numeric(m, downcast='signed')    # same as 'integer'
Out[409]: array([1, 2, 3], dtype=int8)

In [410]: pd.to_numeric(m, downcast='unsigned')  # smallest unsigned int dtype
Out[410]: array([1, 2, 3], dtype=uint8)

In [411]: pd.to_numeric(m, downcast='float')     # smallest float dtype
Out[411]: array([ 1.,  2.,  3.], dtype=float32)
```

由于这些方法都是只能作用在一维数组、列表或标量上，所以不能直接在多维对象（例如DataFrame）上使用。不过，使用 [`apply()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.apply.html#pandas.DataFrame.apply)，们可以在每一列上高效地调用这些函数。

```python
In [412]: import datetime

In [413]: df = pd.DataFrame([['2016-07-09', datetime.datetime(2016, 3, 2)]] * 2, dtype='O')

In [414]: df
Out[414]: 
            0                    1
0  2016-07-09  2016-03-02 00:00:00
1  2016-07-09  2016-03-02 00:00:00

In [415]: df.apply(pd.to_datetime)
Out[415]: 
           0          1
0 2016-07-09 2016-03-02
1 2016-07-09 2016-03-02

In [416]: df = pd.DataFrame([['1.1', 2, 3]] * 2, dtype='O')

In [417]: df
Out[417]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [418]: df.apply(pd.to_numeric)
Out[418]: 
     0  1  2
0  1.1  2  3
1  1.1  2  3

In [419]: df = pd.DataFrame([['5us', pd.Timedelta('1day')]] * 2, dtype='O')

In [420]: df
Out[420]: 
     0                1
0  5us  1 days 00:00:00
1  5us  1 days 00:00:00

In [421]: df.apply(pd.to_timedelta)
Out[421]: 
                0      1
0 00:00:00.000005 1 days
1 00:00:00.000005 1 days
```

##### 陷阱

在整型数据类型数据上执行选择操作会很容易将数据向上转型为浮点型。在不引入nan类型的情况下，输入数据的类型将会被保留。查看[支持整型NA](http://pandas.pydata.org/pandas-docs/version/0.23/gotchas.html#gotchas-intna)，获得更多介绍。

```python
In [422]: dfi = df3.astype('int32')

In [423]: dfi['E'] = 1

In [424]: dfi
Out[424]: 
   A  B    C  E
0  0  0  255  1
1  0  0  255  1
2  0  0    0  1
3  1  0    0  1
4  0  0    0  1
5  0  0    0  1
6  1 -1    0  1
7  0  0    0  1

In [425]: dfi.dtypes
Out[425]: 
A    int32
B    int32
C    int32
E    int64
dtype: object

In [426]: casted = dfi[dfi>0]

In [427]: casted
Out[427]: 
     A   B      C  E
0  NaN NaN  255.0  1
1  NaN NaN  255.0  1
2  NaN NaN    NaN  1
3  1.0 NaN    NaN  1
4  NaN NaN    NaN  1
5  NaN NaN    NaN  1
6  1.0 NaN    NaN  1
7  NaN NaN    NaN  1

In [428]: casted.dtypes
Out[428]: 
A    float64
B    float64
C    float64
E      int64
dtype: object
```

同时，浮点型没有改变

```python
In [429]: dfa = df3.copy()

In [430]: dfa['A'] = dfa['A'].astype('float32')

In [431]: dfa.dtypes
Out[431]: 
A    float32
B    float64
C    float64
dtype: object

In [432]: casted = dfa[df2>0]

In [433]: casted
Out[433]: 
          A         B      C
0       NaN  0.200071  255.0
1       NaN       NaN  255.0
2  0.337012       NaN    NaN
3  1.483571       NaN    NaN
4       NaN  0.258626    NaN
5       NaN  0.941688    NaN
6       NaN       NaN    NaN
7       NaN       NaN    NaN

In [434]: casted.dtypes
Out[434]: 
A    float32
B    float64
C    float64
dtype: object
```

#### 基于dtype选择列

[`select_dtypes()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes)方法实现了基于列的类型得到列的子集。

首先，我们创建一个包含一些类不同数据类型的列的[`DataFrame`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.html#pandas.DataFrame)。

```python
In [435]: df = pd.DataFrame({'string': list('abc'),
   .....:                    'int64': list(range(1, 4)),
   .....:                    'uint8': np.arange(3, 6).astype('u1'),
   .....:                    'float64': np.arange(4.0, 7.0),
   .....:                    'bool1': [True, False, True],
   .....:                    'bool2': [False, True, False],
   .....:                    'dates': pd.date_range('now', periods=3).values,
   .....:                    'category': pd.Series(list("ABC")).astype('category')})
   .....: 

In [436]: df['tdeltas'] = df.dates.diff()

In [437]: df['uint64'] = np.arange(3, 6).astype('u8')

In [438]: df['other_dates'] = pd.date_range('20130101', periods=3).values

In [439]: df['tz_aware_dates'] = pd.date_range('20130101', periods=3, tz='US/Eastern')

In [440]: df
Out[440]: 
  string  int64  uint8  float64  bool1            ...             category tdeltas uint64 other_dates            tz_aware_dates
0      a      1      3      4.0   True            ...                    A     NaT      3  2013-01-01 2013-01-01 00:00:00-05:00
1      b      2      4      5.0  False            ...                    B  1 days      4  2013-01-02 2013-01-02 00:00:00-05:00
2      c      3      5      6.0   True            ...                    C  1 days      5  2013-01-03 2013-01-03 00:00:00-05:00

[3 rows x 12 columns]
```

数据类型

```python
In [441]: df.dtypes
Out[441]: 
string                                object
int64                                  int64
uint8                                  uint8
float64                              float64
bool1                                   bool
bool2                                   bool
dates                         datetime64[ns]
category                            category
tdeltas                      timedelta64[ns]
uint64                                uint64
other_dates                   datetime64[ns]
tz_aware_dates    datetime64[ns, US/Eastern]
dtype: object
```

[`select_dtypes()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes) 有两个参数`include`和`exclude`，允许你明示"包含这些数据"（include）或"排除这些数据"（exclude）。

例如，选择布尔数据类型的列：

```python
In [442]: df.select_dtypes(include=[bool])
Out[442]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
```

也可以为[Numpy类型层级](http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html)传入数据类型名

```python
In [443]: df.select_dtypes(include=['bool'])
Out[443]: 
   bool1  bool2
0   True  False
1  False   True
2   True  False
```

[`select_dtypes()`](http://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.select_dtypes.html#pandas.DataFrame.select_dtypes)配合一般的数据类型也能很好的工作

例如，选择所有的数值型和布尔型列，并且排除无符号整型

```python
In [444]: df.select_dtypes(include=['number', 'bool'], exclude=['unsignedinteger'])
Out[444]: 
   int64  float64  bool1  bool2 tdeltas
0      1      4.0   True  False     NaT
1      2      5.0  False   True  1 days
2      3      6.0   True  False  1 days
```

选择字符串列，必须使用object数类型

```python
In [445]: df.select_dtypes(include=['object'])
Out[445]: 
  string
0      a
1      b
2      c
```

查看一般的数据类型（比如numpy.number）的子类型，可以定义一个返回子类型树的函数

```python
In [446]: def subdtypes(dtype):
   .....:     subs = dtype.__subclasses__()
   .....:     if not subs:
   .....:         return dtype
   .....:     return [dtype, [subdtypes(dt) for dt in subs]]
   .....: 
```

所有的Numpy数据类型都是numpy.generic的子类：

```python
In [447]: subdtypes(np.generic)
Out[447]: 
[numpy.generic,
 [[numpy.number,
   [[numpy.integer,
     [[numpy.signedinteger,
       [numpy.int8,
        numpy.int16,
        numpy.int32,
        numpy.int64,
        numpy.int64,
        numpy.timedelta64]],
      [numpy.unsignedinteger,
       [numpy.uint8,
        numpy.uint16,
        numpy.uint32,
        numpy.uint64,
        numpy.uint64]]]],
    [numpy.inexact,
     [[numpy.floating,
       [numpy.float16, numpy.float32, numpy.float64, numpy.float128]],
      [numpy.complexfloating,
       [numpy.complex64, numpy.complex128, numpy.complex256]]]]]],
  [numpy.flexible,
   [[numpy.character, [numpy.bytes_, numpy.str_]],
    [numpy.void, [numpy.record]]]],
  numpy.bool_,
  numpy.datetime64,
  numpy.object_]]
```

> 注意：
>
> Pandas也定义`category`和`datetime[ns, tz]`数据类型，这两个数据类型没有集成到普通Numpy类型层级中，在上面的函数中不会展示。

