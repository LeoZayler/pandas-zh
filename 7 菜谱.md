### 第七章 菜谱

本章是一些简洁明了的例子的仓库和有用的pandas方法的链接。我们鼓励用户为本章添加文档。

为本部分内容添加有意思的链接或在线示例，会是非常棒的首次pull request。

简单、扼要、对新手友好的在线示例已经添加进有可能扩大Stack Overflow和GitHub链接的地方。许多链接在提供在线示例之外也提供扩展信息。

只有pandas（pd）和Numpy（np）是默认引入的模块。其余的模块对新手都是显式引入的。

这些示例是使用Python3.4写的，使用更早的Python版本的用户可能需要一些小的调整。

译者注：Stack Overflow上的一些示例可能有些过时，例如，最新版本的pandas不建议使用`.ix`，因为后面的版本会删除该用法。

#### 7.1 惯例

以下这些是pandas的一些惯用操作

[在一列上使用if-then或if-then-else条件语句，赋值给另一（多）列](https://stackoverflow.com/questions/17128302/python-pandas-idiom-for-if-then-else)

```python
In [1]: df = pd.DataFrame(
...:            {'AAA' : [4,5,6,7], 
                 'BBB' : [10,20,30,40],
                 'CCC' : [100,50,-30,-50]}
                ); 
        df
...:
Out[1]:
  AAA BBB CCC
0   4  10 100
1   5  20  50
2   6  30 -30
3   7  40 -50
```

##### 7.1.1 if-then条件语句

在一列上使用if-then条件语句：
```python
In [2]: df.loc[df.AAA >= 5,'BBB'] = -1; df
Out[2]:
  AAA BBB CCC
0   4  10 100
1   5  -1  50
2   6  -1 -30
3   7  -1 -50
```

if-then条件语句作用于两列：
```python
In [3]: df.loc[df.AAA >= 5,['BBB','CCC']] = 555; df
Out[3]: 
   AAA  BBB  CCC
0    4   10  100
1    5  555  555
2    6  555  555
3    7  555  555
```

不同逻辑作用于另外的行（else的情况）：
```python
In [4]: df.loc[df.AAA < 5,['BBB','CCC']] = 2000; df
Out[4]: 
   AAA   BBB   CCC
0    4  2000  2000
1    5   555   555
2    6   555   555
3    7   555   555
```

使用`mask`：
```python
In [5]: df_mask = pd.DataFrame({'AAA' : [True] * 4, 'BBB' : [False] * 4,'CCC' : [True,False] * 2})

In [6]: df.where(df_mask,-1000)
Out[6]: 
   AAA   BBB   CCC
0    4 -1000  2000
1    5 -1000 -1000
2    6 -1000   555
3    7 -1000 -1000
```

使用`Numpy`的`where()`方法：
```python
In [7]: df = pd.DataFrame(
   ...:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ...: 
Out[7]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [8]: df['logic'] = np.where(df['AAA'] > 5,'high','low'); df
Out[8]: 
   AAA  BBB  CCC logic
0    4   10  100   low
1    5   20   50   low
2    6   30  -30  high
3    7   40  -50  high
```

##### 7.1.2 分解

[使用布尔条件分解数据](https://stackoverflow.com/questions/14957116/how-to-split-a-dataframe-according-to-a-boolean-criterion)

```python
In [9]: df = pd.DataFrame(
   ...:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ...: 
Out[9]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [10]: dflow = df[df.AAA <= 5]; dflow
Out[10]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50

In [11]: dfhigh = df[df.AAA > 5]; dfhigh
Out[11]: 
   AAA  BBB  CCC
2    6   30  -30
3    7   40  -50
```

##### 7.1.3 构造条件

[基于多列条件的筛选](https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe)

创建DataFrame
```python
In [12]: df = pd.DataFrame(
   ....:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ....: 
Out[12]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50
```
`与`（不赋值给同一个DataFrame，返回一个Series）
```python
In [13]: newseries = df.loc[(df['BBB'] < 25) & (df['CCC'] >= -40), 'AAA']; newseries
Out[13]: 
0    4
1    5
Name: AAA, dtype: int64
```
`或`（不赋值给同一个DataFrame，返回一个Series）
```python
In [14]: newseries = df.loc[(df['BBB'] > 25) | (df['CCC'] >= -40), 'AAA']; newseries;
```
`或`（赋值给同一个DataFrame，修改对应位置的值）
```python
In [15]: df.loc[(df['BBB'] > 25) | (df['CCC'] >= 75), 'AAA'] = 0.1; df
Out[15]: 
   AAA  BBB  CCC
0  0.1   10  100
1  5.0   20   50
2  0.1   30  -30
3  0.1   40  -50
```

[使用`argsort`选择离给定值最近的值](https://stackoverflow.com/questions/17758023/return-rows-in-a-dataframe-closest-to-a-user-defined-number)
```python
In [16]: df = pd.DataFrame(
   ....:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ....: 
Out[16]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [17]: aValue = 43.0

In [18]: df.loc[(df.CCC-aValue).abs().argsort()]
Out[18]: 
   AAA  BBB  CCC
1    5   20   50
0    4   10  100
2    6   30  -30
3    7   40  -50
```

[动态地归纳二元操作符条件列表](https://stackoverflow.com/questions/21058254/pandas-boolean-operation-in-a-python-list/21058331)

```python
In [19]: df = pd.DataFrame(
   ....:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ....: 
Out[19]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [20]: Crit1 = df.AAA <= 5.5

In [21]: Crit2 = df.BBB == 10.0

In [22]: Crit3 = df.CCC > -40.0
```

`硬编码`：
```python
In [23]: AllCrit = Crit1 & Crit2 & Crit3
```

或者`动态创建条件列表`:
```python
In [24]: CritList = [Crit1,Crit2,Crit3]

In [25]: AllCrit = functools.reduce(lambda x,y: x & y, CritList)

In [26]: df[AllCrit]
Out[26]: 
   AAA  BBB  CCC
0    4   10  100
```

#### 7.2 筛选

##### 7.2.1 DataFrames

[索引](http://pandas.pydata.org/pandas-docs/version/0.23/indexing.html#indexing)文档

[既使用行标签也使用值条件](http://stackoverflow.com/questions/14725068/pandas-using-row-labels-in-boolean-indexing)

```python
In [27]: df = pd.DataFrame(
   ....:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}); df
   ....: 
Out[27]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [28]: df[(df.AAA <= 6) & (df.index.isin([0,2,4]))]
Out[28]: 
   AAA  BBB  CCC
0    4   10  100
2    6   30  -30
```

[使用`loc`进行标签方向的索引，使用iloc进行位置索引](https://github.com/pandas-dev/pandas/issues/2904)

```python
In [29]: data = {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40],'CCC' : [100,50,-30,-50]}

In [30]: df = pd.DataFrame(data=data,index=['foo','bar','boo','kar']); df
Out[30]: 
     AAA  BBB  CCC
foo    4   10  100
bar    5   20   50
boo    6   30  -30
kar    7   40  -50
```

这两个显式的索引方法，有三种一般情况：

- 位置方向的索引：Python索引风格`:`不包含结尾
- 标签方向的索引：非Python索引风格`:`包含结尾
- 一般情况，`:`是不是包含结尾，需要根据索引是否包含标签或位置来判断

```python
In [31]: df.loc['bar':'kar'] #Label
Out[31]: 
     AAA  BBB  CCC
bar    5   20   50
boo    6   30  -30
kar    7   40  -50

# Generic
In [32]: df.iloc[0:3]
Out[32]: 
     AAA  BBB  CCC
foo    4   10  100
bar    5   20   50
boo    6   30  -30

In [33]: df.loc['bar':'kar']
Out[33]: 
     AAA  BBB  CCC
bar    5   20   50
boo    6   30  -30
kar    7   40  -50
```

当索引由非零整数开始或不是按单位增加时，会产生歧义

```python
In [34]: df2 = pd.DataFrame(data=data,index=[1,2,3,4]); #Note index starts at 1.

In [35]: df2.iloc[1:3] #Position-oriented
Out[35]: 
   AAA  BBB  CCC
2    5   20   50
3    6   30  -30

In [36]: df2.loc[1:3] #Label-oriented
Out[36]: 
   AAA  BBB  CCC
1    4   10  100
2    5   20   50
3    6   30  -30
```

使用否运算（`~`）取一组条件的补集

```python
In [37]: df = pd.DataFrame(
   ....:      {'AAA' : [4,5,6,7], 'BBB' : [10,20,30,40], 'CCC' : [100,50,-30,-50]}); df
   ....: 
Out[37]: 
   AAA  BBB  CCC
0    4   10  100
1    5   20   50
2    6   30  -30
3    7   40  -50

In [38]: df[~((df.AAA <= 6) & (df.index.isin([0,2,4])))]
Out[38]: 
   AAA  BBB  CCC
1    5   20   50
3    7   40  -50
```

##### 7.2.2 Panels

[通过转置扩展panel，增加一个新的维度，然后转置回原来的维度](http://stackoverflow.com/questions/15364050/extending-a-pandas-panel-frame-along-the-minor-axis)

```python
In [39]: rng = pd.date_range('1/1/2013',periods=100,freq='D')

In [40]: data = np.random.randn(100, 4)

In [41]: cols = ['A','B','C','D']

In [42]: df1, df2, df3 = pd.DataFrame(data, rng, cols), pd.DataFrame(data, rng, cols), pd.DataFrame(data, rng, cols)

In [43]: pf = pd.Panel({'df1':df1,'df2':df2,'df3':df3});pf
Out[43]: 
<class 'pandas.core.panel.Panel'>
Dimensions: 3 (items) x 100 (major_axis) x 4 (minor_axis)
Items axis: df1 to df3
Major_axis axis: 2013-01-01 00:00:00 to 2013-04-10 00:00:00
Minor_axis axis: A to D

In [44]: pf.loc[:,:,'F'] = pd.DataFrame(data, rng, cols);pf
Out[44]: 
<class 'pandas.core.panel.Panel'>
Dimensions: 3 (items) x 100 (major_axis) x 5 (minor_axis)
Items axis: df1 to df3
Major_axis axis: 2013-01-01 00:00:00 to 2013-04-10 00:00:00
Minor_axis axis: A to F
```

[使用np.where创建一个新的panel，然后使用新的条件数值重塑panel](http://stackoverflow.com/questions/14650341/boolean-mask-in-pandas-panel)

##### 7.2.3 新的列

[使用applymap来高效地、动态地创建新的列](http://stackoverflow.com/questions/16575868/efficiently-creating-additional-columns-in-a-pandas-dataframe-using-map)

```python
In [45]: df = pd.DataFrame(
   ....:      {'AAA' : [1,2,1,3], 'BBB' : [1,1,2,2], 'CCC' : [2,1,3,1]}); df
   ....: 
Out[45]: 
   AAA  BBB  CCC
0    1    1    2
1    2    1    1
2    1    2    3
3    3    2    1

In [46]: source_cols = df.columns # or some subset would work too.

In [47]: new_cols = [str(x) + "_cat" for x in source_cols]

In [48]: categories = {1 : 'Alpha', 2 : 'Beta', 3 : 'Charlie' }

In [49]: df[new_cols] = df[source_cols].applymap(categories.get);df
Out[49]: 
   AAA  BBB  CCC  AAA_cat BBB_cat  CCC_cat
0    1    1    2    Alpha   Alpha     Beta
1    2    1    1     Beta   Alpha    Alpha
2    1    2    3    Alpha    Beta  Charlie
3    3    2    1  Charlie    Beta    Alpha
```

[groupby后使用min()时来保持其他列](http://stackoverflow.com/questions/23394476/keep-other-columns-when-using-min-with-groupby)

```python
In [50]: df = pd.DataFrame(
   ....:      {'AAA' : [1,1,1,2,2,2,3,3], 'BBB' : [2,1,3,4,5,1,2,3]}); df
   ....: 
Out[50]: 
   AAA  BBB
0    1    2
1    1    1
2    1    3
3    2    4
4    2    5
5    2    1
6    3    2
7    3    3
```

方法1：使用`idxmin()`获得最小值的索引

```python
In [51]: df.loc[df.groupby("AAA")["BBB"].idxmin()]
Out[51]: 
   AAA  BBB
1    1    1
5    2    1
6    3    2
```

方法2：排序，然后每组取第一个

```python
In [52]: df.sort_values(by="BBB").groupby("AAA", as_index=False).first()
Out[52]: 
   AAA  BBB
0    1    1
1    2    1
2    3    2
```

注意：除了索引之外，这两个方法的结果是一样的。

#### 7.3 多重索引

[多重索引](http://pandas.pydata.org/pandas-docs/version/0.23/advanced.html#advanced-hierarchical)文档

[用标签化的数据框创建多级索引](http://stackoverflow.com/questions/14916358/reshaping-dataframes-in-pandas-based-on-column-labels)

```python
In [53]: df = pd.DataFrame({'row' : [0,1,2],
   ....:                    'One_X' : [1.1,1.1,1.1],
   ....:                    'One_Y' : [1.2,1.2,1.2],
   ....:                    'Two_X' : [1.11,1.11,1.11],
   ....:                    'Two_Y' : [1.22,1.22,1.22]}); df
   ....: 
Out[53]: 
   row  One_X  One_Y  Two_X  Two_Y
0    0    1.1    1.2   1.11   1.22
1    1    1.1    1.2   1.11   1.22
2    2    1.1    1.2   1.11   1.22

# As Labelled Index
In [54]: df = df.set_index('row');df
Out[54]: 
     One_X  One_Y  Two_X  Two_Y
row                            
0      1.1    1.2   1.11   1.22
1      1.1    1.2   1.11   1.22
2      1.1    1.2   1.11   1.22

# With Hierarchical Columns
In [55]: df.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns]);df
Out[55]: 
     One        Two      
       X    Y     X     Y
row                      
0    1.1  1.2  1.11  1.22
1    1.1  1.2  1.11  1.22
2    1.1  1.2  1.11  1.22

# Now stack & Reset
In [56]: df = df.stack(0).reset_index(1);df
Out[56]: 
    level_1     X     Y
row                    
0       One  1.10  1.20
0       Two  1.11  1.22
1       One  1.10  1.20
1       Two  1.11  1.22
2       One  1.10  1.20
2       Two  1.11  1.22

# And fix the labels (Notice the label 'level_1' got added automatically)
In [57]: df.columns = ['Sample','All_X','All_Y'];df
Out[57]: 
    Sample  All_X  All_Y
row                     
0      One   1.10   1.20
0      Two   1.11   1.22
1      One   1.10   1.20
1      Two   1.11   1.22
2      One   1.10   1.20
2      Two   1.11   1.22
```

##### 7.3.1 算术 

[需要广播的多级索引的算术运算](http://stackoverflow.com/questions/19501510/divide-entire-pandas-multiindex-dataframe-by-dataframe-variable/19502176#19502176)

```python
In [58]: cols = pd.MultiIndex.from_tuples([ (x,y) for x in ['A','B','C'] for y in ['O','I']])

In [59]: df = pd.DataFrame(np.random.randn(2,6),index=['n','m'],columns=cols); df
Out[59]: 
          A                   B                   C          
          O         I         O         I         O         I
n  1.920906 -0.388231 -2.314394  0.665508  0.402562  0.399555
m -1.765956  0.850423  0.388054  0.992312  0.744086 -0.739776

In [60]: df = df.div(df['C'],level=1); df
Out[60]: 
          A                   B              C     
          O         I         O         I    O    I
n  4.771702 -0.971660 -5.749162  1.665625  1.0  1.0
m -2.373321 -1.149568  0.521518 -1.341367  1.0  1.0
```

##### 7.3.2 索引

[使用`xs`进行多重索引](http://stackoverflow.com/questions/12590131/how-to-slice-multindex-columns-in-pandas-dataframes)

```python
In [61]: coords = [('AA','one'),('AA','six'),('BB','one'),('BB','two'),('BB','six')]

In [62]: index = pd.MultiIndex.from_tuples(coords)

In [63]: df = pd.DataFrame([11,22,33,44,55],index,['MyData']); df
Out[63]: 
        MyData
AA one      11
   six      22
BB one      33
   two      44
   six      55
```

得到第一级索引和第一个轴的横截面

```python
In [64]: df.xs('BB',level=0,axis=0)  #Note : level and axis are optional, and default to zero
Out[64]: 
     MyData
one      33
two      44
six      55
```

第二季索引和第一个轴

```python
In [65]: df.xs('six',level=1,axis=0)
Out[65]: 
    MyData
AA      22
BB      55
```

[使用`xs`进行多重索引，方法2](http://stackoverflow.com/questions/12590131/how-to-slice-multindex-columns-in-pandas-dataframes)

```python
In [66]: index = list(itertools.product(['Ada','Quinn','Violet'],['Comp','Math','Sci']))

In [67]: headr = list(itertools.product(['Exams','Labs'],['I','II']))

In [68]: indx = pd.MultiIndex.from_tuples(index,names=['Student','Course'])

In [69]: cols = pd.MultiIndex.from_tuples(headr) #Notice these are un-named

In [70]: data = [[70+x+y+(x*y)%3 for x in range(4)] for y in range(9)]

In [71]: df = pd.DataFrame(data,indx,cols); df
Out[71]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Comp      70  71   72  73
        Math      71  73   75  74
        Sci       72  75   75  75
Quinn   Comp      73  74   75  76
        Math      74  76   78  77
        Sci       75  78   78  78
Violet  Comp      76  77   78  79
        Math      77  79   81  80
        Sci       78  81   81  81

In [72]: All = slice(None)

In [73]: df.loc['Violet']
Out[73]: 
       Exams     Labs    
           I  II    I  II
Course                   
Comp      76  77   78  79
Math      77  79   81  80
Sci       78  81   81  81

In [74]: df.loc[(All,'Math'),All]
Out[74]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77
Violet  Math      77  79   81  80

In [75]: df.loc[(slice('Ada','Quinn'),'Math'),All]
Out[75]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Ada     Math      71  73   75  74
Quinn   Math      74  76   78  77

In [76]: df.loc[(All,'Math'),('Exams')]
Out[76]: 
                 I  II
Student Course        
Ada     Math    71  73
Quinn   Math    74  76
Violet  Math    77  79

In [77]: df.loc[(All,'Math'),(All,'II')]
Out[77]: 
               Exams Labs
                  II   II
Student Course           
Ada     Math      73   74
Quinn   Math      76   77
Violet  Math      79   80
```

[使用`xs`设置多重索引的一部分](http://stackoverflow.com/questions/19319432/pandas-selecting-a-lower-level-in-a-dataframe-to-do-a-ffill)

##### 7.3.3 排序

[对多重索引按照指定的列或排好序的列列表排序](http://stackoverflow.com/questions/14733871/mutli-index-sorting-in-pandas)

```python
In [78]: df.sort_values(by=('Labs', 'II'), ascending=False)
Out[78]: 
               Exams     Labs    
                   I  II    I  II
Student Course                   
Violet  Sci       78  81   81  81
        Math      77  79   81  80
        Comp      76  77   78  79
Quinn   Sci       75  78   78  78
        Math      74  76   78  77
        Comp      73  74   75  76
Ada     Sci       72  75   75  75
        Math      71  73   75  74
        Comp      70  71   72  73
```

[部分选择，排序的需要](https://github.com/pandas-dev/pandas/issues/2995)

##### 7.3.4 等级

[在多重索引上增加索引等级](http://stackoverflow.com/questions/14744068/prepend-a-level-to-a-pandas-multiindex)

[多层索引平整](http://stackoverflow.com/questions/14507794/python-pandas-how-to-flatten-a-hierarchical-index-in-columns)

#### 7.4 缺失数据

[缺失数据文档](http://pandas.pydata.org/pandas-docs/version/0.23/missing_data.html#missing-data)

填充一个颠倒的时间序列

```python
In [79]: df = pd.DataFrame(np.random.randn(6,1), index=pd.date_range('2013-08-01', periods=6, freq='B'), columns=list('A'))

In [80]: df.loc[df.index[3], 'A'] = np.nan

In [81]: df
Out[81]: 
                   A
2013-08-01 -1.054874
2013-08-02 -0.179642
2013-08-05  0.639589
2013-08-06       NaN
2013-08-07  1.906684
2013-08-08  0.104050

In [82]: df.reindex(df.index[::-1]).ffill()
Out[82]: 
                   A
2013-08-08  0.104050
2013-08-07  1.906684
2013-08-06  1.906684
2013-08-05  0.639589
2013-08-02 -0.179642
2013-08-01 -1.054874
```

[累加重置NaN值](http://stackoverflow.com/questions/18196811/cumsum-reset-at-nan)

##### 7.4.1 替换

[使用反向引用进行替换](https://stackoverflow.com/questions/16818871/extracting-value-and-creating-new-column-out-of-it)

#### 7.5 分组

[分组文档](http://pandas.pydata.org/pandas-docs/version/0.23/groupby.html#groupby)

[分组之后使用apply的基本使用](http://stackoverflow.com/questions/15322632/python-pandas-df-groupy-agg-column-reference-in-agg)

不用于`agg`，`apply`的调用对象是传入的一个能够让你访问所有列的子DataFrame

```python
In [83]: df = pd.DataFrame({'animal': 'cat dog cat fish dog cat cat'.split(),
   ....:                    'size': list('SSMMMLL'),
   ....:                    'weight': [8, 10, 11, 1, 20, 12, 12],
   ....:                    'adult' : [False] * 5 + [True] * 2}); df
   ....: 
Out[83]: 
  animal size  weight  adult
0    cat    S       8  False
1    dog    S      10  False
2    cat    M      11  False
3   fish    M       1  False
4    dog    M      20  False
5    cat    L      12   True
6    cat    L      12   True

#List the size of the animals with the highest weight.
In [84]: df.groupby('animal').apply(lambda subf: subf['size'][subf['weight'].idxmax()])
Out[84]: 
animal
cat     L
dog     M
fish    M
dtype: object
```

[使用`get_group`](http://stackoverflow.com/questions/14734533/how-to-access-pandas-groupby-dataframe-by-key)

```python
In [85]: gb = df.groupby(['animal'])

In [86]: gb.get_group('cat')
Out[86]: 
  animal size  weight  adult
0    cat    S       8  False
2    cat    M      11  False
5    cat    L      12   True
6    cat    L      12   True
```

[应用到一组的不同元素](http://stackoverflow.com/questions/15262134/apply-different-functions-to-different-items-in-group-object-python-pandas)

```python
In [87]: def GrowUp(x):
   ....:    avg_weight =  sum(x[x['size'] == 'S'].weight * 1.5)
   ....:    avg_weight += sum(x[x['size'] == 'M'].weight * 1.25)
   ....:    avg_weight += sum(x[x['size'] == 'L'].weight)
   ....:    avg_weight /= len(x)
   ....:    return pd.Series(['L',avg_weight,True], index=['size', 'weight', 'adult'])
   ....: 

In [88]: expected_df = gb.apply(GrowUp)

In [89]: expected_df
Out[89]: 
       size   weight  adult
animal                     
cat       L  12.4375   True
dog       L  20.0000   True
fish      L   1.2500   True
```

[扩展`apply`](http://stackoverflow.com/questions/14542145/reductions-down-a-column-in-pandas)

```python
In [90]: S = pd.Series([i / 100.0 for i in range(1,11)])

In [91]: def CumRet(x,y):
   ....:    return x * (1 + y)
   ....: 

In [92]: def Red(x):
   ....:    return functools.reduce(CumRet,x,1.0)
   ....: 

In [93]: S.expanding().apply(Red, raw=True)
Out[93]: 
0    1.010000
1    1.030200
2    1.061106
3    1.103550
4    1.158728
5    1.228251
6    1.314229
7    1.419367
8    1.547110
9    1.701821
dtype: float64
```

[用一组内剩余数据的均值填充缺失值](http://stackoverflow.com/questions/14760757/replacing-values-with-groupby-means)

```python
In [94]: df = pd.DataFrame({'A' : [1, 1, 2, 2], 'B' : [1, -1, 1, 2]})

In [95]: gb = df.groupby('A')

In [96]: def replace(g):
   ....:    mask = g < 0
   ....:    g.loc[mask] = g[~mask].mean()
   ....:    return g
   ....: 

In [97]: gb.transform(replace)
Out[97]: 
     B
0  1.0
1  1.0
2  1.0
3  2.0
```

[用聚合数据排序组](http://stackoverflow.com/questions/14941366/pandas-sort-by-group-aggregate-and-column)

```python
In [98]: df = pd.DataFrame({'code': ['foo', 'bar', 'baz'] * 2,
   ....:                    'data': [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],
   ....:                    'flag': [False, True] * 3})
   ....: 

In [99]: code_groups = df.groupby('code')

In [100]: agg_n_sort_order = code_groups[['data']].transform(sum).sort_values(by='data')

In [101]: sorted_df = df.loc[agg_n_sort_order.index]

In [102]: sorted_df
Out[102]: 
  code  data   flag
1  bar -0.21   True
4  bar -0.59  False
0  foo  0.16  False
3  foo  0.45   True
2  baz  0.33  False
5  baz  0.62   True
```

[创建多重聚合列](http://stackoverflow.com/questions/14897100/create-multiple-columns-in-pandas-aggregation-function)

```python
In [103]: rng = pd.date_range(start="2014-10-07",periods=10,freq='2min')

In [104]: ts = pd.Series(data = list(range(10)), index = rng)

In [105]: def MyCust(x):
   .....:    if len(x) > 2:
   .....:       return x[1] * 1.234
   .....:    return pd.NaT
   .....: 

In [106]: mhc = {'Mean' : np.mean, 'Max' : np.max, 'Custom' : MyCust}

In [107]: ts.resample("5min").apply(mhc)
Out[107]: 
Custom  2014-10-07 00:00:00    1.234
        2014-10-07 00:05:00      NaT
        2014-10-07 00:10:00    7.404
        2014-10-07 00:15:00      NaT
Max     2014-10-07 00:00:00        2
        2014-10-07 00:05:00        4
        2014-10-07 00:10:00        7
        2014-10-07 00:15:00        9
Mean    2014-10-07 00:00:00        1
        2014-10-07 00:05:00      3.5
        2014-10-07 00:10:00        6
        2014-10-07 00:15:00      8.5
dtype: object

In [108]: ts
Out[108]: 
2014-10-07 00:00:00    0
2014-10-07 00:02:00    1
2014-10-07 00:04:00    2
2014-10-07 00:06:00    3
2014-10-07 00:08:00    4
2014-10-07 00:10:00    5
2014-10-07 00:12:00    6
2014-10-07 00:14:00    7
2014-10-07 00:16:00    8
2014-10-07 00:18:00    9
Freq: 2T, dtype: int64
```

[创建数值计数列然后赋值回DataFrame](http://stackoverflow.com/questions/17709270/i-want-to-create-a-column-of-value-counts-in-my-pandas-dataframe)

```python
In [109]: df = pd.DataFrame({'Color': 'Red Red Red Blue'.split(),
   .....:                    'Value': [100, 150, 50, 50]}); df
   .....: 
Out[109]: 
  Color  Value
0   Red    100
1   Red    150
2   Red     50
3  Blue     50

In [110]: df['Counts'] = df.groupby(['Color']).transform(len)

In [111]: df
Out[111]: 
  Color  Value  Counts
0   Red    100       3
1   Red    150       3
2   Red     50       3
3  Blue     50       1
```

[基于索引的一列中的数值的组移位](http://stackoverflow.com/q/23198053/190597)

```python
In [112]: df = pd.DataFrame(
   .....:    {u'line_race': [10, 10, 8, 10, 10, 8],
   .....:     u'beyer': [99, 102, 103, 103, 88, 100]},
   .....:     index=[u'Last Gunfighter', u'Last Gunfighter', u'Last Gunfighter',
   .....:            u'Paynter', u'Paynter', u'Paynter']); df
   .....: 
Out[112]: 
                 line_race  beyer
Last Gunfighter         10     99
Last Gunfighter         10    102
Last Gunfighter          8    103
Paynter                 10    103
Paynter                 10     88
Paynter                  8    100

In [113]: df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1)

In [114]: df
Out[114]: 
                 line_race  beyer  beyer_shifted
Last Gunfighter         10     99            NaN
Last Gunfighter         10    102           99.0
Last Gunfighter          8    103          102.0
Paynter                 10    103            NaN
Paynter                 10     88          103.0
Paynter                  8    100           88.0
```

[选择每组数据中的最大值](http://stackoverflow.com/q/26701849/190597)

```python
In [115]: df = pd.DataFrame({'host':['other','other','that','this','this'],
   .....:                    'service':['mail','web','mail','mail','web'],
   .....:                    'no':[1, 2, 1, 2, 1]}).set_index(['host', 'service'])
   .....: 

In [116]: mask = df.groupby(level=0).agg('idxmax')

In [117]: df_count = df.loc[mask['no']].reset_index()

In [118]: df_count
Out[118]: 
    host service  no
0  other     web   2
1   that    mail   1
2   this    mail   2
```

[像Python的`itertools.groupby`那样分组](http://stackoverflow.com/q/29142487/846892)

```python
In [119]: df = pd.DataFrame([0, 1, 0, 1, 1, 1, 0, 1, 1], columns=['A'])

In [120]: df.A.groupby((df.A != df.A.shift()).cumsum()).groups
Out[120]: 
{1: Int64Index([0], dtype='int64'),
 2: Int64Index([1], dtype='int64'),
 3: Int64Index([2], dtype='int64'),
 4: Int64Index([3, 4, 5], dtype='int64'),
 5: Int64Index([6], dtype='int64'),
 6: Int64Index([7, 8], dtype='int64')}

In [121]: df.A.groupby((df.A != df.A.shift()).cumsum()).cumsum()
Out[121]: 
0    0
1    1
2    0
3    1
4    2
5    3
6    0
7    1
8    2
Name: A, dtype: int64
```

##### 7.5.1 扩展数据

[数据规整和日期转换](http://stackoverflow.com/questions/15489011/python-time-series-alignment-and-to-date-functions)

[在数据（而不是计数）上执行窗口移动计算](http://stackoverflow.com/questions/14300768/pandas-rolling-computation-with-window-based-on-values-instead-of-counts)

[根据时间间隔滚动求平均值](http://stackoverflow.com/questions/15771472/pandas-rolling-mean-by-time-interval)

##### 7.5.2 分解

[分解一个结构](http://stackoverflow.com/questions/13353233/best-way-to-split-a-dataframe-given-an-edge/15449992#15449992)

创建一组DataFrame，使用行之间包含的逻辑描述分解数据。

```python
In [122]: df = pd.DataFrame(data={'Case' : ['A','A','A','B','A','A','B','A','A'],
   .....:                         'Data' : np.random.randn(9)})
   .....: 

In [123]: dfs = list(zip(*df.groupby((1*(df['Case']=='B')).cumsum().rolling(window=3,min_periods=1).median())))[-1]

In [124]: dfs[0]
Out[124]: 
  Case      Data
0    A  0.174068
1    A -0.439461
2    A -0.741343
3    B -0.079673

In [125]: dfs[1]
Out[125]: 
  Case      Data
4    A -0.922875
5    A  0.303638
6    B -0.917368

In [126]: dfs[2]
Out[126]: 
  Case      Data
7    A -1.624062
8    A -0.758514
```

##### 7.5.3 透视表

[透视表](http://pandas.pydata.org/pandas-docs/version/0.23/reshaping.html#reshaping-pivot)文档

[局部求和与小计](http://stackoverflow.com/questions/15570099/pandas-pivot-tables-row-subtotals/15574875#15574875)

```python
In [127]: df = pd.DataFrame(data={'Province' : ['ON','QC','BC','AL','AL','MN','ON'],
   .....:                          'City' : ['Toronto','Montreal','Vancouver','Calgary','Edmonton','Winnipeg','Windsor'],
   .....:                          'Sales' : [13,6,16,8,4,3,1]})
   .....: 

In [128]: table = pd.pivot_table(df,values=['Sales'],index=['Province'],columns=['City'],aggfunc=np.sum,margins=True)

In [129]: table.stack('City')
Out[129]: 
                    Sales
Province City            
AL       All         12.0
         Calgary      8.0
         Edmonton     4.0
BC       All         16.0
         Vancouver   16.0
MN       All          3.0
         Winnipeg     3.0
...                   ...
All      Calgary      8.0
         Edmonton     4.0
         Montreal     6.0
         Toronto     13.0
         Vancouver   16.0
         Windsor      1.0
         Winnipeg     3.0

[20 rows x 1 columns]
```

[像R中的`pylr`那种的频率表](http://stackoverflow.com/questions/15589354/frequency-tables-in-pandas-like-plyr-in-r)

```python
In [130]: grades = [48,99,75,80,42,80,72,68,36,78]

In [131]: df = pd.DataFrame( {'ID': ["x%d" % r for r in range(10)],
   .....:                     'Gender' : ['F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'M', 'M'],
   .....:                     'ExamYear': ['2007','2007','2007','2008','2008','2008','2008','2009','2009','2009'],
   .....:                     'Class': ['algebra', 'stats', 'bio', 'algebra', 'algebra', 'stats', 'stats', 'algebra', 'bio', 'bio'],
   .....:                     'Participated': ['yes','yes','yes','yes','no','yes','yes','yes','yes','yes'],
   .....:                     'Passed': ['yes' if x > 50 else 'no' for x in grades],
   .....:                     'Employed': [True,True,True,False,False,False,False,True,True,False],
   .....:                     'Grade': grades})
   .....: 

In [132]: df.groupby('ExamYear').agg({'Participated': lambda x: x.value_counts()['yes'],
   .....:                     'Passed': lambda x: sum(x == 'yes'),
   .....:                     'Employed' : lambda x : sum(x),
   .....:                     'Grade' : lambda x : sum(x) / len(x)})
   .....: 
Out[132]: 
          Participated  Passed  Employed      Grade
ExamYear                                           
2007                 3       2         3  74.000000
2008                 3       3         0  68.500000
2009                 3       2         2  60.666667
```

[使用逐年的数据绘图](http://stackoverflow.com/questions/30379789/plot-pandas-data-frame-with-year-over-year-data)

创建年与月交叉列表

```python
In [133]: df = pd.DataFrame({'value': np.random.randn(36)},
   .....:                   index=pd.date_range('2011-01-01', freq='M', periods=36))
   .....: 

In [134]: pd.pivot_table(df, index=df.index.month, columns=df.index.year,
   .....:                values='value', aggfunc='sum')
   .....: 
Out[134]: 
        2011      2012      2013
1  -0.560859  0.120930  0.516870
2  -0.589005 -0.210518  0.343125
3  -1.070678 -0.931184  2.137827
4  -1.681101  0.240647  0.452429
5   0.403776 -0.027462  0.483103
6   0.609862  0.033113  0.061495
7   0.387936 -0.658418  0.240767
8   1.815066  0.324102  0.782413
9   0.705200 -1.403048  0.628462
10 -0.668049 -0.581967 -0.880627
11  0.242501 -1.233862  0.777575
12  0.313421 -3.520876 -0.779367
```

##### 7.5.4 调用 

[滚动调用来组织数据 - 将嵌入式列表转换成多重索引数据框。](http://stackoverflow.com/questions/17349981/converting-pandas-dataframe-with-categorical-values-into-binary-values)

```python
In [135]: df = pd.DataFrame(data={'A' : [[2,4,8,16],[100,200],[10,20,30]], 'B' : [['a','b','c'],['jj','kk'],['ccc']]},index=['I','II','III'])

In [136]: def SeriesFromSubList(aList):
   .....:    return pd.Series(aList)
   .....: 

In [137]: df_orgz = pd.concat(dict([ (ind,row.apply(SeriesFromSubList)) for ind,row in df.iterrows() ]))
```

[对一个DataFrame滚动调用，返回Series](http://stackoverflow.com/questions/19121854/using-rolling-apply-on-a-dataframe-object)

对多个列滚动调用函数，这个函数在一个Series的一个标量返回之前计算这个Series。

```python
In [138]: df = pd.DataFrame(data=np.random.randn(2000,2)/10000,
   .....:                   index=pd.date_range('2001-01-01',periods=2000),
   .....:                   columns=['A','B']); df
   .....: 
Out[138]: 
                   A         B
2001-01-01  0.000032 -0.000004
2001-01-02 -0.000001  0.000207
2001-01-03  0.000120 -0.000220
2001-01-04 -0.000083 -0.000165
2001-01-05 -0.000047  0.000156
2001-01-06  0.000027  0.000104
2001-01-07  0.000041 -0.000101
...              ...       ...
2006-06-17 -0.000034  0.000034
2006-06-18  0.000002  0.000166
2006-06-19  0.000023 -0.000081
2006-06-20 -0.000061  0.000012
2006-06-21 -0.000111  0.000027
2006-06-22 -0.000061 -0.000009
2006-06-23  0.000074 -0.000138

[2000 rows x 2 columns]

In [139]: def gm(aDF,Const):
   .....:    v = ((((aDF.A+aDF.B)+1).cumprod())-1)*Const
   .....:    return (aDF.index[0],v.iloc[-1])
   .....: 

In [140]: S = pd.Series(dict([ gm(df.iloc[i:min(i+51,len(df)-1)],5) for i in range(len(df)-50) ])); S
Out[140]: 
2001-01-01   -0.001373
2001-01-02   -0.001705
2001-01-03   -0.002885
2001-01-04   -0.002987
2001-01-05   -0.002384
2001-01-06   -0.004700
2001-01-07   -0.005500
                ...   
2006-04-28   -0.002682
2006-04-29   -0.002436
2006-04-30   -0.002602
2006-05-01   -0.001785
2006-05-02   -0.001799
2006-05-03   -0.000605
2006-05-04   -0.000541
Length: 1950, dtype: float64
```

[对一个DataFrame滚动调用，返回一个标量](http://stackoverflow.com/questions/21040766/python-pandas-rolling-apply-two-column-input-into-function/21045831#21045831)

对多个列滚动调用函数，这个函数返回一个标量（`Volume`加权平均`price`）。

```python
In [141]: rng = pd.date_range(start = '2014-01-01',periods = 100)

In [142]: df = pd.DataFrame({'Open' : np.random.randn(len(rng)),
   .....:                    'Close' : np.random.randn(len(rng)),
   .....:                    'Volume' : np.random.randint(100,2000,len(rng))}, index=rng); df
   .....: 
Out[142]: 
                Open     Close  Volume
2014-01-01  0.011174 -0.653039    1581
2014-01-02  0.214258  1.314205    1707
2014-01-03 -1.046922 -0.341915    1768
2014-01-04 -0.752902 -1.303586     836
2014-01-05 -0.410793  0.396288     694
2014-01-06  0.648401 -0.548006     796
2014-01-07  0.737320  0.481380     265
...              ...       ...     ...
2014-04-04  0.120378 -2.548128     564
2014-04-05  0.231661  0.223346    1908
2014-04-06  0.952664  1.228841    1090
2014-04-07 -0.176090  0.552784    1813
2014-04-08  1.781318 -0.795389    1103
2014-04-09 -0.753493 -0.018815    1456
2014-04-10 -1.047997  1.138197    1193

[100 rows x 3 columns]

In [143]: def vwap(bars): return ((bars.Close*bars.Volume).sum()/bars.Volume.sum())

In [144]: window = 5

In [145]: s = pd.concat([ (pd.Series(vwap(df.iloc[i:i+window]), index=[df.index[i+window]])) for i in range(len(df)-window) ]);

In [146]: s.round(2)
Out[146]: 
2014-01-06   -0.03
2014-01-07    0.07
2014-01-08   -0.40
2014-01-09   -0.81
2014-01-10   -0.63
2014-01-11   -0.86
2014-01-12   -0.36
              ... 
2014-04-04   -1.27
2014-04-05   -1.36
2014-04-06   -0.73
2014-04-07    0.04
2014-04-08    0.21
2014-04-09    0.07
2014-04-10    0.25
Length: 95, dtype: float64
```



#### 7.6 时间序列

[时间之间](http://stackoverflow.com/questions/14539992/pandas-drop-rows-outside-of-time-range)

[在时间之间使用索引器](http://stackoverflow.com/questions/17559885/pandas-dataframe-mask-based-on-index)

[构造一个不包含周末包含特定时间的时间序列](http://stackoverflow.com/questions/24010830/pandas-generate-sequential-timestamp-with-jump/24014440#24014440?)

[矢量化查找](http://stackoverflow.com/questions/13893227/vectorized-look-up-of-values-in-pandas-dataframe)

[聚合、绘制时间序列](http://nipunbatra.github.io/2015/06/timeseries/)

将列是小时数据、行是天数据的矩阵转换成连续的时间序列形式的行序列。[如何重塑Python pandas DataFrame](http://stackoverflow.com/questions/15432659/how-to-rearrange-a-python-pandas-dataframe)？

[在包含重复值的时间序列上按特定的频率重建索引](http://stackoverflow.com/questions/22244383/pandas-df-refill-adding-two-columns-of-different-shape)

计算一个DatatimeIndex中每个月的第一天

```python
In [147]: dates = pd.date_range('2000-01-01', periods=5)

In [148]: dates.to_period(freq='M').to_timestamp()
Out[148]: 
DatetimeIndex(['2000-01-01', '2000-01-01', '2000-01-01', '2000-01-01',
               '2000-01-01'],
              dtype='datetime64[ns]', freq=None)
```

##### 7.6.1 重采样

[重采样](http://pandas.pydata.org/pandas-docs/version/0.23/timeseries.html#timeseries-resampling)文档

[使用Grouper而不是TimeGrouper来分组数据](https://stackoverflow.com/questions/15297053/how-can-i-divide-single-values-of-a-dataframe-by-monthly-averages)

[包含缺失值的时间分组](https://stackoverflow.com/questions/33637312/pandas-grouper-by-frequency-with-completeness-requirement)

[合法的Grouper频率参数](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases)

[使用多重索引分组](https://stackoverflow.com/questions/41483763/pandas-timegrouper-on-multiindex)

[使用TimeGrouper和另一个分组创建子分组，然后调用自定义函数](https://github.com/pandas-dev/pandas/issues/3791)

[使用自定义周期重采样](http://stackoverflow.com/questions/15408156/resampling-with-custom-periods)

[不添加新的天重采样当天的数据](http://stackoverflow.com/questions/14898574/resample-intrday-pandas-dataframe-without-add-new-days)

[重采样分钟数据](http://stackoverflow.com/questions/14861023/resampling-minute-data)

[使用groupby重采样](http://stackoverflow.com/q/18677271/564538)



#### 7.7 合并

[Concat](http://pandas.pydata.org/pandas-docs/version/0.23/merging.html#merging-concatenation)文档。[Join](http://pandas.pydata.org/pandas-docs/version/0.23/merging.html#merging-join)文档

追加两个有重复索引的DataFrame（模仿R的rbind）

```python
In [149]: rng = pd.date_range('2000-01-01', periods=6)

In [150]: df1 = pd.DataFrame(np.random.randn(6, 3), index=rng, columns=['A', 'B', 'C'])

In [151]: df2 = df1.copy()
```

视DataFrame的结构，可能需要指定`ignore_index`

```python
In [152]: df = df1.append(df2,ignore_index=True); df
Out[152]: 
           A         B         C
0  -0.480676 -1.305282 -0.212846
1   1.979901  0.363112 -0.275732
2  -1.433852  0.580237 -0.013672
3   1.776623 -0.803467  0.521517
4  -0.302508 -0.442948 -0.395768
5  -0.249024 -0.031510  2.413751
6  -0.480676 -1.305282 -0.212846
7   1.979901  0.363112 -0.275732
8  -1.433852  0.580237 -0.013672
9   1.776623 -0.803467  0.521517
10 -0.302508 -0.442948 -0.395768
11 -0.249024 -0.031510  2.413751
```

[DataFrame的左连接](https://github.com/pandas-dev/pandas/issues/2996)

```python
In [153]: df = pd.DataFrame(data={'Area' : ['A'] * 5 + ['C'] * 2,
   .....:                         'Bins' : [110] * 2 + [160] * 3 + [40] * 2,
   .....:                         'Test_0' : [0, 1, 0, 1, 2, 0, 1],
   .....:                         'Data' : np.random.randn(7)});df
   .....: 
Out[153]: 
  Area  Bins  Test_0      Data
0    A   110       0 -0.378914
1    A   110       1 -1.032527
2    A   160       0 -1.402816
3    A   160       1  0.715333
4    A   160       2 -0.091438
5    C    40       0  1.608418
6    C    40       1  0.753207

In [154]: df['Test_1'] = df['Test_0'] - 1

In [155]: pd.merge(df, df, left_on=['Bins', 'Area','Test_0'], right_on=['Bins', 'Area','Test_1'],suffixes=('_L','_R'))
Out[155]: 
  Area  Bins  Test_0_L    Data_L  Test_1_L  Test_0_R    Data_R  Test_1_R
0    A   110         0 -0.378914        -1         1 -1.032527         0
1    A   160         0 -1.402816        -1         1  0.715333         0
2    A   160         1  0.715333         0         2 -0.091438         1
3    C    40         0  1.608418        -1         1  0.753207         0
```

[如何设置索引并连接](http://stackoverflow.com/questions/14341805/pandas-merge-pd-merge-how-to-set-the-index-and-join)

[类似KDB的asof连接](http://stackoverflow.com/questions/12322289/kdb-like-asof-join-for-timeseries-data-in-pandas/12336039#12336039)

[使用基于数值的条件进行连接](http://stackoverflow.com/questions/15581829/how-to-perform-an-inner-or-outer-join-of-dataframes-with-pandas-on-non-simplisti)

[基于一个范围内的数值使用`searchsorted`合并](http://stackoverflow.com/questions/25125626/pandas-merge-with-logic/2512764)

#### 7.8 绘图

[绘图](http://pandas.pydata.org/pandas-docs/version/0.23/visualization.html#visualization)文档

[让`matplotlib`看起来像R](http://stackoverflow.com/questions/14349055/making-matplotlib-graphs-look-like-r-by-default)

[设置x轴的最大最小标签](http://stackoverflow.com/questions/12945971/pandas-timeseries-plot-setting-x-axis-major-and-minor-ticks-and-labels)

[在iPython notebook中绘制多个图表](http://stackoverflow.com/questions/16392921/make-more-than-one-chart-in-same-ipython-notebook-cell)

[创建多线图](http://stackoverflow.com/questions/16568964/make-a-multiline-plot-from-csv-file-in-matplotlib)

[绘制热力图](http://stackoverflow.com/questions/17050202/plot-timeseries-of-histograms-in-python)

[为时间序列图添加注释](http://stackoverflow.com/questions/11067368/annotate-time-series-plot-in-matplotlib)

[为时间序列图添加注释 #2](http://stackoverflow.com/questions/17891493/annotating-points-from-a-pandas-dataframe-in-matplotlib-plot)

[使用`Pandas`、`Vincent`和`xlsxwrite`在Excel文件中生成嵌套图表](https://pandas-xlsxwriter-charts.readthedocs.io/)

[为分层变量的每个四分位点绘制盒须图](http://stackoverflow.com/questions/23232989/boxplot-stratified-by-column-in-python-pandas)

```python
In [156]: df = pd.DataFrame(
   .....:      {u'stratifying_var': np.random.uniform(0, 100, 20),
   .....:       u'price': np.random.normal(100, 5, 20)})
   .....: 

In [157]: df[u'quartiles'] = pd.qcut(
   .....:     df[u'stratifying_var'],
   .....:     4,
   .....:     labels=[u'0-25%', u'25-50%', u'50-75%', u'75-100%'])
   .....: 

In [158]: df.boxplot(column=u'price', by=u'quartiles')
Out[158]: <matplotlib.axes._subplots.AxesSubplot at 0x1198cd940>
```

![](http://pandas.pydata.org/pandas-docs/version/0.23/_images/quartile_boxplot.png)

#### 7.9 数据IO

[SQL和HDF5的性能比较](http://stackoverflow.com/questions/16628329/hdf5-and-sqlite-concurrency-compression-i-o-performance)

##### 7.9.1 CSV

[CSV](http://pandas.pydata.org/pandas-docs/version/0.23/io.html#io-read-csv-table)文档

[read_csv实战](http://wesmckinney.com/blog/update-on-upcoming-pandas-v0-10-new-file-parser-other-performance-wins/)

[追加到一个csv文件](http://stackoverflow.com/questions/17134942/pandas-dataframe-output-end-of-csv)

[按块读取csv数据](http://stackoverflow.com/questions/11622652/large-persistent-dataframe-in-pandas/12193309#12193309)

[读取数据结构开始的一些行](http://stackoverflow.com/questions/15008970/way-to-read-first-few-lines-for-pandas-dataframe)

读取不是用gzip或bz2（这两种压缩方法是`read_csv`能理解的原生压缩格式）压缩的压缩文件。后面的这个示例展示了（如何处理）一个用winzip压缩的文件，但是是一个使用上下文管理器打开并且使用句柄读取的一般应用程序。查看[这里](http://stackoverflow.com/questions/17789907/pandas-convert-winzipped-csv-file-to-data-frame)。

（译者注：这里原文有语病，大概的意思是，这个链接介绍了处理压缩文件的一般方法。不过，如果使用gzip或bz2压缩的话，read_csv自己可以处理）

[从文件推断dtype](http://stackoverflow.com/questions/15555005/get-inferred-dataframe-types-iteratively-using-chunksize)

[处理包含脏数据的行](http://github.com/pandas-dev/pandas/issues/2886)

[处理包含脏数据的行 #2](http://nipunbatra.github.io/2013/06/reading-unclean-data-csv-using-pandas/)

[读取包含Unix时间戳的csv文件，转换成本地时区时间格式](http://nipunbatra.github.io/2013/06/pandas-reading-csv-with-unix-timestamps-and-converting-to-local-timezone/)

[不写重复值的情况下，写一个多行索引csv文件](http://stackoverflow.com/questions/17349574/pandas-write-multiindex-rows-with-to-csv)

##### 7.9.2 读取多个文件，创建一个DataFrame

合并多个文件到一个DataFrame的最好方式是，挨个读取数据框，将它们放入一个列表，然后使用`pd.concat`合并它们。

```python
In [159]: for i in range(3):
   .....:     data = pd.DataFrame(np.random.randn(10, 4))
   .....:     data.to_csv('file_{}.csv'.format(i))
   .....: 

In [160]: files = ['file_0.csv', 'file_1.csv', 'file_2.csv']

In [161]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
```

可以使用同样的方法读取符合某种模式的所有文件。下面是使用glob的一个示例：

```python
In [162]: import glob

In [163]: files = glob.glob('file_*.csv')

In [164]: result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)
```

最后，这个方法也可以和[io文档](http://pandas.pydata.org/pandas-docs/version/0.23/io.html#io)中其他的`pd.read_*(...)`函数一起工作。

##### 7.9.3 解析多个列中的日期元素

使用一个格式解析多个列中的日期元素更快

```python
In [30]: i = pd.date_range('20000101',periods=10000)

In [31]: df = pd.DataFrame(dict(year = i.year, month = i.month, day = i.day))

In [32]: df.head()
Out[32]:
   day  month  year
0    1      1  2000
1    2      1  2000
2    3      1  2000
3    4      1  2000
4    5      1  2000

In [33]: %timeit pd.to_datetime(df.year*10000+df.month*100+df.day,format='%Y%m%d')
100 loops, best of 3: 7.08 ms per loop

# simulate combinging into a string, then parsing
In [34]: ds = df.apply(lambda x: "%04d%02d%02d" % (x['year'],x['month'],x['day']),axis=1)

In [35]: ds.head()
Out[35]:
0    20000101
1    20000102
2    20000103
3    20000104
4    20000105
dtype: object

In [36]: %timeit pd.to_datetime(ds)
1 loops, best of 3: 488 ms per loop
```

##### 7.9.4 跳过头部和数据之间的行

```python
In [165]: data = """;;;;
   .....:  ;;;;
   .....:  ;;;;
   .....:  ;;;;
   .....:  ;;;;
   .....:  ;;;;
   .....: ;;;;
   .....:  ;;;;
   .....:  ;;;;
   .....: ;;;;
   .....: date;Param1;Param2;Param4;Param5
   .....:     ;m²;°C;m²;m
   .....: ;;;;
   .....: 01.01.1990 00:00;1;1;2;3
   .....: 01.01.1990 01:00;5;3;4;5
   .....: 01.01.1990 02:00;9;5;6;7
   .....: 01.01.1990 03:00;13;7;8;9
   .....: 01.01.1990 04:00;17;9;10;11
   .....: 01.01.1990 05:00;21;11;12;13
   .....: """
   .....: 
```

方法1：明确地指出要跳过的行，传递给`skiprows`参数

```python
In [166]: pd.read_csv(StringIO(data), sep=';', skiprows=[11,12],
   .....:         index_col=0, parse_dates=True, header=10)
   .....: 
Out[166]: 
                     Param1  Param2  Param4  Param5
date                                               
1990-01-01 00:00:00       1       1       2       3
1990-01-01 01:00:00       5       3       4       5
1990-01-01 02:00:00       9       5       6       7
1990-01-01 03:00:00      13       7       8       9
1990-01-01 04:00:00      17       9      10      11
1990-01-01 05:00:00      21      11      12      13
```

方法2：读取列名，然后读取数据

```python
In [167]: pd.read_csv(StringIO(data), sep=';', header=10, nrows=10).columns
Out[167]: Index(['date', 'Param1', 'Param2', 'Param4', 'Param5'], dtype='object')

In [168]: columns = pd.read_csv(StringIO(data), sep=';', header=10, nrows=10).columns

In [169]: pd.read_csv(StringIO(data), sep=';', index_col=0,
   .....:             header=12, parse_dates=True, names=columns)
   .....: 
Out[169]: 
                     Param1  Param2  Param4  Param5
date                                               
1990-01-01 00:00:00       1       1       2       3
1990-01-01 01:00:00       5       3       4       5
1990-01-01 02:00:00       9       5       6       7
1990-01-01 03:00:00      13       7       8       9
1990-01-01 04:00:00      17       9      10      11
1990-01-01 05:00:00      21      11      12      13
```

#### 7.10 SQL

[SQL](http://pandas.pydata.org/pandas-docs/version/0.23/io.html#io-sql)文档

[使用SQL从数据库读取数据](http://stackoverflow.com/questions/10065051/python-pandas-and-databases-like-mysql)

#### 7.11 Excel

[Excel](http://pandas.pydata.org/pandas-docs/version/0.23/io.html#io-excel)文档

[从一个类file的句柄中读取数据](http://stackoverflow.com/questions/15588713/sheets-of-excel-workbook-from-a-url-into-a-pandas-dataframe)

[在`XlsxWriter`输出中修改格式](http://pbpython.com/improve-pandas-excel-output.html)

#### 7.12 HTML

[从一个不能处理缺省请求头的服务器上读取HTML表格](http://stackoverflow.com/a/18939272/564538)

#### 7.13 HDFStore

[HDFStores](http://pandas.pydata.org/pandas-docs/version/0.23/io.html#io-hdf5)文档

[时间戳索引的简单查询](http://stackoverflow.com/questions/13926089/selecting-columns-from-pandas-hdfstore-table)

[使用相互关联的多表层级管理异构数据](http://github.com/pandas-dev/pandas/issues/3032)

[合并包含百万行量级的本地表格](http://stackoverflow.com/questions/14614512/merging-two-tables-with-millions-of-rows-in-python/14617925#14617925)

[从多个进程/线程写入仓库时避免不一致发生](http://stackoverflow.com/a/29014295/2858145)

使用块减少大型仓库的重复，本质上是一个递归减少操作。后面的这个示例展示了一个函数，这个函数用来从csv文件中获得数据，按块创建仓库，同时进行日期解析。[查看这里](http://stackoverflow.com/questions/16110252/need-to-compare-very-large-files-around-1-5gb-in-python/16110391#16110391)。

[按块读取csv文件，创建一个仓库](http://stackoverflow.com/questions/20428355/appending-column-to-frame-of-hdf-file-in-pandas/20428786#20428786)

[追加到一个仓库，同时创建唯一索引](http://stackoverflow.com/questions/16997048/how-does-one-append-large-amounts-of-data-to-a-pandas-hdfstore-and-get-a-natural/16999397#16999397)

[海量数据工作流](http://stackoverflow.com/questions/14262433/large-data-work-flows-using-pandas)

[从一个文件序列中读取数据，追加到一个仓库的同时提供全局唯一索引](http://stackoverflow.com/questions/16997048/how-does-one-append-large-amounts-of-data-to-a-pandas-hdfstore-and-get-a-natural)

[组别密度低的情况下，在一个HDFStore上执行分组](http://stackoverflow.com/questions/15798209/pandas-group-by-query-on-large-data-in-hdfstore)

[组别密度高的前提下，在一个HDFStore上执行分组](http://stackoverflow.com/questions/25459982/trouble-with-grouby-on-millions-of-keys-on-a-chunked-file-in-python-pandas/25471765#25471765)

[在HDFStore上执行分成查询](http://stackoverflow.com/questions/22777284/improve-query-performance-from-a-large-hdfstore-table-with-pandas/22820780#22820780)

[在HDFStore上执行计数](http://stackoverflow.com/questions/20497897/converting-dict-of-dicts-into-pandas-dataframe-memory-issues)

[HDFStore异常排查](http://stackoverflow.com/questions/15488809/how-to-trouble-shoot-hdfstore-exception-cannot-find-the-correct-atom-type)

[设置字符串的`min_itemsize`](http://stackoverflow.com/questions/15988871/hdfstore-appendstring-dataframe-fails-when-string-column-contents-are-longer)

[使用`ptrepack`在仓库中创建一个完全排序的索引](http://stackoverflow.com/questions/17893370/ptrepack-sortby-needs-full-index)

将属性存储到组节点

```python
In [170]: df = pd.DataFrame(np.random.randn(8,3))

In [171]: store = pd.HDFStore('test.h5')

In [172]: store.put('df',df)

# you can store an arbitrary Python object via pickle
In [173]: store.get_storer('df').attrs.my_attribute = dict(A = 10)

In [174]: store.get_storer('df').attrs.my_attribute
Out[174]: {'A': 10}
```

#### 7.14 二进制文件

如果你需要从一个有C结构的数组组成的二进制文件中读取数据，Pandas可以很容易地接受Numpy数组。例如，给一个64位机器上名为`main.c`的文件中的由`gcc main.c -std=gnu99`编译的C程序，

```c
#include <stdio.h>
#include <stdint.h>

typedef struct _Data
{
    int32_t count;
    double avg;
    float scale;
} Data;

int main(int argc, const char *argv[])
{
    size_t n = 10;
    Data d[n];

    for (int i = 0; i < n; ++i)
    {
        d[i].count = i;
        d[i].avg = i + 1.0;
        d[i].scale = (float) i + 2.0f;
    }

    FILE *file = fopen("binary.dat", "wb");
    fwrite(&d, sizeof(Data), n, file);
    fclose(file);

    return 0;
}
```

下面的Python代码将读取二进制文件`binary.dat`到Pandas DataFrame，结构体中每一个元素对应到数据结构中的一列：

```python
names = 'count', 'avg', 'scale'

# note that the offsets are larger than the size of the type because of
# struct padding
offsets = 0, 8, 16
formats = 'i4', 'f8', 'f4'
dt = np.dtype({'names': names, 'offsets': offsets, 'formats': formats},
              align=True)
df = pd.DataFrame(np.fromfile('binary.dat', dt))
```

> 注意：结构体元素的偏移可能会不同，这取决于创建文件的机器的架构。不建议使用这样的原生二进制文件作为一般的数据存储，因为不能跨平台。我们建议使用HDF5或者msgpack，Pandas的IO工具两种都支持。

#### 7.15 计算

[（基于抽样的）时间序列的数值积分](http://nbviewer.ipython.org/5720498)

#### 7.16 Timedeltas（时间差）

[Timedeltas](http://pandas.pydata.org/pandas-docs/version/0.23/timedeltas.html#timedeltas-timedeltas)文档

使用Timedeltas

```python
In [175]: s  = pd.Series(pd.date_range('2012-1-1', periods=3, freq='D'))

In [176]: s - s.max()
Out[176]: 
0   -2 days
1   -1 days
2    0 days
dtype: timedelta64[ns]

In [177]: s.max() - s
Out[177]: 
0   2 days
1   1 days
2   0 days
dtype: timedelta64[ns]

In [178]: s - datetime.datetime(2011,1,1,3,5)
Out[178]: 
0   364 days 20:55:00
1   365 days 20:55:00
2   366 days 20:55:00
dtype: timedelta64[ns]

In [179]: s + datetime.timedelta(minutes=5)
Out[179]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]

In [180]: datetime.datetime(2011,1,1,3,5) - s
Out[180]: 
0   -365 days +03:05:00
1   -366 days +03:05:00
2   -367 days +03:05:00
dtype: timedelta64[ns]

In [181]: datetime.timedelta(minutes=5) + s
Out[181]: 
0   2012-01-01 00:05:00
1   2012-01-02 00:05:00
2   2012-01-03 00:05:00
dtype: datetime64[ns]
```

日期和时间差的加、减

```python
In [182]: deltas = pd.Series([ datetime.timedelta(days=i) for i in range(3) ])

In [183]: df = pd.DataFrame(dict(A = s, B = deltas)); df
Out[183]: 
           A      B
0 2012-01-01 0 days
1 2012-01-02 1 days
2 2012-01-03 2 days

In [184]: df['New Dates'] = df['A'] + df['B'];

In [185]: df['Delta'] = df['A'] - df['New Dates']; df
Out[185]: 
           A      B  New Dates   Delta
0 2012-01-01 0 days 2012-01-01  0 days
1 2012-01-02 1 days 2012-01-03 -1 days
2 2012-01-03 2 days 2012-01-05 -2 days

In [186]: df.dtypes
Out[186]: 
A             datetime64[ns]
B            timedelta64[ns]
New Dates     datetime64[ns]
Delta        timedelta64[ns]
dtype: object
```

另一示例

使用np.nan，数值会被设置成NAT，就像datetime

```python
In [187]: y = s - s.shift(); y
Out[187]: 
0      NaT
1   1 days
2   1 days
dtype: timedelta64[ns]

In [188]: y[1] = np.nan; y
Out[188]: 
0      NaT
1      NaT
2   1 days
dtype: timedelta64[ns]
```

#### 7.17 重命名轴名称

使用者可以用两个函数全局重命名轴名称

```python
In [189]: def set_axis_alias(cls, axis, alias):
   .....:    if axis not in cls._AXIS_NUMBERS:
   .....:       raise Exception("invalid axis [%s] for alias [%s]" % (axis, alias))
   .....:    cls._AXIS_ALIASES[alias] = axis
   .....: 
```

```python
In [190]: def clear_axis_alias(cls, axis, alias):
   .....:    if axis not in cls._AXIS_NUMBERS:
   .....:       raise Exception("invalid axis [%s] for alias [%s]" % (axis, alias))
   .....:    cls._AXIS_ALIASES.pop(alias,None)
   .....: 
```

```python
In [191]: set_axis_alias(pd.DataFrame,'columns', 'myaxis2')

In [192]: df2 = pd.DataFrame(np.random.randn(3,2),columns=['c1','c2'],index=['i1','i2','i3'])

In [193]: df2.sum(axis='myaxis2')
Out[193]: 
i1    0.745167
i2   -0.176251
i3    0.014354
dtype: float64

In [194]: clear_axis_alias(pd.DataFrame,'columns', 'myaxis2')
```

#### 7.18 创建示例数据

像R的`expand.grid()`函数那样，从给定值的每一个组合中创建DataFrame，我们可以创建一个字典，字典中的键是列名，值是数据值的列表

```python
In [195]: def expand_grid(data_dict):
   .....:    rows = itertools.product(*data_dict.values())
   .....:    return pd.DataFrame.from_records(rows, columns=data_dict.keys())
   .....: 

In [196]: df = expand_grid(
   .....:    {'height': [60, 70],
   .....:     'weight': [100, 140, 180],
   .....:     'sex': ['Male', 'Female']})
   .....: 

In [197]: df
Out[197]: 
    height  weight     sex
0       60     100    Male
1       60     100  Female
2       60     140    Male
3       60     140  Female
4       60     180    Male
5       60     180  Female
6       70     100    Male
7       70     100  Female
8       70     140    Male
9       70     140  Female
10      70     180    Male
11      70     180  Female
```





























